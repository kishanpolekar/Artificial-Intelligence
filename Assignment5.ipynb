{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Assignment5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f5WrOcAHZFx8"
      },
      "source": [
        "# Deep Q-Learning "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "l7R5wM2Tn48U"
      },
      "source": [
        "## This Assignment is adopted from University of Illinois\n",
        "http://slazebni.cs.illinois.edu/fall18/assignment5.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wukzQ9o-ZFx-"
      },
      "source": [
        "For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__.\n",
        "\n",
        "![alt text](https://drive.google.com/uc?id=1b54faj61wVsRJYIU6O98tlTu2XrPO5Cr)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qwIDquvEZFx_",
        "outputId": "aac112d3-ced5-48c2-8427-b42656eaba75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "import gym\n",
        "import torch\n",
        "import pylab\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import deque\n",
        "from datetime import datetime\n",
        "from copy import deepcopy\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from skimage.transform import resize\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zrpyr30jZFyG"
      },
      "source": [
        "## Understanding the environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2PntGfn6ZFyH"
      },
      "source": [
        "In the following cell, we initialise our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qAm4ujNNZFyK",
        "colab": {}
      },
      "source": [
        "env = gym.make('BreakoutDeterministic-v4')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iUAVLFo2Awt-",
        "colab": {}
      },
      "source": [
        "def find_max_lifes(env):\n",
        "    env.reset()\n",
        "    _, _, _, info = env.step(0)\n",
        "    return info['ale.lives']\n",
        "\n",
        "def check_live(life, cur_life):\n",
        "    if life > cur_life:\n",
        "        return True\n",
        "    else:\n",
        "        return False\n",
        "\n",
        "def get_frame(X):\n",
        "    x = np.uint8(resize(rgb2gray(X), (HEIGHT, WIDTH), mode='reflect') * 255)\n",
        "    return x\n",
        "\n",
        "def get_init_state(history, s):\n",
        "    for i in range(HISTORY_SIZE):\n",
        "        history[i, :, :] = get_frame(s)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VeA5rHqwZFyQ",
        "outputId": "6a9aa02a-cdb1-4511-e704-39e7cd52a6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "number_lives = find_max_lifes(env)\n",
        "state_size = env.observation_space.shape\n",
        "action_size = 3\n",
        "rewards, episodes = [], []\n",
        "print(number_lives)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "z_AE780Lo3iW"
      },
      "source": [
        "## Mount Google Drive to store / load the model\n",
        "You need to create a Temp directory in your Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JF_wH9aHFM0d",
        "outputId": "3c23c004-74b7-4d75-c527-138ea95763b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "\"\"\"\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_name = 'DQN.ckpt'\n",
        "model_path = F\"/content/drive/My Drive/Temp/{model_name}\" \n",
        "\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom google.colab import drive\\ndrive.mount(\\'/content/drive\\')\\n\\nmodel_name = \\'DQN.ckpt\\'\\nmodel_path = F\"/content/drive/My Drive/Temp/{model_name}\" \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "42OBfiVuZFyT"
      },
      "source": [
        "## Creating a DQN Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "BfOJgANGZFyU"
      },
      "source": [
        "Here we create a DQN Agent. \n",
        "\n",
        "__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n",
        "\n",
        "__Frame__ : Number of frames processed in total.\n",
        "\n",
        "__Memory Size__ : The current size of the replay memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uQimEJYaBcf2",
        "colab": {}
      },
      "source": [
        "EPISODES = 500000\n",
        "HEIGHT = 84\n",
        "WIDTH = 84\n",
        "HISTORY_SIZE = 4\n",
        "learning_rate = 0.0001\n",
        "evaluation_reward_length = 100\n",
        "Memory_capacity = 1000000\n",
        "render_breakout = True\n",
        "batch_size = 32\n",
        "Update_target_network_frequency = 1000\n",
        "train_frame = 100000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "i8i8szcQBj4u",
        "colab": {}
      },
      "source": [
        "class DQN(nn.Module):\n",
        "    def __init__(self, action_size):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 32, kernel_size=8, stride=4)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(64)\n",
        "        self.fc = nn.Linear(3136, 512)\n",
        "        self.head = nn.Linear(512, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = F.relu(self.fc(x.view(x.size(0), -1)))\n",
        "        return self.head(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NuJnxRbDA7dt",
        "colab": {}
      },
      "source": [
        "class Agent():\n",
        "    def __init__(self, action_size):\n",
        "        self.load_model = False\n",
        "\n",
        "        self.action_size = action_size\n",
        "\n",
        "        # These are hyper parameters for the DQN\n",
        "        self.discount_factor = 0.99\n",
        "        self.epsilon = 1.0\n",
        "        self.epsilon_min = 0.01\n",
        "        self.explore_step = 1000000\n",
        "        self.epsilon_decay = (self.epsilon - self.epsilon_min) / self.explore_step\n",
        "\n",
        "        # Generate the memory\n",
        "        self.memory = ReplayMemory()\n",
        "\n",
        "        # Create the policy net and the target net\n",
        "        self.policy_net = DQN(action_size)\n",
        "        self.policy_net.to(device)\n",
        "        self.target_net = DQN(action_size)\n",
        "        self.target_net.to(device)\n",
        "\n",
        "        self.optimizer = optim.Adam(params=self.policy_net.parameters(), lr=learning_rate)\n",
        "\n",
        "        # initialize target net\n",
        "        self.update_target_net()\n",
        "\n",
        "        if self.load_model:\n",
        "            self.policy_net.load_state_dict(torch.load(model_path))\n",
        "            self.policy_net.to(device)\n",
        "            #self.policy_net = torch.load('save_model/breakout_dqn')\n",
        "            \n",
        "    def save_model(self):\n",
        "        torch.save(self.policy_net.state_dict(), model_path)\n",
        "\n",
        "    # after some time interval update the target net to be same with policy net\n",
        "    def update_target_net(self):\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "        \n",
        "    \"\"\"Get action using policy net using epsilon-greedy policy\"\"\"\n",
        "    def get_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            # Choose a random action\n",
        "            return np.random.randint(0, action_size)\n",
        "                     \n",
        "        else:\n",
        "            z = self.policy_net(torch.from_numpy(state).unsqueeze(0).to(device))\n",
        "            return z.max(1)[1].item()\n",
        "            \n",
        "    # pick samples randomly from replay memory (with batch_size)\n",
        "    def train_policy_net(self, frame):\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon -= self.epsilon_decay\n",
        "\n",
        "        mini_batch = self.memory.sample_mini_batch(frame)\n",
        "        mini_batch = np.array(mini_batch).transpose()\n",
        "\n",
        "        history = np.stack(mini_batch[0], axis=0)\n",
        "        states = np.float32(history[:, :4, :, :]) / 255.\n",
        "        actions = list(mini_batch[1])\n",
        "        rewards = list(mini_batch[2])\n",
        "        next_states = np.float32(history[:, 1:, :, :]) / 255.\n",
        "        dones = mini_batch[3] # checks if the game is over\n",
        "\n",
        "\n",
        "        # Compute Q(s_t, a) - Q of the current state\n",
        "        curr_state = self.policy_net(torch.from_numpy(states).to(device))\n",
        "        q_value = curr_state.gather(1, torch.LongTensor(actions).to(device).reshape(32, 1))\n",
        "        q_value = q_value.reshape(32)\n",
        "      \n",
        "        # Compute Q function of next state\n",
        "        next_state = self.target_net(torch.from_numpy(next_states).to(device)).detach()\n",
        "\n",
        "        # Find maximum Q-value of action at next state from target net\n",
        "        max_q_values = next_state.max(1)[0]\n",
        "        \n",
        "        # Compute expected Q value\n",
        "        discount = self.discount_factor\n",
        "        d_new = dones.astype(np.int)\n",
        "        expected_q_value = torch.Tensor(rewards).to(device) + discount * max_q_values * (1 - torch.from_numpy(d_new).to(device))\n",
        "        \n",
        "        ## Huber Loss\n",
        "        loss = F.smooth_l1_loss(q_value, expected_q_value.data)\n",
        "        \n",
        "        # Optimize the model \n",
        "        \n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3dDxqQf0BTSZ",
        "colab": {}
      },
      "source": [
        "class ReplayMemory(object):\n",
        "    def __init__(self):\n",
        "        self.memory = deque(maxlen=Memory_capacity)\n",
        "    \n",
        "    def push(self, history, action, reward, done):\n",
        "        self.memory.append((history, action, reward, done))\n",
        "\n",
        "    def sample_mini_batch(self, frame):\n",
        "        mini_batch = []\n",
        "        if frame >= Memory_capacity:\n",
        "            sample_range = Memory_capacity\n",
        "        else:\n",
        "            sample_range = frame\n",
        "\n",
        "        # history size\n",
        "        sample_range -= (HISTORY_SIZE + 1)\n",
        "\n",
        "        idx_sample = random.sample(range(sample_range), batch_size)\n",
        "        for i in idx_sample:\n",
        "            sample = []\n",
        "            for j in range(HISTORY_SIZE + 1):\n",
        "                sample.append(self.memory[i + j])\n",
        "\n",
        "            sample = np.array(sample)\n",
        "            mini_batch.append((np.stack(sample[:, 0], axis=0), sample[3, 1], sample[3, 2], sample[3, 3]))\n",
        "\n",
        "        return mini_batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kz9j9uNeZFyV",
        "colab": {}
      },
      "source": [
        "agent = Agent(action_size)\n",
        "evaluation_reward = deque(maxlen=evaluation_reward_length)\n",
        "frame = 0\n",
        "memory_size = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xGjJJ6KDZFyc"
      },
      "source": [
        "### Main Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qgRHw04EZFyd",
        "scrolled": true,
        "outputId": "b63f4659-1e32-4a8a-c938-54fb514c7077",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for e in range(EPISODES):\n",
        "    done = False\n",
        "    score = 0\n",
        "\n",
        "    history = np.zeros([5, 84, 84], dtype=np.uint8)\n",
        "    step = 0\n",
        "    state = env.reset()\n",
        "    life = number_lives\n",
        "\n",
        "    get_init_state(history, state)\n",
        "\n",
        "    while not done:\n",
        "        step += 1\n",
        "        frame += 1\n",
        "\n",
        "        # Select and perform an action\n",
        "        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n",
        "\n",
        "        next_state, reward, done, info = env.step(action + 1)\n",
        "\n",
        "        frame_next_state = get_frame(next_state)\n",
        "        history[4, :, :] = frame_next_state\n",
        "        terminal_state = check_live(life, info['ale.lives'])\n",
        "        terminal_state = 1 if terminal_state else 0\n",
        "\n",
        "        life = info['ale.lives']\n",
        "        r = np.clip(reward, -1, 1)\n",
        "\n",
        "        # Store the transition in memory \n",
        "        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n",
        "        # Start training after random sample generation\n",
        "        if(frame >= train_frame):\n",
        "            agent.train_policy_net(frame)\n",
        "            # Update the target network\n",
        "            if(frame % Update_target_network_frequency)== 0:\n",
        "                agent.update_target_net()\n",
        "        score += reward\n",
        "        history[:4, :, :] = history[1:, :, :]\n",
        "\n",
        "        \n",
        "        if frame % 50000 == 0:\n",
        "            print('now time : ', datetime.now())\n",
        "            rewards.append(np.mean(evaluation_reward))\n",
        "            episodes.append(e)\n",
        "            #pylab.plot(episodes, rewards, 'b')\n",
        "            \n",
        "            \n",
        "        if done:\n",
        "            evaluation_reward.append(score)\n",
        "            # every episode, plot the play time\n",
        "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
        "                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n",
        "                  \"    evaluation reward:\", np.mean(evaluation_reward))\n",
        "\n",
        "                \n",
        "    # if the mean of scores of last 100 episode is bigger than 10\n",
        "    # stop training\n",
        "    if done and np.mean(evaluation_reward) > 10:\n",
        "        print(\"Training Done ...\")\n",
        "        agent.save_model()\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "episode: 0   score: 2.0   memory length: 200   epsilon: 1.0    steps: 200     evaluation reward: 2.0\n",
            "episode: 1   score: 3.0   memory length: 463   epsilon: 1.0    steps: 263     evaluation reward: 2.5\n",
            "episode: 2   score: 0.0   memory length: 593   epsilon: 1.0    steps: 130     evaluation reward: 1.6666666666666667\n",
            "episode: 3   score: 0.0   memory length: 718   epsilon: 1.0    steps: 125     evaluation reward: 1.25\n",
            "episode: 4   score: 0.0   memory length: 851   epsilon: 1.0    steps: 133     evaluation reward: 1.0\n",
            "episode: 5   score: 3.0   memory length: 1128   epsilon: 1.0    steps: 277     evaluation reward: 1.3333333333333333\n",
            "episode: 6   score: 1.0   memory length: 1284   epsilon: 1.0    steps: 156     evaluation reward: 1.2857142857142858\n",
            "episode: 7   score: 2.0   memory length: 1509   epsilon: 1.0    steps: 225     evaluation reward: 1.375\n",
            "episode: 8   score: 0.0   memory length: 1633   epsilon: 1.0    steps: 124     evaluation reward: 1.2222222222222223\n",
            "episode: 9   score: 1.0   memory length: 1794   epsilon: 1.0    steps: 161     evaluation reward: 1.2\n",
            "episode: 10   score: 1.0   memory length: 1974   epsilon: 1.0    steps: 180     evaluation reward: 1.1818181818181819\n",
            "episode: 11   score: 1.0   memory length: 2146   epsilon: 1.0    steps: 172     evaluation reward: 1.1666666666666667\n",
            "episode: 12   score: 0.0   memory length: 2273   epsilon: 1.0    steps: 127     evaluation reward: 1.0769230769230769\n",
            "episode: 13   score: 1.0   memory length: 2428   epsilon: 1.0    steps: 155     evaluation reward: 1.0714285714285714\n",
            "episode: 14   score: 0.0   memory length: 2572   epsilon: 1.0    steps: 144     evaluation reward: 1.0\n",
            "episode: 15   score: 1.0   memory length: 2759   epsilon: 1.0    steps: 187     evaluation reward: 1.0\n",
            "episode: 16   score: 0.0   memory length: 2885   epsilon: 1.0    steps: 126     evaluation reward: 0.9411764705882353\n",
            "episode: 17   score: 1.0   memory length: 3063   epsilon: 1.0    steps: 178     evaluation reward: 0.9444444444444444\n",
            "episode: 18   score: 1.0   memory length: 3248   epsilon: 1.0    steps: 185     evaluation reward: 0.9473684210526315\n",
            "episode: 19   score: 2.0   memory length: 3449   epsilon: 1.0    steps: 201     evaluation reward: 1.0\n",
            "episode: 20   score: 0.0   memory length: 3595   epsilon: 1.0    steps: 146     evaluation reward: 0.9523809523809523\n",
            "episode: 21   score: 2.0   memory length: 3810   epsilon: 1.0    steps: 215     evaluation reward: 1.0\n",
            "episode: 22   score: 1.0   memory length: 3968   epsilon: 1.0    steps: 158     evaluation reward: 1.0\n",
            "episode: 23   score: 2.0   memory length: 4189   epsilon: 1.0    steps: 221     evaluation reward: 1.0416666666666667\n",
            "episode: 24   score: 2.0   memory length: 4415   epsilon: 1.0    steps: 226     evaluation reward: 1.08\n",
            "episode: 25   score: 0.0   memory length: 4547   epsilon: 1.0    steps: 132     evaluation reward: 1.0384615384615385\n",
            "episode: 26   score: 4.0   memory length: 4853   epsilon: 1.0    steps: 306     evaluation reward: 1.1481481481481481\n",
            "episode: 27   score: 1.0   memory length: 5012   epsilon: 1.0    steps: 159     evaluation reward: 1.1428571428571428\n",
            "episode: 28   score: 2.0   memory length: 5223   epsilon: 1.0    steps: 211     evaluation reward: 1.1724137931034482\n",
            "episode: 29   score: 0.0   memory length: 5365   epsilon: 1.0    steps: 142     evaluation reward: 1.1333333333333333\n",
            "episode: 30   score: 2.0   memory length: 5565   epsilon: 1.0    steps: 200     evaluation reward: 1.1612903225806452\n",
            "episode: 31   score: 0.0   memory length: 5700   epsilon: 1.0    steps: 135     evaluation reward: 1.125\n",
            "episode: 32   score: 2.0   memory length: 5917   epsilon: 1.0    steps: 217     evaluation reward: 1.1515151515151516\n",
            "episode: 33   score: 1.0   memory length: 6099   epsilon: 1.0    steps: 182     evaluation reward: 1.1470588235294117\n",
            "episode: 34   score: 1.0   memory length: 6278   epsilon: 1.0    steps: 179     evaluation reward: 1.1428571428571428\n",
            "episode: 35   score: 1.0   memory length: 6441   epsilon: 1.0    steps: 163     evaluation reward: 1.1388888888888888\n",
            "episode: 36   score: 3.0   memory length: 6668   epsilon: 1.0    steps: 227     evaluation reward: 1.1891891891891893\n",
            "episode: 37   score: 0.0   memory length: 6800   epsilon: 1.0    steps: 132     evaluation reward: 1.1578947368421053\n",
            "episode: 38   score: 0.0   memory length: 6940   epsilon: 1.0    steps: 140     evaluation reward: 1.1282051282051282\n",
            "episode: 39   score: 2.0   memory length: 7142   epsilon: 1.0    steps: 202     evaluation reward: 1.15\n",
            "episode: 40   score: 2.0   memory length: 7369   epsilon: 1.0    steps: 227     evaluation reward: 1.170731707317073\n",
            "episode: 41   score: 0.0   memory length: 7498   epsilon: 1.0    steps: 129     evaluation reward: 1.1428571428571428\n",
            "episode: 42   score: 2.0   memory length: 7704   epsilon: 1.0    steps: 206     evaluation reward: 1.1627906976744187\n",
            "episode: 43   score: 0.0   memory length: 7835   epsilon: 1.0    steps: 131     evaluation reward: 1.1363636363636365\n",
            "episode: 44   score: 2.0   memory length: 8066   epsilon: 1.0    steps: 231     evaluation reward: 1.1555555555555554\n",
            "episode: 45   score: 1.0   memory length: 8247   epsilon: 1.0    steps: 181     evaluation reward: 1.1521739130434783\n",
            "episode: 46   score: 3.0   memory length: 8500   epsilon: 1.0    steps: 253     evaluation reward: 1.1914893617021276\n",
            "episode: 47   score: 2.0   memory length: 8713   epsilon: 1.0    steps: 213     evaluation reward: 1.2083333333333333\n",
            "episode: 48   score: 0.0   memory length: 8837   epsilon: 1.0    steps: 124     evaluation reward: 1.183673469387755\n",
            "episode: 49   score: 0.0   memory length: 8965   epsilon: 1.0    steps: 128     evaluation reward: 1.16\n",
            "episode: 50   score: 0.0   memory length: 9105   epsilon: 1.0    steps: 140     evaluation reward: 1.1372549019607843\n",
            "episode: 51   score: 0.0   memory length: 9236   epsilon: 1.0    steps: 131     evaluation reward: 1.1153846153846154\n",
            "episode: 52   score: 4.0   memory length: 9526   epsilon: 1.0    steps: 290     evaluation reward: 1.169811320754717\n",
            "episode: 53   score: 1.0   memory length: 9713   epsilon: 1.0    steps: 187     evaluation reward: 1.1666666666666667\n",
            "episode: 54   score: 1.0   memory length: 9892   epsilon: 1.0    steps: 179     evaluation reward: 1.1636363636363636\n",
            "episode: 55   score: 0.0   memory length: 10022   epsilon: 1.0    steps: 130     evaluation reward: 1.1428571428571428\n",
            "episode: 56   score: 0.0   memory length: 10147   epsilon: 1.0    steps: 125     evaluation reward: 1.1228070175438596\n",
            "episode: 57   score: 1.0   memory length: 10335   epsilon: 1.0    steps: 188     evaluation reward: 1.1206896551724137\n",
            "episode: 58   score: 1.0   memory length: 10491   epsilon: 1.0    steps: 156     evaluation reward: 1.11864406779661\n",
            "episode: 59   score: 2.0   memory length: 10703   epsilon: 1.0    steps: 212     evaluation reward: 1.1333333333333333\n",
            "episode: 60   score: 1.0   memory length: 10868   epsilon: 1.0    steps: 165     evaluation reward: 1.1311475409836065\n",
            "episode: 61   score: 1.0   memory length: 11044   epsilon: 1.0    steps: 176     evaluation reward: 1.1290322580645162\n",
            "episode: 62   score: 0.0   memory length: 11191   epsilon: 1.0    steps: 147     evaluation reward: 1.1111111111111112\n",
            "episode: 63   score: 2.0   memory length: 11384   epsilon: 1.0    steps: 193     evaluation reward: 1.125\n",
            "episode: 64   score: 3.0   memory length: 11634   epsilon: 1.0    steps: 250     evaluation reward: 1.1538461538461537\n",
            "episode: 65   score: 1.0   memory length: 11837   epsilon: 1.0    steps: 203     evaluation reward: 1.1515151515151516\n",
            "episode: 66   score: 0.0   memory length: 11961   epsilon: 1.0    steps: 124     evaluation reward: 1.1343283582089552\n",
            "episode: 67   score: 0.0   memory length: 12100   epsilon: 1.0    steps: 139     evaluation reward: 1.1176470588235294\n",
            "episode: 68   score: 0.0   memory length: 12241   epsilon: 1.0    steps: 141     evaluation reward: 1.1014492753623188\n",
            "episode: 69   score: 0.0   memory length: 12375   epsilon: 1.0    steps: 134     evaluation reward: 1.0857142857142856\n",
            "episode: 70   score: 1.0   memory length: 12531   epsilon: 1.0    steps: 156     evaluation reward: 1.0845070422535212\n",
            "episode: 71   score: 2.0   memory length: 12757   epsilon: 1.0    steps: 226     evaluation reward: 1.0972222222222223\n",
            "episode: 72   score: 0.0   memory length: 12882   epsilon: 1.0    steps: 125     evaluation reward: 1.082191780821918\n",
            "episode: 73   score: 3.0   memory length: 13130   epsilon: 1.0    steps: 248     evaluation reward: 1.1081081081081081\n",
            "episode: 74   score: 0.0   memory length: 13256   epsilon: 1.0    steps: 126     evaluation reward: 1.0933333333333333\n",
            "episode: 75   score: 4.0   memory length: 13569   epsilon: 1.0    steps: 313     evaluation reward: 1.131578947368421\n",
            "episode: 76   score: 1.0   memory length: 13739   epsilon: 1.0    steps: 170     evaluation reward: 1.12987012987013\n",
            "episode: 77   score: 2.0   memory length: 13939   epsilon: 1.0    steps: 200     evaluation reward: 1.141025641025641\n",
            "episode: 78   score: 0.0   memory length: 14071   epsilon: 1.0    steps: 132     evaluation reward: 1.1265822784810127\n",
            "episode: 79   score: 1.0   memory length: 14228   epsilon: 1.0    steps: 157     evaluation reward: 1.125\n",
            "episode: 80   score: 0.0   memory length: 14355   epsilon: 1.0    steps: 127     evaluation reward: 1.1111111111111112\n",
            "episode: 81   score: 1.0   memory length: 14535   epsilon: 1.0    steps: 180     evaluation reward: 1.1097560975609757\n",
            "episode: 82   score: 3.0   memory length: 14797   epsilon: 1.0    steps: 262     evaluation reward: 1.1325301204819278\n",
            "episode: 83   score: 2.0   memory length: 15024   epsilon: 1.0    steps: 227     evaluation reward: 1.1428571428571428\n",
            "episode: 84   score: 1.0   memory length: 15178   epsilon: 1.0    steps: 154     evaluation reward: 1.1411764705882352\n",
            "episode: 85   score: 2.0   memory length: 15382   epsilon: 1.0    steps: 204     evaluation reward: 1.1511627906976745\n",
            "episode: 86   score: 1.0   memory length: 15533   epsilon: 1.0    steps: 151     evaluation reward: 1.1494252873563218\n",
            "episode: 87   score: 0.0   memory length: 15661   epsilon: 1.0    steps: 128     evaluation reward: 1.1363636363636365\n",
            "episode: 88   score: 2.0   memory length: 15850   epsilon: 1.0    steps: 189     evaluation reward: 1.146067415730337\n",
            "episode: 89   score: 5.0   memory length: 16144   epsilon: 1.0    steps: 294     evaluation reward: 1.1888888888888889\n",
            "episode: 90   score: 1.0   memory length: 16327   epsilon: 1.0    steps: 183     evaluation reward: 1.1868131868131868\n",
            "episode: 91   score: 1.0   memory length: 16500   epsilon: 1.0    steps: 173     evaluation reward: 1.184782608695652\n",
            "episode: 92   score: 2.0   memory length: 16688   epsilon: 1.0    steps: 188     evaluation reward: 1.1935483870967742\n",
            "episode: 93   score: 0.0   memory length: 16818   epsilon: 1.0    steps: 130     evaluation reward: 1.1808510638297873\n",
            "episode: 94   score: 3.0   memory length: 17069   epsilon: 1.0    steps: 251     evaluation reward: 1.2\n",
            "episode: 95   score: 1.0   memory length: 17247   epsilon: 1.0    steps: 178     evaluation reward: 1.1979166666666667\n",
            "episode: 96   score: 3.0   memory length: 17482   epsilon: 1.0    steps: 235     evaluation reward: 1.2164948453608246\n",
            "episode: 97   score: 1.0   memory length: 17641   epsilon: 1.0    steps: 159     evaluation reward: 1.2142857142857142\n",
            "episode: 98   score: 0.0   memory length: 17766   epsilon: 1.0    steps: 125     evaluation reward: 1.202020202020202\n",
            "episode: 99   score: 1.0   memory length: 17927   epsilon: 1.0    steps: 161     evaluation reward: 1.2\n",
            "episode: 100   score: 2.0   memory length: 18111   epsilon: 1.0    steps: 184     evaluation reward: 1.2\n",
            "episode: 101   score: 1.0   memory length: 18267   epsilon: 1.0    steps: 156     evaluation reward: 1.18\n",
            "episode: 102   score: 2.0   memory length: 18478   epsilon: 1.0    steps: 211     evaluation reward: 1.2\n",
            "episode: 103   score: 2.0   memory length: 18683   epsilon: 1.0    steps: 205     evaluation reward: 1.22\n",
            "episode: 104   score: 3.0   memory length: 18936   epsilon: 1.0    steps: 253     evaluation reward: 1.25\n",
            "episode: 105   score: 1.0   memory length: 19114   epsilon: 1.0    steps: 178     evaluation reward: 1.23\n",
            "episode: 106   score: 3.0   memory length: 19356   epsilon: 1.0    steps: 242     evaluation reward: 1.25\n",
            "episode: 107   score: 1.0   memory length: 19524   epsilon: 1.0    steps: 168     evaluation reward: 1.24\n",
            "episode: 108   score: 1.0   memory length: 19712   epsilon: 1.0    steps: 188     evaluation reward: 1.25\n",
            "episode: 109   score: 4.0   memory length: 19994   epsilon: 1.0    steps: 282     evaluation reward: 1.28\n",
            "episode: 110   score: 1.0   memory length: 20172   epsilon: 1.0    steps: 178     evaluation reward: 1.28\n",
            "episode: 111   score: 0.0   memory length: 20297   epsilon: 1.0    steps: 125     evaluation reward: 1.27\n",
            "episode: 112   score: 0.0   memory length: 20429   epsilon: 1.0    steps: 132     evaluation reward: 1.27\n",
            "episode: 113   score: 1.0   memory length: 20605   epsilon: 1.0    steps: 176     evaluation reward: 1.27\n",
            "episode: 114   score: 0.0   memory length: 20729   epsilon: 1.0    steps: 124     evaluation reward: 1.27\n",
            "episode: 115   score: 2.0   memory length: 20921   epsilon: 1.0    steps: 192     evaluation reward: 1.28\n",
            "episode: 116   score: 2.0   memory length: 21126   epsilon: 1.0    steps: 205     evaluation reward: 1.3\n",
            "episode: 117   score: 3.0   memory length: 21398   epsilon: 1.0    steps: 272     evaluation reward: 1.32\n",
            "episode: 118   score: 1.0   memory length: 21556   epsilon: 1.0    steps: 158     evaluation reward: 1.32\n",
            "episode: 119   score: 2.0   memory length: 21783   epsilon: 1.0    steps: 227     evaluation reward: 1.32\n",
            "episode: 120   score: 0.0   memory length: 21917   epsilon: 1.0    steps: 134     evaluation reward: 1.32\n",
            "episode: 121   score: 2.0   memory length: 22105   epsilon: 1.0    steps: 188     evaluation reward: 1.32\n",
            "episode: 122   score: 1.0   memory length: 22261   epsilon: 1.0    steps: 156     evaluation reward: 1.32\n",
            "episode: 123   score: 1.0   memory length: 22437   epsilon: 1.0    steps: 176     evaluation reward: 1.31\n",
            "episode: 124   score: 1.0   memory length: 22610   epsilon: 1.0    steps: 173     evaluation reward: 1.3\n",
            "episode: 125   score: 3.0   memory length: 22858   epsilon: 1.0    steps: 248     evaluation reward: 1.33\n",
            "episode: 126   score: 1.0   memory length: 23031   epsilon: 1.0    steps: 173     evaluation reward: 1.3\n",
            "episode: 127   score: 2.0   memory length: 23262   epsilon: 1.0    steps: 231     evaluation reward: 1.31\n",
            "episode: 128   score: 0.0   memory length: 23391   epsilon: 1.0    steps: 129     evaluation reward: 1.29\n",
            "episode: 129   score: 1.0   memory length: 23572   epsilon: 1.0    steps: 181     evaluation reward: 1.3\n",
            "episode: 130   score: 0.0   memory length: 23697   epsilon: 1.0    steps: 125     evaluation reward: 1.28\n",
            "episode: 131   score: 7.0   memory length: 24111   epsilon: 1.0    steps: 414     evaluation reward: 1.35\n",
            "episode: 132   score: 0.0   memory length: 24242   epsilon: 1.0    steps: 131     evaluation reward: 1.33\n",
            "episode: 133   score: 1.0   memory length: 24399   epsilon: 1.0    steps: 157     evaluation reward: 1.33\n",
            "episode: 134   score: 3.0   memory length: 24649   epsilon: 1.0    steps: 250     evaluation reward: 1.35\n",
            "episode: 135   score: 0.0   memory length: 24773   epsilon: 1.0    steps: 124     evaluation reward: 1.34\n",
            "episode: 136   score: 4.0   memory length: 25059   epsilon: 1.0    steps: 286     evaluation reward: 1.35\n",
            "episode: 137   score: 0.0   memory length: 25185   epsilon: 1.0    steps: 126     evaluation reward: 1.35\n",
            "episode: 138   score: 1.0   memory length: 25341   epsilon: 1.0    steps: 156     evaluation reward: 1.36\n",
            "episode: 139   score: 1.0   memory length: 25512   epsilon: 1.0    steps: 171     evaluation reward: 1.35\n",
            "episode: 140   score: 1.0   memory length: 25667   epsilon: 1.0    steps: 155     evaluation reward: 1.34\n",
            "episode: 141   score: 1.0   memory length: 25832   epsilon: 1.0    steps: 165     evaluation reward: 1.35\n",
            "episode: 142   score: 1.0   memory length: 25984   epsilon: 1.0    steps: 152     evaluation reward: 1.34\n",
            "episode: 143   score: 2.0   memory length: 26192   epsilon: 1.0    steps: 208     evaluation reward: 1.36\n",
            "episode: 144   score: 2.0   memory length: 26418   epsilon: 1.0    steps: 226     evaluation reward: 1.36\n",
            "episode: 145   score: 0.0   memory length: 26558   epsilon: 1.0    steps: 140     evaluation reward: 1.35\n",
            "episode: 146   score: 1.0   memory length: 26735   epsilon: 1.0    steps: 177     evaluation reward: 1.33\n",
            "episode: 147   score: 1.0   memory length: 26891   epsilon: 1.0    steps: 156     evaluation reward: 1.32\n",
            "episode: 148   score: 1.0   memory length: 27051   epsilon: 1.0    steps: 160     evaluation reward: 1.33\n",
            "episode: 149   score: 1.0   memory length: 27231   epsilon: 1.0    steps: 180     evaluation reward: 1.34\n",
            "episode: 150   score: 2.0   memory length: 27434   epsilon: 1.0    steps: 203     evaluation reward: 1.36\n",
            "episode: 151   score: 0.0   memory length: 27567   epsilon: 1.0    steps: 133     evaluation reward: 1.36\n",
            "episode: 152   score: 0.0   memory length: 27700   epsilon: 1.0    steps: 133     evaluation reward: 1.32\n",
            "episode: 153   score: 1.0   memory length: 27861   epsilon: 1.0    steps: 161     evaluation reward: 1.32\n",
            "episode: 154   score: 2.0   memory length: 28093   epsilon: 1.0    steps: 232     evaluation reward: 1.33\n",
            "episode: 155   score: 1.0   memory length: 28246   epsilon: 1.0    steps: 153     evaluation reward: 1.34\n",
            "episode: 156   score: 0.0   memory length: 28374   epsilon: 1.0    steps: 128     evaluation reward: 1.34\n",
            "episode: 157   score: 0.0   memory length: 28508   epsilon: 1.0    steps: 134     evaluation reward: 1.33\n",
            "episode: 158   score: 0.0   memory length: 28637   epsilon: 1.0    steps: 129     evaluation reward: 1.32\n",
            "episode: 159   score: 1.0   memory length: 28813   epsilon: 1.0    steps: 176     evaluation reward: 1.31\n",
            "episode: 160   score: 2.0   memory length: 28999   epsilon: 1.0    steps: 186     evaluation reward: 1.32\n",
            "episode: 161   score: 1.0   memory length: 29173   epsilon: 1.0    steps: 174     evaluation reward: 1.32\n",
            "episode: 162   score: 0.0   memory length: 29303   epsilon: 1.0    steps: 130     evaluation reward: 1.32\n",
            "episode: 163   score: 1.0   memory length: 29474   epsilon: 1.0    steps: 171     evaluation reward: 1.31\n",
            "episode: 164   score: 0.0   memory length: 29606   epsilon: 1.0    steps: 132     evaluation reward: 1.28\n",
            "episode: 165   score: 0.0   memory length: 29744   epsilon: 1.0    steps: 138     evaluation reward: 1.27\n",
            "episode: 166   score: 0.0   memory length: 29872   epsilon: 1.0    steps: 128     evaluation reward: 1.27\n",
            "episode: 167   score: 0.0   memory length: 29996   epsilon: 1.0    steps: 124     evaluation reward: 1.27\n",
            "episode: 168   score: 2.0   memory length: 30222   epsilon: 1.0    steps: 226     evaluation reward: 1.29\n",
            "episode: 169   score: 2.0   memory length: 30428   epsilon: 1.0    steps: 206     evaluation reward: 1.31\n",
            "episode: 170   score: 4.0   memory length: 30741   epsilon: 1.0    steps: 313     evaluation reward: 1.34\n",
            "episode: 171   score: 1.0   memory length: 30891   epsilon: 1.0    steps: 150     evaluation reward: 1.33\n",
            "episode: 172   score: 0.0   memory length: 31024   epsilon: 1.0    steps: 133     evaluation reward: 1.33\n",
            "episode: 173   score: 0.0   memory length: 31152   epsilon: 1.0    steps: 128     evaluation reward: 1.3\n",
            "episode: 174   score: 1.0   memory length: 31305   epsilon: 1.0    steps: 153     evaluation reward: 1.31\n",
            "episode: 175   score: 0.0   memory length: 31438   epsilon: 1.0    steps: 133     evaluation reward: 1.27\n",
            "episode: 176   score: 2.0   memory length: 31646   epsilon: 1.0    steps: 208     evaluation reward: 1.28\n",
            "episode: 177   score: 1.0   memory length: 31812   epsilon: 1.0    steps: 166     evaluation reward: 1.27\n",
            "episode: 178   score: 0.0   memory length: 31941   epsilon: 1.0    steps: 129     evaluation reward: 1.27\n",
            "episode: 179   score: 1.0   memory length: 32125   epsilon: 1.0    steps: 184     evaluation reward: 1.27\n",
            "episode: 180   score: 1.0   memory length: 32301   epsilon: 1.0    steps: 176     evaluation reward: 1.28\n",
            "episode: 181   score: 3.0   memory length: 32521   epsilon: 1.0    steps: 220     evaluation reward: 1.3\n",
            "episode: 182   score: 1.0   memory length: 32693   epsilon: 1.0    steps: 172     evaluation reward: 1.28\n",
            "episode: 183   score: 1.0   memory length: 32868   epsilon: 1.0    steps: 175     evaluation reward: 1.27\n",
            "episode: 184   score: 2.0   memory length: 33072   epsilon: 1.0    steps: 204     evaluation reward: 1.28\n",
            "episode: 185   score: 0.0   memory length: 33203   epsilon: 1.0    steps: 131     evaluation reward: 1.26\n",
            "episode: 186   score: 3.0   memory length: 33444   epsilon: 1.0    steps: 241     evaluation reward: 1.28\n",
            "episode: 187   score: 0.0   memory length: 33571   epsilon: 1.0    steps: 127     evaluation reward: 1.28\n",
            "episode: 188   score: 1.0   memory length: 33750   epsilon: 1.0    steps: 179     evaluation reward: 1.27\n",
            "episode: 189   score: 0.0   memory length: 33879   epsilon: 1.0    steps: 129     evaluation reward: 1.22\n",
            "episode: 190   score: 1.0   memory length: 34057   epsilon: 1.0    steps: 178     evaluation reward: 1.22\n",
            "episode: 191   score: 2.0   memory length: 34289   epsilon: 1.0    steps: 232     evaluation reward: 1.23\n",
            "episode: 192   score: 2.0   memory length: 34490   epsilon: 1.0    steps: 201     evaluation reward: 1.23\n",
            "episode: 193   score: 4.0   memory length: 34785   epsilon: 1.0    steps: 295     evaluation reward: 1.27\n",
            "episode: 194   score: 1.0   memory length: 34968   epsilon: 1.0    steps: 183     evaluation reward: 1.25\n",
            "episode: 195   score: 0.0   memory length: 35094   epsilon: 1.0    steps: 126     evaluation reward: 1.24\n",
            "episode: 196   score: 2.0   memory length: 35300   epsilon: 1.0    steps: 206     evaluation reward: 1.23\n",
            "episode: 197   score: 0.0   memory length: 35432   epsilon: 1.0    steps: 132     evaluation reward: 1.22\n",
            "episode: 198   score: 0.0   memory length: 35566   epsilon: 1.0    steps: 134     evaluation reward: 1.22\n",
            "episode: 199   score: 3.0   memory length: 35838   epsilon: 1.0    steps: 272     evaluation reward: 1.24\n",
            "episode: 200   score: 1.0   memory length: 36020   epsilon: 1.0    steps: 182     evaluation reward: 1.23\n",
            "episode: 201   score: 2.0   memory length: 36248   epsilon: 1.0    steps: 228     evaluation reward: 1.24\n",
            "episode: 202   score: 1.0   memory length: 36403   epsilon: 1.0    steps: 155     evaluation reward: 1.23\n",
            "episode: 203   score: 1.0   memory length: 36564   epsilon: 1.0    steps: 161     evaluation reward: 1.22\n",
            "episode: 204   score: 3.0   memory length: 36812   epsilon: 1.0    steps: 248     evaluation reward: 1.22\n",
            "episode: 205   score: 2.0   memory length: 37018   epsilon: 1.0    steps: 206     evaluation reward: 1.23\n",
            "episode: 206   score: 1.0   memory length: 37191   epsilon: 1.0    steps: 173     evaluation reward: 1.21\n",
            "episode: 207   score: 1.0   memory length: 37361   epsilon: 1.0    steps: 170     evaluation reward: 1.21\n",
            "episode: 208   score: 0.0   memory length: 37493   epsilon: 1.0    steps: 132     evaluation reward: 1.2\n",
            "episode: 209   score: 1.0   memory length: 37663   epsilon: 1.0    steps: 170     evaluation reward: 1.17\n",
            "episode: 210   score: 1.0   memory length: 37839   epsilon: 1.0    steps: 176     evaluation reward: 1.17\n",
            "episode: 211   score: 1.0   memory length: 38024   epsilon: 1.0    steps: 185     evaluation reward: 1.18\n",
            "episode: 212   score: 1.0   memory length: 38178   epsilon: 1.0    steps: 154     evaluation reward: 1.19\n",
            "episode: 213   score: 0.0   memory length: 38305   epsilon: 1.0    steps: 127     evaluation reward: 1.18\n",
            "episode: 214   score: 1.0   memory length: 38465   epsilon: 1.0    steps: 160     evaluation reward: 1.19\n",
            "episode: 215   score: 2.0   memory length: 38682   epsilon: 1.0    steps: 217     evaluation reward: 1.19\n",
            "episode: 216   score: 3.0   memory length: 38936   epsilon: 1.0    steps: 254     evaluation reward: 1.2\n",
            "episode: 217   score: 3.0   memory length: 39200   epsilon: 1.0    steps: 264     evaluation reward: 1.2\n",
            "episode: 218   score: 0.0   memory length: 39335   epsilon: 1.0    steps: 135     evaluation reward: 1.19\n",
            "episode: 219   score: 0.0   memory length: 39469   epsilon: 1.0    steps: 134     evaluation reward: 1.17\n",
            "episode: 220   score: 1.0   memory length: 39639   epsilon: 1.0    steps: 170     evaluation reward: 1.18\n",
            "episode: 221   score: 1.0   memory length: 39803   epsilon: 1.0    steps: 164     evaluation reward: 1.17\n",
            "episode: 222   score: 1.0   memory length: 39983   epsilon: 1.0    steps: 180     evaluation reward: 1.17\n",
            "episode: 223   score: 2.0   memory length: 40208   epsilon: 1.0    steps: 225     evaluation reward: 1.18\n",
            "episode: 224   score: 3.0   memory length: 40463   epsilon: 1.0    steps: 255     evaluation reward: 1.2\n",
            "episode: 225   score: 1.0   memory length: 40621   epsilon: 1.0    steps: 158     evaluation reward: 1.18\n",
            "episode: 226   score: 0.0   memory length: 40768   epsilon: 1.0    steps: 147     evaluation reward: 1.17\n",
            "episode: 227   score: 1.0   memory length: 40943   epsilon: 1.0    steps: 175     evaluation reward: 1.16\n",
            "episode: 228   score: 3.0   memory length: 41187   epsilon: 1.0    steps: 244     evaluation reward: 1.19\n",
            "episode: 229   score: 0.0   memory length: 41323   epsilon: 1.0    steps: 136     evaluation reward: 1.18\n",
            "episode: 230   score: 2.0   memory length: 41548   epsilon: 1.0    steps: 225     evaluation reward: 1.2\n",
            "episode: 231   score: 2.0   memory length: 41757   epsilon: 1.0    steps: 209     evaluation reward: 1.15\n",
            "episode: 232   score: 4.0   memory length: 42032   epsilon: 1.0    steps: 275     evaluation reward: 1.19\n",
            "episode: 233   score: 0.0   memory length: 42163   epsilon: 1.0    steps: 131     evaluation reward: 1.18\n",
            "episode: 234   score: 2.0   memory length: 42361   epsilon: 1.0    steps: 198     evaluation reward: 1.17\n",
            "episode: 235   score: 1.0   memory length: 42545   epsilon: 1.0    steps: 184     evaluation reward: 1.18\n",
            "episode: 236   score: 1.0   memory length: 42704   epsilon: 1.0    steps: 159     evaluation reward: 1.15\n",
            "episode: 237   score: 1.0   memory length: 42883   epsilon: 1.0    steps: 179     evaluation reward: 1.16\n",
            "episode: 238   score: 1.0   memory length: 43072   epsilon: 1.0    steps: 189     evaluation reward: 1.16\n",
            "episode: 239   score: 1.0   memory length: 43256   epsilon: 1.0    steps: 184     evaluation reward: 1.16\n",
            "episode: 240   score: 2.0   memory length: 43471   epsilon: 1.0    steps: 215     evaluation reward: 1.17\n",
            "episode: 241   score: 0.0   memory length: 43611   epsilon: 1.0    steps: 140     evaluation reward: 1.16\n",
            "episode: 242   score: 1.0   memory length: 43791   epsilon: 1.0    steps: 180     evaluation reward: 1.16\n",
            "episode: 243   score: 1.0   memory length: 43945   epsilon: 1.0    steps: 154     evaluation reward: 1.15\n",
            "episode: 244   score: 2.0   memory length: 44132   epsilon: 1.0    steps: 187     evaluation reward: 1.15\n",
            "episode: 245   score: 1.0   memory length: 44302   epsilon: 1.0    steps: 170     evaluation reward: 1.16\n",
            "episode: 246   score: 2.0   memory length: 44502   epsilon: 1.0    steps: 200     evaluation reward: 1.17\n",
            "episode: 247   score: 3.0   memory length: 44759   epsilon: 1.0    steps: 257     evaluation reward: 1.19\n",
            "episode: 248   score: 1.0   memory length: 44931   epsilon: 1.0    steps: 172     evaluation reward: 1.19\n",
            "episode: 249   score: 3.0   memory length: 45163   epsilon: 1.0    steps: 232     evaluation reward: 1.21\n",
            "episode: 250   score: 0.0   memory length: 45287   epsilon: 1.0    steps: 124     evaluation reward: 1.19\n",
            "episode: 251   score: 0.0   memory length: 45418   epsilon: 1.0    steps: 131     evaluation reward: 1.19\n",
            "episode: 252   score: 0.0   memory length: 45544   epsilon: 1.0    steps: 126     evaluation reward: 1.19\n",
            "episode: 253   score: 2.0   memory length: 45768   epsilon: 1.0    steps: 224     evaluation reward: 1.2\n",
            "episode: 254   score: 0.0   memory length: 45899   epsilon: 1.0    steps: 131     evaluation reward: 1.18\n",
            "episode: 255   score: 1.0   memory length: 46058   epsilon: 1.0    steps: 159     evaluation reward: 1.18\n",
            "episode: 256   score: 0.0   memory length: 46182   epsilon: 1.0    steps: 124     evaluation reward: 1.18\n",
            "episode: 257   score: 0.0   memory length: 46321   epsilon: 1.0    steps: 139     evaluation reward: 1.18\n",
            "episode: 258   score: 2.0   memory length: 46545   epsilon: 1.0    steps: 224     evaluation reward: 1.2\n",
            "episode: 259   score: 3.0   memory length: 46795   epsilon: 1.0    steps: 250     evaluation reward: 1.22\n",
            "episode: 260   score: 3.0   memory length: 47028   epsilon: 1.0    steps: 233     evaluation reward: 1.23\n",
            "episode: 261   score: 2.0   memory length: 47242   epsilon: 1.0    steps: 214     evaluation reward: 1.24\n",
            "episode: 262   score: 1.0   memory length: 47412   epsilon: 1.0    steps: 170     evaluation reward: 1.25\n",
            "episode: 263   score: 0.0   memory length: 47539   epsilon: 1.0    steps: 127     evaluation reward: 1.24\n",
            "episode: 264   score: 0.0   memory length: 47671   epsilon: 1.0    steps: 132     evaluation reward: 1.24\n",
            "episode: 265   score: 2.0   memory length: 47862   epsilon: 1.0    steps: 191     evaluation reward: 1.26\n",
            "episode: 266   score: 1.0   memory length: 48038   epsilon: 1.0    steps: 176     evaluation reward: 1.27\n",
            "episode: 267   score: 1.0   memory length: 48209   epsilon: 1.0    steps: 171     evaluation reward: 1.28\n",
            "episode: 268   score: 3.0   memory length: 48493   epsilon: 1.0    steps: 284     evaluation reward: 1.29\n",
            "episode: 269   score: 2.0   memory length: 48678   epsilon: 1.0    steps: 185     evaluation reward: 1.29\n",
            "episode: 270   score: 1.0   memory length: 48855   epsilon: 1.0    steps: 177     evaluation reward: 1.26\n",
            "episode: 271   score: 4.0   memory length: 49151   epsilon: 1.0    steps: 296     evaluation reward: 1.29\n",
            "episode: 272   score: 2.0   memory length: 49364   epsilon: 1.0    steps: 213     evaluation reward: 1.31\n",
            "episode: 273   score: 2.0   memory length: 49600   epsilon: 1.0    steps: 236     evaluation reward: 1.33\n",
            "episode: 274   score: 0.0   memory length: 49740   epsilon: 1.0    steps: 140     evaluation reward: 1.32\n",
            "episode: 275   score: 0.0   memory length: 49867   epsilon: 1.0    steps: 127     evaluation reward: 1.32\n",
            "now time :  2019-12-12 17:35:36.858126\n",
            "episode: 276   score: 0.0   memory length: 50003   epsilon: 1.0    steps: 136     evaluation reward: 1.3\n",
            "episode: 277   score: 0.0   memory length: 50132   epsilon: 1.0    steps: 129     evaluation reward: 1.29\n",
            "episode: 278   score: 1.0   memory length: 50306   epsilon: 1.0    steps: 174     evaluation reward: 1.3\n",
            "episode: 279   score: 1.0   memory length: 50476   epsilon: 1.0    steps: 170     evaluation reward: 1.3\n",
            "episode: 280   score: 0.0   memory length: 50611   epsilon: 1.0    steps: 135     evaluation reward: 1.29\n",
            "episode: 281   score: 2.0   memory length: 50845   epsilon: 1.0    steps: 234     evaluation reward: 1.28\n",
            "episode: 282   score: 2.0   memory length: 51057   epsilon: 1.0    steps: 212     evaluation reward: 1.29\n",
            "episode: 283   score: 0.0   memory length: 51191   epsilon: 1.0    steps: 134     evaluation reward: 1.28\n",
            "episode: 284   score: 0.0   memory length: 51321   epsilon: 1.0    steps: 130     evaluation reward: 1.26\n",
            "episode: 285   score: 1.0   memory length: 51483   epsilon: 1.0    steps: 162     evaluation reward: 1.27\n",
            "episode: 286   score: 1.0   memory length: 51637   epsilon: 1.0    steps: 154     evaluation reward: 1.25\n",
            "episode: 287   score: 1.0   memory length: 51813   epsilon: 1.0    steps: 176     evaluation reward: 1.26\n",
            "episode: 288   score: 0.0   memory length: 51940   epsilon: 1.0    steps: 127     evaluation reward: 1.25\n",
            "episode: 289   score: 0.0   memory length: 52076   epsilon: 1.0    steps: 136     evaluation reward: 1.25\n",
            "episode: 290   score: 0.0   memory length: 52220   epsilon: 1.0    steps: 144     evaluation reward: 1.24\n",
            "episode: 291   score: 2.0   memory length: 52442   epsilon: 1.0    steps: 222     evaluation reward: 1.24\n",
            "episode: 292   score: 1.0   memory length: 52605   epsilon: 1.0    steps: 163     evaluation reward: 1.23\n",
            "episode: 293   score: 3.0   memory length: 52859   epsilon: 1.0    steps: 254     evaluation reward: 1.22\n",
            "episode: 294   score: 0.0   memory length: 52992   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
            "episode: 295   score: 2.0   memory length: 53211   epsilon: 1.0    steps: 219     evaluation reward: 1.23\n",
            "episode: 296   score: 2.0   memory length: 53415   epsilon: 1.0    steps: 204     evaluation reward: 1.23\n",
            "episode: 297   score: 3.0   memory length: 53666   epsilon: 1.0    steps: 251     evaluation reward: 1.26\n",
            "episode: 298   score: 2.0   memory length: 53876   epsilon: 1.0    steps: 210     evaluation reward: 1.28\n",
            "episode: 299   score: 0.0   memory length: 54009   epsilon: 1.0    steps: 133     evaluation reward: 1.25\n",
            "episode: 300   score: 0.0   memory length: 54139   epsilon: 1.0    steps: 130     evaluation reward: 1.24\n",
            "episode: 301   score: 0.0   memory length: 54269   epsilon: 1.0    steps: 130     evaluation reward: 1.22\n",
            "episode: 302   score: 0.0   memory length: 54402   epsilon: 1.0    steps: 133     evaluation reward: 1.21\n",
            "episode: 303   score: 1.0   memory length: 54575   epsilon: 1.0    steps: 173     evaluation reward: 1.21\n",
            "episode: 304   score: 0.0   memory length: 54718   epsilon: 1.0    steps: 143     evaluation reward: 1.18\n",
            "episode: 305   score: 1.0   memory length: 54894   epsilon: 1.0    steps: 176     evaluation reward: 1.17\n",
            "episode: 306   score: 0.0   memory length: 55017   epsilon: 1.0    steps: 123     evaluation reward: 1.16\n",
            "episode: 307   score: 0.0   memory length: 55141   epsilon: 1.0    steps: 124     evaluation reward: 1.15\n",
            "episode: 308   score: 0.0   memory length: 55278   epsilon: 1.0    steps: 137     evaluation reward: 1.15\n",
            "episode: 309   score: 2.0   memory length: 55487   epsilon: 1.0    steps: 209     evaluation reward: 1.16\n",
            "episode: 310   score: 2.0   memory length: 55701   epsilon: 1.0    steps: 214     evaluation reward: 1.17\n",
            "episode: 311   score: 0.0   memory length: 55844   epsilon: 1.0    steps: 143     evaluation reward: 1.16\n",
            "episode: 312   score: 0.0   memory length: 55974   epsilon: 1.0    steps: 130     evaluation reward: 1.15\n",
            "episode: 313   score: 0.0   memory length: 56109   epsilon: 1.0    steps: 135     evaluation reward: 1.15\n",
            "episode: 314   score: 0.0   memory length: 56247   epsilon: 1.0    steps: 138     evaluation reward: 1.14\n",
            "episode: 315   score: 0.0   memory length: 56384   epsilon: 1.0    steps: 137     evaluation reward: 1.12\n",
            "episode: 316   score: 1.0   memory length: 56543   epsilon: 1.0    steps: 159     evaluation reward: 1.1\n",
            "episode: 317   score: 0.0   memory length: 56669   epsilon: 1.0    steps: 126     evaluation reward: 1.07\n",
            "episode: 318   score: 2.0   memory length: 56908   epsilon: 1.0    steps: 239     evaluation reward: 1.09\n",
            "episode: 319   score: 1.0   memory length: 57079   epsilon: 1.0    steps: 171     evaluation reward: 1.1\n",
            "episode: 320   score: 1.0   memory length: 57238   epsilon: 1.0    steps: 159     evaluation reward: 1.1\n",
            "episode: 321   score: 2.0   memory length: 57443   epsilon: 1.0    steps: 205     evaluation reward: 1.11\n",
            "episode: 322   score: 2.0   memory length: 57655   epsilon: 1.0    steps: 212     evaluation reward: 1.12\n",
            "episode: 323   score: 0.0   memory length: 57783   epsilon: 1.0    steps: 128     evaluation reward: 1.1\n",
            "episode: 324   score: 0.0   memory length: 57907   epsilon: 1.0    steps: 124     evaluation reward: 1.07\n",
            "episode: 325   score: 1.0   memory length: 58081   epsilon: 1.0    steps: 174     evaluation reward: 1.07\n",
            "episode: 326   score: 2.0   memory length: 58287   epsilon: 1.0    steps: 206     evaluation reward: 1.09\n",
            "episode: 327   score: 3.0   memory length: 58522   epsilon: 1.0    steps: 235     evaluation reward: 1.11\n",
            "episode: 328   score: 0.0   memory length: 58652   epsilon: 1.0    steps: 130     evaluation reward: 1.08\n",
            "episode: 329   score: 1.0   memory length: 58831   epsilon: 1.0    steps: 179     evaluation reward: 1.09\n",
            "episode: 330   score: 0.0   memory length: 58960   epsilon: 1.0    steps: 129     evaluation reward: 1.07\n",
            "episode: 331   score: 2.0   memory length: 59161   epsilon: 1.0    steps: 201     evaluation reward: 1.07\n",
            "episode: 332   score: 1.0   memory length: 59315   epsilon: 1.0    steps: 154     evaluation reward: 1.04\n",
            "episode: 333   score: 3.0   memory length: 59564   epsilon: 1.0    steps: 249     evaluation reward: 1.07\n",
            "episode: 334   score: 1.0   memory length: 59742   epsilon: 1.0    steps: 178     evaluation reward: 1.06\n",
            "episode: 335   score: 1.0   memory length: 59909   epsilon: 1.0    steps: 167     evaluation reward: 1.06\n",
            "episode: 336   score: 0.0   memory length: 60044   epsilon: 1.0    steps: 135     evaluation reward: 1.05\n",
            "episode: 337   score: 1.0   memory length: 60215   epsilon: 1.0    steps: 171     evaluation reward: 1.05\n",
            "episode: 338   score: 2.0   memory length: 60439   epsilon: 1.0    steps: 224     evaluation reward: 1.06\n",
            "episode: 339   score: 1.0   memory length: 60598   epsilon: 1.0    steps: 159     evaluation reward: 1.06\n",
            "episode: 340   score: 1.0   memory length: 60762   epsilon: 1.0    steps: 164     evaluation reward: 1.05\n",
            "episode: 341   score: 1.0   memory length: 60931   epsilon: 1.0    steps: 169     evaluation reward: 1.06\n",
            "episode: 342   score: 1.0   memory length: 61095   epsilon: 1.0    steps: 164     evaluation reward: 1.06\n",
            "episode: 343   score: 0.0   memory length: 61221   epsilon: 1.0    steps: 126     evaluation reward: 1.05\n",
            "episode: 344   score: 2.0   memory length: 61441   epsilon: 1.0    steps: 220     evaluation reward: 1.05\n",
            "episode: 345   score: 2.0   memory length: 61645   epsilon: 1.0    steps: 204     evaluation reward: 1.06\n",
            "episode: 346   score: 3.0   memory length: 61896   epsilon: 1.0    steps: 251     evaluation reward: 1.07\n",
            "episode: 347   score: 1.0   memory length: 62062   epsilon: 1.0    steps: 166     evaluation reward: 1.05\n",
            "episode: 348   score: 1.0   memory length: 62233   epsilon: 1.0    steps: 171     evaluation reward: 1.05\n",
            "episode: 349   score: 1.0   memory length: 62393   epsilon: 1.0    steps: 160     evaluation reward: 1.03\n",
            "episode: 350   score: 1.0   memory length: 62574   epsilon: 1.0    steps: 181     evaluation reward: 1.04\n",
            "episode: 351   score: 2.0   memory length: 62775   epsilon: 1.0    steps: 201     evaluation reward: 1.06\n",
            "episode: 352   score: 3.0   memory length: 63016   epsilon: 1.0    steps: 241     evaluation reward: 1.09\n",
            "episode: 353   score: 0.0   memory length: 63141   epsilon: 1.0    steps: 125     evaluation reward: 1.07\n",
            "episode: 354   score: 0.0   memory length: 63268   epsilon: 1.0    steps: 127     evaluation reward: 1.07\n",
            "episode: 355   score: 1.0   memory length: 63421   epsilon: 1.0    steps: 153     evaluation reward: 1.07\n",
            "episode: 356   score: 0.0   memory length: 63554   epsilon: 1.0    steps: 133     evaluation reward: 1.07\n",
            "episode: 357   score: 1.0   memory length: 63732   epsilon: 1.0    steps: 178     evaluation reward: 1.08\n",
            "episode: 358   score: 0.0   memory length: 63862   epsilon: 1.0    steps: 130     evaluation reward: 1.06\n",
            "episode: 359   score: 1.0   memory length: 64019   epsilon: 1.0    steps: 157     evaluation reward: 1.04\n",
            "episode: 360   score: 0.0   memory length: 64158   epsilon: 1.0    steps: 139     evaluation reward: 1.01\n",
            "episode: 361   score: 0.0   memory length: 64289   epsilon: 1.0    steps: 131     evaluation reward: 0.99\n",
            "episode: 362   score: 5.0   memory length: 64583   epsilon: 1.0    steps: 294     evaluation reward: 1.03\n",
            "episode: 363   score: 0.0   memory length: 64715   epsilon: 1.0    steps: 132     evaluation reward: 1.03\n",
            "episode: 364   score: 0.0   memory length: 64840   epsilon: 1.0    steps: 125     evaluation reward: 1.03\n",
            "episode: 365   score: 3.0   memory length: 65088   epsilon: 1.0    steps: 248     evaluation reward: 1.04\n",
            "episode: 366   score: 0.0   memory length: 65219   epsilon: 1.0    steps: 131     evaluation reward: 1.03\n",
            "episode: 367   score: 1.0   memory length: 65396   epsilon: 1.0    steps: 177     evaluation reward: 1.03\n",
            "episode: 368   score: 4.0   memory length: 65693   epsilon: 1.0    steps: 297     evaluation reward: 1.04\n",
            "episode: 369   score: 1.0   memory length: 65867   epsilon: 1.0    steps: 174     evaluation reward: 1.03\n",
            "episode: 370   score: 3.0   memory length: 66106   epsilon: 1.0    steps: 239     evaluation reward: 1.05\n",
            "episode: 371   score: 2.0   memory length: 66325   epsilon: 1.0    steps: 219     evaluation reward: 1.03\n",
            "episode: 372   score: 1.0   memory length: 66494   epsilon: 1.0    steps: 169     evaluation reward: 1.02\n",
            "episode: 373   score: 1.0   memory length: 66678   epsilon: 1.0    steps: 184     evaluation reward: 1.01\n",
            "episode: 374   score: 3.0   memory length: 66913   epsilon: 1.0    steps: 235     evaluation reward: 1.04\n",
            "episode: 375   score: 3.0   memory length: 67145   epsilon: 1.0    steps: 232     evaluation reward: 1.07\n",
            "episode: 376   score: 0.0   memory length: 67276   epsilon: 1.0    steps: 131     evaluation reward: 1.07\n",
            "episode: 377   score: 0.0   memory length: 67408   epsilon: 1.0    steps: 132     evaluation reward: 1.07\n",
            "episode: 378   score: 0.0   memory length: 67539   epsilon: 1.0    steps: 131     evaluation reward: 1.06\n",
            "episode: 379   score: 4.0   memory length: 67828   epsilon: 1.0    steps: 289     evaluation reward: 1.09\n",
            "episode: 380   score: 1.0   memory length: 68006   epsilon: 1.0    steps: 178     evaluation reward: 1.1\n",
            "episode: 381   score: 1.0   memory length: 68182   epsilon: 1.0    steps: 176     evaluation reward: 1.09\n",
            "episode: 382   score: 2.0   memory length: 68368   epsilon: 1.0    steps: 186     evaluation reward: 1.09\n",
            "episode: 383   score: 2.0   memory length: 68585   epsilon: 1.0    steps: 217     evaluation reward: 1.11\n",
            "episode: 384   score: 2.0   memory length: 68812   epsilon: 1.0    steps: 227     evaluation reward: 1.13\n",
            "episode: 385   score: 1.0   memory length: 68974   epsilon: 1.0    steps: 162     evaluation reward: 1.13\n",
            "episode: 386   score: 2.0   memory length: 69180   epsilon: 1.0    steps: 206     evaluation reward: 1.14\n",
            "episode: 387   score: 0.0   memory length: 69315   epsilon: 1.0    steps: 135     evaluation reward: 1.13\n",
            "episode: 388   score: 0.0   memory length: 69453   epsilon: 1.0    steps: 138     evaluation reward: 1.13\n",
            "episode: 389   score: 1.0   memory length: 69628   epsilon: 1.0    steps: 175     evaluation reward: 1.14\n",
            "episode: 390   score: 4.0   memory length: 69915   epsilon: 1.0    steps: 287     evaluation reward: 1.18\n",
            "episode: 391   score: 2.0   memory length: 70142   epsilon: 1.0    steps: 227     evaluation reward: 1.18\n",
            "episode: 392   score: 2.0   memory length: 70370   epsilon: 1.0    steps: 228     evaluation reward: 1.19\n",
            "episode: 393   score: 2.0   memory length: 70575   epsilon: 1.0    steps: 205     evaluation reward: 1.18\n",
            "episode: 394   score: 2.0   memory length: 70781   epsilon: 1.0    steps: 206     evaluation reward: 1.2\n",
            "episode: 395   score: 3.0   memory length: 71053   epsilon: 1.0    steps: 272     evaluation reward: 1.21\n",
            "episode: 396   score: 1.0   memory length: 71210   epsilon: 1.0    steps: 157     evaluation reward: 1.2\n",
            "episode: 397   score: 0.0   memory length: 71343   epsilon: 1.0    steps: 133     evaluation reward: 1.17\n",
            "episode: 398   score: 0.0   memory length: 71476   epsilon: 1.0    steps: 133     evaluation reward: 1.15\n",
            "episode: 399   score: 0.0   memory length: 71611   epsilon: 1.0    steps: 135     evaluation reward: 1.15\n",
            "episode: 400   score: 2.0   memory length: 71806   epsilon: 1.0    steps: 195     evaluation reward: 1.17\n",
            "episode: 401   score: 0.0   memory length: 71939   epsilon: 1.0    steps: 133     evaluation reward: 1.17\n",
            "episode: 402   score: 1.0   memory length: 72107   epsilon: 1.0    steps: 168     evaluation reward: 1.18\n",
            "episode: 403   score: 2.0   memory length: 72313   epsilon: 1.0    steps: 206     evaluation reward: 1.19\n",
            "episode: 404   score: 1.0   memory length: 72486   epsilon: 1.0    steps: 173     evaluation reward: 1.2\n",
            "episode: 405   score: 4.0   memory length: 72783   epsilon: 1.0    steps: 297     evaluation reward: 1.23\n",
            "episode: 406   score: 1.0   memory length: 72955   epsilon: 1.0    steps: 172     evaluation reward: 1.24\n",
            "episode: 407   score: 0.0   memory length: 73090   epsilon: 1.0    steps: 135     evaluation reward: 1.24\n",
            "episode: 408   score: 2.0   memory length: 73297   epsilon: 1.0    steps: 207     evaluation reward: 1.26\n",
            "episode: 409   score: 0.0   memory length: 73426   epsilon: 1.0    steps: 129     evaluation reward: 1.24\n",
            "episode: 410   score: 2.0   memory length: 73652   epsilon: 1.0    steps: 226     evaluation reward: 1.24\n",
            "episode: 411   score: 0.0   memory length: 73785   epsilon: 1.0    steps: 133     evaluation reward: 1.24\n",
            "episode: 412   score: 1.0   memory length: 73972   epsilon: 1.0    steps: 187     evaluation reward: 1.25\n",
            "episode: 413   score: 3.0   memory length: 74233   epsilon: 1.0    steps: 261     evaluation reward: 1.28\n",
            "episode: 414   score: 2.0   memory length: 74449   epsilon: 1.0    steps: 216     evaluation reward: 1.3\n",
            "episode: 415   score: 2.0   memory length: 74649   epsilon: 1.0    steps: 200     evaluation reward: 1.32\n",
            "episode: 416   score: 2.0   memory length: 74875   epsilon: 1.0    steps: 226     evaluation reward: 1.33\n",
            "episode: 417   score: 1.0   memory length: 75055   epsilon: 1.0    steps: 180     evaluation reward: 1.34\n",
            "episode: 418   score: 1.0   memory length: 75229   epsilon: 1.0    steps: 174     evaluation reward: 1.33\n",
            "episode: 419   score: 0.0   memory length: 75364   epsilon: 1.0    steps: 135     evaluation reward: 1.32\n",
            "episode: 420   score: 1.0   memory length: 75528   epsilon: 1.0    steps: 164     evaluation reward: 1.32\n",
            "episode: 421   score: 1.0   memory length: 75718   epsilon: 1.0    steps: 190     evaluation reward: 1.31\n",
            "episode: 422   score: 0.0   memory length: 75844   epsilon: 1.0    steps: 126     evaluation reward: 1.29\n",
            "episode: 423   score: 2.0   memory length: 76057   epsilon: 1.0    steps: 213     evaluation reward: 1.31\n",
            "episode: 424   score: 2.0   memory length: 76251   epsilon: 1.0    steps: 194     evaluation reward: 1.33\n",
            "episode: 425   score: 2.0   memory length: 76457   epsilon: 1.0    steps: 206     evaluation reward: 1.34\n",
            "episode: 426   score: 0.0   memory length: 76586   epsilon: 1.0    steps: 129     evaluation reward: 1.32\n",
            "episode: 427   score: 2.0   memory length: 76802   epsilon: 1.0    steps: 216     evaluation reward: 1.31\n",
            "episode: 428   score: 1.0   memory length: 76975   epsilon: 1.0    steps: 173     evaluation reward: 1.32\n",
            "episode: 429   score: 2.0   memory length: 77200   epsilon: 1.0    steps: 225     evaluation reward: 1.33\n",
            "episode: 430   score: 2.0   memory length: 77424   epsilon: 1.0    steps: 224     evaluation reward: 1.35\n",
            "episode: 431   score: 2.0   memory length: 77631   epsilon: 1.0    steps: 207     evaluation reward: 1.35\n",
            "episode: 432   score: 0.0   memory length: 77757   epsilon: 1.0    steps: 126     evaluation reward: 1.34\n",
            "episode: 433   score: 1.0   memory length: 77916   epsilon: 1.0    steps: 159     evaluation reward: 1.32\n",
            "episode: 434   score: 1.0   memory length: 78096   epsilon: 1.0    steps: 180     evaluation reward: 1.32\n",
            "episode: 435   score: 0.0   memory length: 78225   epsilon: 1.0    steps: 129     evaluation reward: 1.31\n",
            "episode: 436   score: 1.0   memory length: 78383   epsilon: 1.0    steps: 158     evaluation reward: 1.32\n",
            "episode: 437   score: 2.0   memory length: 78590   epsilon: 1.0    steps: 207     evaluation reward: 1.33\n",
            "episode: 438   score: 1.0   memory length: 78748   epsilon: 1.0    steps: 158     evaluation reward: 1.32\n",
            "episode: 439   score: 3.0   memory length: 78991   epsilon: 1.0    steps: 243     evaluation reward: 1.34\n",
            "episode: 440   score: 1.0   memory length: 79161   epsilon: 1.0    steps: 170     evaluation reward: 1.34\n",
            "episode: 441   score: 0.0   memory length: 79289   epsilon: 1.0    steps: 128     evaluation reward: 1.33\n",
            "episode: 442   score: 0.0   memory length: 79422   epsilon: 1.0    steps: 133     evaluation reward: 1.32\n",
            "episode: 443   score: 0.0   memory length: 79555   epsilon: 1.0    steps: 133     evaluation reward: 1.32\n",
            "episode: 444   score: 1.0   memory length: 79744   epsilon: 1.0    steps: 189     evaluation reward: 1.31\n",
            "episode: 445   score: 1.0   memory length: 79918   epsilon: 1.0    steps: 174     evaluation reward: 1.3\n",
            "episode: 446   score: 0.0   memory length: 80050   epsilon: 1.0    steps: 132     evaluation reward: 1.27\n",
            "episode: 447   score: 0.0   memory length: 80191   epsilon: 1.0    steps: 141     evaluation reward: 1.26\n",
            "episode: 448   score: 2.0   memory length: 80395   epsilon: 1.0    steps: 204     evaluation reward: 1.27\n",
            "episode: 449   score: 2.0   memory length: 80584   epsilon: 1.0    steps: 189     evaluation reward: 1.28\n",
            "episode: 450   score: 2.0   memory length: 80786   epsilon: 1.0    steps: 202     evaluation reward: 1.29\n",
            "episode: 451   score: 1.0   memory length: 80963   epsilon: 1.0    steps: 177     evaluation reward: 1.28\n",
            "episode: 452   score: 2.0   memory length: 81173   epsilon: 1.0    steps: 210     evaluation reward: 1.27\n",
            "episode: 453   score: 1.0   memory length: 81347   epsilon: 1.0    steps: 174     evaluation reward: 1.28\n",
            "episode: 454   score: 2.0   memory length: 81535   epsilon: 1.0    steps: 188     evaluation reward: 1.3\n",
            "episode: 455   score: 6.0   memory length: 81866   epsilon: 1.0    steps: 331     evaluation reward: 1.35\n",
            "episode: 456   score: 2.0   memory length: 82082   epsilon: 1.0    steps: 216     evaluation reward: 1.37\n",
            "episode: 457   score: 1.0   memory length: 82261   epsilon: 1.0    steps: 179     evaluation reward: 1.37\n",
            "episode: 458   score: 1.0   memory length: 82418   epsilon: 1.0    steps: 157     evaluation reward: 1.38\n",
            "episode: 459   score: 2.0   memory length: 82638   epsilon: 1.0    steps: 220     evaluation reward: 1.39\n",
            "episode: 460   score: 1.0   memory length: 82797   epsilon: 1.0    steps: 159     evaluation reward: 1.4\n",
            "episode: 461   score: 0.0   memory length: 82925   epsilon: 1.0    steps: 128     evaluation reward: 1.4\n",
            "episode: 462   score: 1.0   memory length: 83103   epsilon: 1.0    steps: 178     evaluation reward: 1.36\n",
            "episode: 463   score: 3.0   memory length: 83337   epsilon: 1.0    steps: 234     evaluation reward: 1.39\n",
            "episode: 464   score: 2.0   memory length: 83544   epsilon: 1.0    steps: 207     evaluation reward: 1.41\n",
            "episode: 465   score: 1.0   memory length: 83721   epsilon: 1.0    steps: 177     evaluation reward: 1.39\n",
            "episode: 466   score: 1.0   memory length: 83902   epsilon: 1.0    steps: 181     evaluation reward: 1.4\n",
            "episode: 467   score: 2.0   memory length: 84122   epsilon: 1.0    steps: 220     evaluation reward: 1.41\n",
            "episode: 468   score: 1.0   memory length: 84288   epsilon: 1.0    steps: 166     evaluation reward: 1.38\n",
            "episode: 469   score: 1.0   memory length: 84468   epsilon: 1.0    steps: 180     evaluation reward: 1.38\n",
            "episode: 470   score: 3.0   memory length: 84700   epsilon: 1.0    steps: 232     evaluation reward: 1.38\n",
            "episode: 471   score: 2.0   memory length: 84882   epsilon: 1.0    steps: 182     evaluation reward: 1.38\n",
            "episode: 472   score: 2.0   memory length: 85083   epsilon: 1.0    steps: 201     evaluation reward: 1.39\n",
            "episode: 473   score: 0.0   memory length: 85211   epsilon: 1.0    steps: 128     evaluation reward: 1.38\n",
            "episode: 474   score: 1.0   memory length: 85387   epsilon: 1.0    steps: 176     evaluation reward: 1.36\n",
            "episode: 475   score: 1.0   memory length: 85542   epsilon: 1.0    steps: 155     evaluation reward: 1.34\n",
            "episode: 476   score: 1.0   memory length: 85710   epsilon: 1.0    steps: 168     evaluation reward: 1.35\n",
            "episode: 477   score: 2.0   memory length: 85904   epsilon: 1.0    steps: 194     evaluation reward: 1.37\n",
            "episode: 478   score: 2.0   memory length: 86106   epsilon: 1.0    steps: 202     evaluation reward: 1.39\n",
            "episode: 479   score: 0.0   memory length: 86234   epsilon: 1.0    steps: 128     evaluation reward: 1.35\n",
            "episode: 480   score: 2.0   memory length: 86421   epsilon: 1.0    steps: 187     evaluation reward: 1.36\n",
            "episode: 481   score: 1.0   memory length: 86578   epsilon: 1.0    steps: 157     evaluation reward: 1.36\n",
            "episode: 482   score: 1.0   memory length: 86750   epsilon: 1.0    steps: 172     evaluation reward: 1.35\n",
            "episode: 483   score: 2.0   memory length: 86947   epsilon: 1.0    steps: 197     evaluation reward: 1.35\n",
            "episode: 484   score: 2.0   memory length: 87171   epsilon: 1.0    steps: 224     evaluation reward: 1.35\n",
            "episode: 485   score: 1.0   memory length: 87342   epsilon: 1.0    steps: 171     evaluation reward: 1.35\n",
            "episode: 486   score: 1.0   memory length: 87518   epsilon: 1.0    steps: 176     evaluation reward: 1.34\n",
            "episode: 487   score: 0.0   memory length: 87641   epsilon: 1.0    steps: 123     evaluation reward: 1.34\n",
            "episode: 488   score: 7.0   memory length: 88091   epsilon: 1.0    steps: 450     evaluation reward: 1.41\n",
            "episode: 489   score: 0.0   memory length: 88224   epsilon: 1.0    steps: 133     evaluation reward: 1.4\n",
            "episode: 490   score: 1.0   memory length: 88409   epsilon: 1.0    steps: 185     evaluation reward: 1.37\n",
            "episode: 491   score: 1.0   memory length: 88572   epsilon: 1.0    steps: 163     evaluation reward: 1.36\n",
            "episode: 492   score: 2.0   memory length: 88780   epsilon: 1.0    steps: 208     evaluation reward: 1.36\n",
            "episode: 493   score: 2.0   memory length: 89004   epsilon: 1.0    steps: 224     evaluation reward: 1.36\n",
            "episode: 494   score: 2.0   memory length: 89229   epsilon: 1.0    steps: 225     evaluation reward: 1.36\n",
            "episode: 495   score: 2.0   memory length: 89436   epsilon: 1.0    steps: 207     evaluation reward: 1.35\n",
            "episode: 496   score: 0.0   memory length: 89570   epsilon: 1.0    steps: 134     evaluation reward: 1.34\n",
            "episode: 497   score: 1.0   memory length: 89749   epsilon: 1.0    steps: 179     evaluation reward: 1.35\n",
            "episode: 498   score: 1.0   memory length: 89909   epsilon: 1.0    steps: 160     evaluation reward: 1.36\n",
            "episode: 499   score: 2.0   memory length: 90102   epsilon: 1.0    steps: 193     evaluation reward: 1.38\n",
            "episode: 500   score: 0.0   memory length: 90241   epsilon: 1.0    steps: 139     evaluation reward: 1.36\n",
            "episode: 501   score: 2.0   memory length: 90467   epsilon: 1.0    steps: 226     evaluation reward: 1.38\n",
            "episode: 502   score: 0.0   memory length: 90598   epsilon: 1.0    steps: 131     evaluation reward: 1.37\n",
            "episode: 503   score: 1.0   memory length: 90768   epsilon: 1.0    steps: 170     evaluation reward: 1.36\n",
            "episode: 504   score: 3.0   memory length: 90993   epsilon: 1.0    steps: 225     evaluation reward: 1.38\n",
            "episode: 505   score: 3.0   memory length: 91261   epsilon: 1.0    steps: 268     evaluation reward: 1.37\n",
            "episode: 506   score: 1.0   memory length: 91438   epsilon: 1.0    steps: 177     evaluation reward: 1.37\n",
            "episode: 507   score: 5.0   memory length: 91723   epsilon: 1.0    steps: 285     evaluation reward: 1.42\n",
            "episode: 508   score: 1.0   memory length: 91897   epsilon: 1.0    steps: 174     evaluation reward: 1.41\n",
            "episode: 509   score: 4.0   memory length: 92151   epsilon: 1.0    steps: 254     evaluation reward: 1.45\n",
            "episode: 510   score: 1.0   memory length: 92304   epsilon: 1.0    steps: 153     evaluation reward: 1.44\n",
            "episode: 511   score: 1.0   memory length: 92476   epsilon: 1.0    steps: 172     evaluation reward: 1.45\n",
            "episode: 512   score: 5.0   memory length: 92799   epsilon: 1.0    steps: 323     evaluation reward: 1.49\n",
            "episode: 513   score: 1.0   memory length: 92964   epsilon: 1.0    steps: 165     evaluation reward: 1.47\n",
            "episode: 514   score: 2.0   memory length: 93152   epsilon: 1.0    steps: 188     evaluation reward: 1.47\n",
            "episode: 515   score: 1.0   memory length: 93324   epsilon: 1.0    steps: 172     evaluation reward: 1.46\n",
            "episode: 516   score: 4.0   memory length: 93627   epsilon: 1.0    steps: 303     evaluation reward: 1.48\n",
            "episode: 517   score: 0.0   memory length: 93751   epsilon: 1.0    steps: 124     evaluation reward: 1.47\n",
            "episode: 518   score: 0.0   memory length: 93896   epsilon: 1.0    steps: 145     evaluation reward: 1.46\n",
            "episode: 519   score: 1.0   memory length: 94073   epsilon: 1.0    steps: 177     evaluation reward: 1.47\n",
            "episode: 520   score: 2.0   memory length: 94283   epsilon: 1.0    steps: 210     evaluation reward: 1.48\n",
            "episode: 521   score: 3.0   memory length: 94557   epsilon: 1.0    steps: 274     evaluation reward: 1.5\n",
            "episode: 522   score: 1.0   memory length: 94719   epsilon: 1.0    steps: 162     evaluation reward: 1.51\n",
            "episode: 523   score: 2.0   memory length: 94924   epsilon: 1.0    steps: 205     evaluation reward: 1.51\n",
            "episode: 524   score: 2.0   memory length: 95132   epsilon: 1.0    steps: 208     evaluation reward: 1.51\n",
            "episode: 525   score: 0.0   memory length: 95259   epsilon: 1.0    steps: 127     evaluation reward: 1.49\n",
            "episode: 526   score: 2.0   memory length: 95469   epsilon: 1.0    steps: 210     evaluation reward: 1.51\n",
            "episode: 527   score: 0.0   memory length: 95598   epsilon: 1.0    steps: 129     evaluation reward: 1.49\n",
            "episode: 528   score: 2.0   memory length: 95796   epsilon: 1.0    steps: 198     evaluation reward: 1.5\n",
            "episode: 529   score: 2.0   memory length: 96028   epsilon: 1.0    steps: 232     evaluation reward: 1.5\n",
            "episode: 530   score: 1.0   memory length: 96186   epsilon: 1.0    steps: 158     evaluation reward: 1.49\n",
            "episode: 531   score: 2.0   memory length: 96390   epsilon: 1.0    steps: 204     evaluation reward: 1.49\n",
            "episode: 532   score: 2.0   memory length: 96596   epsilon: 1.0    steps: 206     evaluation reward: 1.51\n",
            "episode: 533   score: 1.0   memory length: 96775   epsilon: 1.0    steps: 179     evaluation reward: 1.51\n",
            "episode: 534   score: 0.0   memory length: 96904   epsilon: 1.0    steps: 129     evaluation reward: 1.5\n",
            "episode: 535   score: 0.0   memory length: 97032   epsilon: 1.0    steps: 128     evaluation reward: 1.5\n",
            "episode: 536   score: 1.0   memory length: 97187   epsilon: 1.0    steps: 155     evaluation reward: 1.5\n",
            "episode: 537   score: 2.0   memory length: 97393   epsilon: 1.0    steps: 206     evaluation reward: 1.5\n",
            "episode: 538   score: 1.0   memory length: 97564   epsilon: 1.0    steps: 171     evaluation reward: 1.5\n",
            "episode: 539   score: 1.0   memory length: 97737   epsilon: 1.0    steps: 173     evaluation reward: 1.48\n",
            "episode: 540   score: 0.0   memory length: 97875   epsilon: 1.0    steps: 138     evaluation reward: 1.47\n",
            "episode: 541   score: 3.0   memory length: 98110   epsilon: 1.0    steps: 235     evaluation reward: 1.5\n",
            "episode: 542   score: 1.0   memory length: 98268   epsilon: 1.0    steps: 158     evaluation reward: 1.51\n",
            "episode: 543   score: 0.0   memory length: 98396   epsilon: 1.0    steps: 128     evaluation reward: 1.51\n",
            "episode: 544   score: 2.0   memory length: 98623   epsilon: 1.0    steps: 227     evaluation reward: 1.52\n",
            "episode: 545   score: 4.0   memory length: 98908   epsilon: 1.0    steps: 285     evaluation reward: 1.55\n",
            "episode: 546   score: 0.0   memory length: 99036   epsilon: 1.0    steps: 128     evaluation reward: 1.55\n",
            "episode: 547   score: 1.0   memory length: 99216   epsilon: 1.0    steps: 180     evaluation reward: 1.56\n",
            "episode: 548   score: 0.0   memory length: 99346   epsilon: 1.0    steps: 130     evaluation reward: 1.54\n",
            "episode: 549   score: 2.0   memory length: 99556   epsilon: 1.0    steps: 210     evaluation reward: 1.54\n",
            "episode: 550   score: 0.0   memory length: 99684   epsilon: 1.0    steps: 128     evaluation reward: 1.52\n",
            "episode: 551   score: 1.0   memory length: 99840   epsilon: 1.0    steps: 156     evaluation reward: 1.52\n",
            "episode: 552   score: 0.0   memory length: 99973   epsilon: 1.0    steps: 133     evaluation reward: 1.5\n",
            "now time :  2019-12-12 17:39:51.950345\n",
            "episode: 553   score: 2.0   memory length: 100171   epsilon: 0.9998297200000037    steps: 198     evaluation reward: 1.51\n",
            "episode: 554   score: 3.0   memory length: 100437   epsilon: 0.9995663800000094    steps: 266     evaluation reward: 1.52\n",
            "episode: 555   score: 1.0   memory length: 100593   epsilon: 0.9994119400000128    steps: 156     evaluation reward: 1.47\n",
            "episode: 556   score: 4.0   memory length: 100874   epsilon: 0.9991337500000188    steps: 281     evaluation reward: 1.49\n",
            "episode: 557   score: 0.0   memory length: 101010   epsilon: 0.9989991100000217    steps: 136     evaluation reward: 1.48\n",
            "episode: 558   score: 1.0   memory length: 101197   epsilon: 0.9988139800000257    steps: 187     evaluation reward: 1.48\n",
            "episode: 559   score: 1.0   memory length: 101378   epsilon: 0.9986347900000296    steps: 181     evaluation reward: 1.47\n",
            "episode: 560   score: 0.0   memory length: 101509   epsilon: 0.9985051000000325    steps: 131     evaluation reward: 1.46\n",
            "episode: 561   score: 2.0   memory length: 101721   epsilon: 0.998295220000037    steps: 212     evaluation reward: 1.48\n",
            "episode: 562   score: 1.0   memory length: 101894   epsilon: 0.9981239500000407    steps: 173     evaluation reward: 1.48\n",
            "episode: 563   score: 0.0   memory length: 102020   epsilon: 0.9979992100000434    steps: 126     evaluation reward: 1.45\n",
            "episode: 564   score: 1.0   memory length: 102200   epsilon: 0.9978210100000473    steps: 180     evaluation reward: 1.44\n",
            "episode: 565   score: 1.0   memory length: 102380   epsilon: 0.9976428100000512    steps: 180     evaluation reward: 1.44\n",
            "episode: 566   score: 2.0   memory length: 102570   epsilon: 0.9974547100000553    steps: 190     evaluation reward: 1.45\n",
            "episode: 567   score: 1.0   memory length: 102752   epsilon: 0.9972745300000592    steps: 182     evaluation reward: 1.44\n",
            "episode: 568   score: 1.0   memory length: 102914   epsilon: 0.9971141500000626    steps: 162     evaluation reward: 1.44\n",
            "episode: 569   score: 1.0   memory length: 103074   epsilon: 0.9969557500000661    steps: 160     evaluation reward: 1.44\n",
            "episode: 570   score: 3.0   memory length: 103304   epsilon: 0.996728050000071    steps: 230     evaluation reward: 1.44\n",
            "episode: 571   score: 1.0   memory length: 103481   epsilon: 0.9965528200000748    steps: 177     evaluation reward: 1.43\n",
            "episode: 572   score: 2.0   memory length: 103710   epsilon: 0.9963261100000798    steps: 229     evaluation reward: 1.43\n",
            "episode: 573   score: 0.0   memory length: 103834   epsilon: 0.9962033500000824    steps: 124     evaluation reward: 1.43\n",
            "episode: 574   score: 3.0   memory length: 104087   epsilon: 0.9959528800000879    steps: 253     evaluation reward: 1.45\n",
            "episode: 575   score: 3.0   memory length: 104361   epsilon: 0.9956816200000937    steps: 274     evaluation reward: 1.47\n",
            "episode: 576   score: 1.0   memory length: 104517   epsilon: 0.9955271800000971    steps: 156     evaluation reward: 1.47\n",
            "episode: 577   score: 3.0   memory length: 104748   epsilon: 0.9952984900001021    steps: 231     evaluation reward: 1.48\n",
            "episode: 578   score: 0.0   memory length: 104880   epsilon: 0.9951678100001049    steps: 132     evaluation reward: 1.46\n",
            "episode: 579   score: 5.0   memory length: 105224   epsilon: 0.9948272500001123    steps: 344     evaluation reward: 1.51\n",
            "episode: 580   score: 3.0   memory length: 105470   epsilon: 0.9945837100001176    steps: 246     evaluation reward: 1.52\n",
            "episode: 581   score: 2.0   memory length: 105676   epsilon: 0.994379770000122    steps: 206     evaluation reward: 1.53\n",
            "episode: 582   score: 1.0   memory length: 105835   epsilon: 0.9942223600001254    steps: 159     evaluation reward: 1.53\n",
            "episode: 583   score: 3.0   memory length: 106076   epsilon: 0.9939837700001306    steps: 241     evaluation reward: 1.54\n",
            "episode: 584   score: 2.0   memory length: 106278   epsilon: 0.993783790000135    steps: 202     evaluation reward: 1.54\n",
            "episode: 585   score: 1.0   memory length: 106462   epsilon: 0.9936016300001389    steps: 184     evaluation reward: 1.54\n",
            "episode: 586   score: 1.0   memory length: 106618   epsilon: 0.9934471900001423    steps: 156     evaluation reward: 1.54\n",
            "episode: 587   score: 2.0   memory length: 106842   epsilon: 0.9932254300001471    steps: 224     evaluation reward: 1.56\n",
            "episode: 588   score: 2.0   memory length: 107047   epsilon: 0.9930224800001515    steps: 205     evaluation reward: 1.51\n",
            "episode: 589   score: 0.0   memory length: 107174   epsilon: 0.9928967500001542    steps: 127     evaluation reward: 1.51\n",
            "episode: 590   score: 0.0   memory length: 107298   epsilon: 0.9927739900001569    steps: 124     evaluation reward: 1.5\n",
            "episode: 591   score: 2.0   memory length: 107499   epsilon: 0.9925750000001612    steps: 201     evaluation reward: 1.51\n",
            "episode: 592   score: 3.0   memory length: 107725   epsilon: 0.992351260000166    steps: 226     evaluation reward: 1.52\n",
            "episode: 593   score: 0.0   memory length: 107864   epsilon: 0.992213650000169    steps: 139     evaluation reward: 1.5\n",
            "episode: 594   score: 2.0   memory length: 108111   epsilon: 0.9919691200001743    steps: 247     evaluation reward: 1.5\n",
            "episode: 595   score: 0.0   memory length: 108234   epsilon: 0.991847350000177    steps: 123     evaluation reward: 1.48\n",
            "episode: 596   score: 5.0   memory length: 108568   epsilon: 0.9915166900001842    steps: 334     evaluation reward: 1.53\n",
            "episode: 597   score: 2.0   memory length: 108769   epsilon: 0.9913177000001885    steps: 201     evaluation reward: 1.54\n",
            "episode: 598   score: 0.0   memory length: 108895   epsilon: 0.9911929600001912    steps: 126     evaluation reward: 1.53\n",
            "episode: 599   score: 1.0   memory length: 109053   epsilon: 0.9910365400001946    steps: 158     evaluation reward: 1.52\n",
            "episode: 600   score: 1.0   memory length: 109209   epsilon: 0.9908821000001979    steps: 156     evaluation reward: 1.53\n",
            "episode: 601   score: 1.0   memory length: 109383   epsilon: 0.9907098400002017    steps: 174     evaluation reward: 1.52\n",
            "episode: 602   score: 0.0   memory length: 109510   epsilon: 0.9905841100002044    steps: 127     evaluation reward: 1.52\n",
            "episode: 603   score: 2.0   memory length: 109695   epsilon: 0.9904009600002084    steps: 185     evaluation reward: 1.53\n",
            "episode: 604   score: 1.0   memory length: 109854   epsilon: 0.9902435500002118    steps: 159     evaluation reward: 1.51\n",
            "episode: 605   score: 0.0   memory length: 109989   epsilon: 0.9901099000002147    steps: 135     evaluation reward: 1.48\n",
            "episode: 606   score: 1.0   memory length: 110142   epsilon: 0.989958430000218    steps: 153     evaluation reward: 1.48\n",
            "episode: 607   score: 2.0   memory length: 110365   epsilon: 0.9897376600002228    steps: 223     evaluation reward: 1.45\n",
            "episode: 608   score: 3.0   memory length: 110628   epsilon: 0.9894772900002284    steps: 263     evaluation reward: 1.47\n",
            "episode: 609   score: 2.0   memory length: 110832   epsilon: 0.9892753300002328    steps: 204     evaluation reward: 1.45\n",
            "episode: 610   score: 1.0   memory length: 110990   epsilon: 0.9891189100002362    steps: 158     evaluation reward: 1.45\n",
            "episode: 611   score: 0.0   memory length: 111126   epsilon: 0.9889842700002391    steps: 136     evaluation reward: 1.44\n",
            "episode: 612   score: 1.0   memory length: 111287   epsilon: 0.9888248800002426    steps: 161     evaluation reward: 1.4\n",
            "episode: 613   score: 0.0   memory length: 111416   epsilon: 0.9886971700002454    steps: 129     evaluation reward: 1.39\n",
            "episode: 614   score: 1.0   memory length: 111594   epsilon: 0.9885209500002492    steps: 178     evaluation reward: 1.38\n",
            "episode: 615   score: 0.0   memory length: 111721   epsilon: 0.9883952200002519    steps: 127     evaluation reward: 1.37\n",
            "episode: 616   score: 2.0   memory length: 111926   epsilon: 0.9881922700002563    steps: 205     evaluation reward: 1.35\n",
            "episode: 617   score: 1.0   memory length: 112112   epsilon: 0.9880081300002603    steps: 186     evaluation reward: 1.36\n",
            "episode: 618   score: 1.0   memory length: 112270   epsilon: 0.9878517100002637    steps: 158     evaluation reward: 1.37\n",
            "episode: 619   score: 3.0   memory length: 112519   epsilon: 0.9876052000002691    steps: 249     evaluation reward: 1.39\n",
            "episode: 620   score: 2.0   memory length: 112704   epsilon: 0.987422050000273    steps: 185     evaluation reward: 1.39\n",
            "episode: 621   score: 2.0   memory length: 112925   epsilon: 0.9872032600002778    steps: 221     evaluation reward: 1.38\n",
            "episode: 622   score: 1.0   memory length: 113082   epsilon: 0.9870478300002812    steps: 157     evaluation reward: 1.38\n",
            "episode: 623   score: 0.0   memory length: 113221   epsilon: 0.9869102200002842    steps: 139     evaluation reward: 1.36\n",
            "episode: 624   score: 1.0   memory length: 113376   epsilon: 0.9867567700002875    steps: 155     evaluation reward: 1.35\n",
            "episode: 625   score: 3.0   memory length: 113610   epsilon: 0.9865251100002925    steps: 234     evaluation reward: 1.38\n",
            "episode: 626   score: 1.0   memory length: 113767   epsilon: 0.9863696800002959    steps: 157     evaluation reward: 1.37\n",
            "episode: 627   score: 1.0   memory length: 113923   epsilon: 0.9862152400002993    steps: 156     evaluation reward: 1.38\n",
            "episode: 628   score: 0.0   memory length: 114049   epsilon: 0.986090500000302    steps: 126     evaluation reward: 1.36\n",
            "episode: 629   score: 3.0   memory length: 114322   epsilon: 0.9858202300003078    steps: 273     evaluation reward: 1.37\n",
            "episode: 630   score: 0.0   memory length: 114462   epsilon: 0.9856816300003108    steps: 140     evaluation reward: 1.36\n",
            "episode: 631   score: 0.0   memory length: 114607   epsilon: 0.985538080000314    steps: 145     evaluation reward: 1.34\n",
            "episode: 632   score: 3.0   memory length: 114861   epsilon: 0.9852866200003194    steps: 254     evaluation reward: 1.35\n",
            "episode: 633   score: 1.0   memory length: 115021   epsilon: 0.9851282200003229    steps: 160     evaluation reward: 1.35\n",
            "episode: 634   score: 1.0   memory length: 115181   epsilon: 0.9849698200003263    steps: 160     evaluation reward: 1.36\n",
            "episode: 635   score: 0.0   memory length: 115312   epsilon: 0.9848401300003291    steps: 131     evaluation reward: 1.36\n",
            "episode: 636   score: 0.0   memory length: 115441   epsilon: 0.9847124200003319    steps: 129     evaluation reward: 1.35\n",
            "episode: 637   score: 1.0   memory length: 115623   epsilon: 0.9845322400003358    steps: 182     evaluation reward: 1.34\n",
            "episode: 638   score: 1.0   memory length: 115784   epsilon: 0.9843728500003393    steps: 161     evaluation reward: 1.34\n",
            "episode: 639   score: 1.0   memory length: 115956   epsilon: 0.984202570000343    steps: 172     evaluation reward: 1.34\n",
            "episode: 640   score: 3.0   memory length: 116204   epsilon: 0.9839570500003483    steps: 248     evaluation reward: 1.37\n",
            "episode: 641   score: 1.0   memory length: 116358   epsilon: 0.9838045900003516    steps: 154     evaluation reward: 1.35\n",
            "episode: 642   score: 2.0   memory length: 116541   epsilon: 0.9836234200003555    steps: 183     evaluation reward: 1.36\n",
            "episode: 643   score: 2.0   memory length: 116769   epsilon: 0.9833977000003604    steps: 228     evaluation reward: 1.38\n",
            "episode: 644   score: 2.0   memory length: 116970   epsilon: 0.9831987100003647    steps: 201     evaluation reward: 1.38\n",
            "episode: 645   score: 1.0   memory length: 117126   epsilon: 0.9830442700003681    steps: 156     evaluation reward: 1.35\n",
            "episode: 646   score: 0.0   memory length: 117253   epsilon: 0.9829185400003708    steps: 127     evaluation reward: 1.35\n",
            "episode: 647   score: 0.0   memory length: 117375   epsilon: 0.9827977600003734    steps: 122     evaluation reward: 1.34\n",
            "episode: 648   score: 1.0   memory length: 117548   epsilon: 0.9826264900003772    steps: 173     evaluation reward: 1.35\n",
            "episode: 649   score: 2.0   memory length: 117736   epsilon: 0.9824403700003812    steps: 188     evaluation reward: 1.35\n",
            "episode: 650   score: 1.0   memory length: 117906   epsilon: 0.9822720700003849    steps: 170     evaluation reward: 1.36\n",
            "episode: 651   score: 3.0   memory length: 118181   epsilon: 0.9819998200003908    steps: 275     evaluation reward: 1.38\n",
            "episode: 652   score: 3.0   memory length: 118413   epsilon: 0.9817701400003958    steps: 232     evaluation reward: 1.41\n",
            "episode: 653   score: 2.0   memory length: 118620   epsilon: 0.9815652100004002    steps: 207     evaluation reward: 1.41\n",
            "episode: 654   score: 0.0   memory length: 118752   epsilon: 0.981434530000403    steps: 132     evaluation reward: 1.38\n",
            "episode: 655   score: 3.0   memory length: 118985   epsilon: 0.981203860000408    steps: 233     evaluation reward: 1.4\n",
            "episode: 656   score: 1.0   memory length: 119156   epsilon: 0.9810345700004117    steps: 171     evaluation reward: 1.37\n",
            "episode: 657   score: 1.0   memory length: 119315   epsilon: 0.9808771600004151    steps: 159     evaluation reward: 1.38\n",
            "episode: 658   score: 0.0   memory length: 119439   epsilon: 0.9807544000004178    steps: 124     evaluation reward: 1.37\n",
            "episode: 659   score: 5.0   memory length: 119754   epsilon: 0.9804425500004246    steps: 315     evaluation reward: 1.41\n",
            "episode: 660   score: 3.0   memory length: 120034   epsilon: 0.9801653500004306    steps: 280     evaluation reward: 1.44\n",
            "episode: 661   score: 1.0   memory length: 120188   epsilon: 0.9800128900004339    steps: 154     evaluation reward: 1.43\n",
            "episode: 662   score: 0.0   memory length: 120320   epsilon: 0.9798822100004367    steps: 132     evaluation reward: 1.42\n",
            "episode: 663   score: 1.0   memory length: 120473   epsilon: 0.97973074000044    steps: 153     evaluation reward: 1.43\n",
            "episode: 664   score: 1.0   memory length: 120636   epsilon: 0.9795693700004435    steps: 163     evaluation reward: 1.43\n",
            "episode: 665   score: 0.0   memory length: 120771   epsilon: 0.9794357200004464    steps: 135     evaluation reward: 1.42\n",
            "episode: 666   score: 1.0   memory length: 120946   epsilon: 0.9792624700004502    steps: 175     evaluation reward: 1.41\n",
            "episode: 667   score: 0.0   memory length: 121074   epsilon: 0.9791357500004529    steps: 128     evaluation reward: 1.4\n",
            "episode: 668   score: 1.0   memory length: 121233   epsilon: 0.9789783400004564    steps: 159     evaluation reward: 1.4\n",
            "episode: 669   score: 0.0   memory length: 121369   epsilon: 0.9788437000004593    steps: 136     evaluation reward: 1.39\n",
            "episode: 670   score: 2.0   memory length: 121571   epsilon: 0.9786437200004636    steps: 202     evaluation reward: 1.38\n",
            "episode: 671   score: 0.0   memory length: 121700   epsilon: 0.9785160100004664    steps: 129     evaluation reward: 1.37\n",
            "episode: 672   score: 0.0   memory length: 121824   epsilon: 0.9783932500004691    steps: 124     evaluation reward: 1.35\n",
            "episode: 673   score: 2.0   memory length: 122026   epsilon: 0.9781932700004734    steps: 202     evaluation reward: 1.37\n",
            "episode: 674   score: 3.0   memory length: 122246   epsilon: 0.9779754700004781    steps: 220     evaluation reward: 1.37\n",
            "episode: 675   score: 0.0   memory length: 122383   epsilon: 0.9778398400004811    steps: 137     evaluation reward: 1.34\n",
            "episode: 676   score: 0.0   memory length: 122512   epsilon: 0.9777121300004838    steps: 129     evaluation reward: 1.33\n",
            "episode: 677   score: 4.0   memory length: 122793   epsilon: 0.9774339400004899    steps: 281     evaluation reward: 1.34\n",
            "episode: 678   score: 0.0   memory length: 122921   epsilon: 0.9773072200004926    steps: 128     evaluation reward: 1.34\n",
            "episode: 679   score: 1.0   memory length: 123078   epsilon: 0.977151790000496    steps: 157     evaluation reward: 1.3\n",
            "episode: 680   score: 0.0   memory length: 123207   epsilon: 0.9770240800004988    steps: 129     evaluation reward: 1.27\n",
            "episode: 681   score: 1.0   memory length: 123364   epsilon: 0.9768686500005022    steps: 157     evaluation reward: 1.26\n",
            "episode: 682   score: 1.0   memory length: 123522   epsilon: 0.9767122300005056    steps: 158     evaluation reward: 1.26\n",
            "episode: 683   score: 0.0   memory length: 123648   epsilon: 0.9765874900005083    steps: 126     evaluation reward: 1.23\n",
            "episode: 684   score: 4.0   memory length: 123916   epsilon: 0.976322170000514    steps: 268     evaluation reward: 1.25\n",
            "episode: 685   score: 3.0   memory length: 124174   epsilon: 0.9760667500005196    steps: 258     evaluation reward: 1.27\n",
            "episode: 686   score: 1.0   memory length: 124329   epsilon: 0.9759133000005229    steps: 155     evaluation reward: 1.27\n",
            "episode: 687   score: 4.0   memory length: 124656   epsilon: 0.9755895700005299    steps: 327     evaluation reward: 1.29\n",
            "episode: 688   score: 2.0   memory length: 124850   epsilon: 0.9753975100005341    steps: 194     evaluation reward: 1.29\n",
            "episode: 689   score: 1.0   memory length: 125022   epsilon: 0.9752272300005378    steps: 172     evaluation reward: 1.3\n",
            "episode: 690   score: 5.0   memory length: 125334   epsilon: 0.9749183500005445    steps: 312     evaluation reward: 1.35\n",
            "episode: 691   score: 2.0   memory length: 125540   epsilon: 0.9747144100005489    steps: 206     evaluation reward: 1.35\n",
            "episode: 692   score: 1.0   memory length: 125702   epsilon: 0.9745540300005524    steps: 162     evaluation reward: 1.33\n",
            "episode: 693   score: 4.0   memory length: 125990   epsilon: 0.9742689100005586    steps: 288     evaluation reward: 1.37\n",
            "episode: 694   score: 1.0   memory length: 126146   epsilon: 0.974114470000562    steps: 156     evaluation reward: 1.36\n",
            "episode: 695   score: 3.0   memory length: 126384   epsilon: 0.9738788500005671    steps: 238     evaluation reward: 1.39\n",
            "episode: 696   score: 3.0   memory length: 126601   epsilon: 0.9736640200005717    steps: 217     evaluation reward: 1.37\n",
            "episode: 697   score: 0.0   memory length: 126736   epsilon: 0.9735303700005746    steps: 135     evaluation reward: 1.35\n",
            "episode: 698   score: 0.0   memory length: 126885   epsilon: 0.9733828600005778    steps: 149     evaluation reward: 1.35\n",
            "episode: 699   score: 1.0   memory length: 127043   epsilon: 0.9732264400005812    steps: 158     evaluation reward: 1.35\n",
            "episode: 700   score: 3.0   memory length: 127303   epsilon: 0.9729690400005868    steps: 260     evaluation reward: 1.37\n",
            "episode: 701   score: 1.0   memory length: 127462   epsilon: 0.9728116300005902    steps: 159     evaluation reward: 1.37\n",
            "episode: 702   score: 4.0   memory length: 127767   epsilon: 0.9725096800005968    steps: 305     evaluation reward: 1.41\n",
            "episode: 703   score: 4.0   memory length: 128046   epsilon: 0.9722334700006028    steps: 279     evaluation reward: 1.43\n",
            "episode: 704   score: 2.0   memory length: 128248   epsilon: 0.9720334900006071    steps: 202     evaluation reward: 1.44\n",
            "episode: 705   score: 0.0   memory length: 128377   epsilon: 0.9719057800006099    steps: 129     evaluation reward: 1.44\n",
            "episode: 706   score: 1.0   memory length: 128554   epsilon: 0.9717305500006137    steps: 177     evaluation reward: 1.44\n",
            "episode: 707   score: 1.0   memory length: 128717   epsilon: 0.9715691800006172    steps: 163     evaluation reward: 1.43\n",
            "episode: 708   score: 1.0   memory length: 128872   epsilon: 0.9714157300006205    steps: 155     evaluation reward: 1.41\n",
            "episode: 709   score: 0.0   memory length: 128996   epsilon: 0.9712929700006232    steps: 124     evaluation reward: 1.39\n",
            "episode: 710   score: 0.0   memory length: 129134   epsilon: 0.9711563500006262    steps: 138     evaluation reward: 1.38\n",
            "episode: 711   score: 1.0   memory length: 129293   epsilon: 0.9709989400006296    steps: 159     evaluation reward: 1.39\n",
            "episode: 712   score: 0.0   memory length: 129424   epsilon: 0.9708692500006324    steps: 131     evaluation reward: 1.38\n",
            "episode: 713   score: 3.0   memory length: 129676   epsilon: 0.9706197700006378    steps: 252     evaluation reward: 1.41\n",
            "episode: 714   score: 2.0   memory length: 129861   epsilon: 0.9704366200006418    steps: 185     evaluation reward: 1.42\n",
            "episode: 715   score: 1.0   memory length: 130041   epsilon: 0.9702584200006457    steps: 180     evaluation reward: 1.43\n",
            "episode: 716   score: 1.0   memory length: 130214   epsilon: 0.9700871500006494    steps: 173     evaluation reward: 1.42\n",
            "episode: 717   score: 2.0   memory length: 130439   epsilon: 0.9698644000006542    steps: 225     evaluation reward: 1.43\n",
            "episode: 718   score: 1.0   memory length: 130629   epsilon: 0.9696763000006583    steps: 190     evaluation reward: 1.43\n",
            "episode: 719   score: 2.0   memory length: 130830   epsilon: 0.9694773100006626    steps: 201     evaluation reward: 1.42\n",
            "episode: 720   score: 2.0   memory length: 131022   epsilon: 0.9692872300006667    steps: 192     evaluation reward: 1.42\n",
            "episode: 721   score: 0.0   memory length: 131147   epsilon: 0.9691634800006694    steps: 125     evaluation reward: 1.4\n",
            "episode: 722   score: 2.0   memory length: 131363   epsilon: 0.9689496400006741    steps: 216     evaluation reward: 1.41\n",
            "episode: 723   score: 1.0   memory length: 131522   epsilon: 0.9687922300006775    steps: 159     evaluation reward: 1.42\n",
            "episode: 724   score: 0.0   memory length: 131654   epsilon: 0.9686615500006803    steps: 132     evaluation reward: 1.41\n",
            "episode: 725   score: 0.0   memory length: 131789   epsilon: 0.9685279000006832    steps: 135     evaluation reward: 1.38\n",
            "episode: 726   score: 0.0   memory length: 131918   epsilon: 0.968400190000686    steps: 129     evaluation reward: 1.37\n",
            "episode: 727   score: 1.0   memory length: 132080   epsilon: 0.9682398100006895    steps: 162     evaluation reward: 1.37\n",
            "episode: 728   score: 3.0   memory length: 132332   epsilon: 0.9679903300006949    steps: 252     evaluation reward: 1.4\n",
            "episode: 729   score: 0.0   memory length: 132460   epsilon: 0.9678636100006976    steps: 128     evaluation reward: 1.37\n",
            "episode: 730   score: 1.0   memory length: 132616   epsilon: 0.967709170000701    steps: 156     evaluation reward: 1.38\n",
            "episode: 731   score: 1.0   memory length: 132775   epsilon: 0.9675517600007044    steps: 159     evaluation reward: 1.39\n",
            "episode: 732   score: 1.0   memory length: 132934   epsilon: 0.9673943500007078    steps: 159     evaluation reward: 1.37\n",
            "episode: 733   score: 1.0   memory length: 133110   epsilon: 0.9672201100007116    steps: 176     evaluation reward: 1.37\n",
            "episode: 734   score: 2.0   memory length: 133328   epsilon: 0.9670042900007163    steps: 218     evaluation reward: 1.38\n",
            "episode: 735   score: 0.0   memory length: 133462   epsilon: 0.9668716300007192    steps: 134     evaluation reward: 1.38\n",
            "episode: 736   score: 2.0   memory length: 133675   epsilon: 0.9666607600007238    steps: 213     evaluation reward: 1.4\n",
            "episode: 737   score: 0.0   memory length: 133823   epsilon: 0.9665142400007269    steps: 148     evaluation reward: 1.39\n",
            "episode: 738   score: 2.0   memory length: 134033   epsilon: 0.9663063400007315    steps: 210     evaluation reward: 1.4\n",
            "episode: 739   score: 2.0   memory length: 134249   epsilon: 0.9660925000007361    steps: 216     evaluation reward: 1.41\n",
            "episode: 740   score: 1.0   memory length: 134424   epsilon: 0.9659192500007399    steps: 175     evaluation reward: 1.39\n",
            "episode: 741   score: 0.0   memory length: 134549   epsilon: 0.9657955000007425    steps: 125     evaluation reward: 1.38\n",
            "episode: 742   score: 0.0   memory length: 134684   epsilon: 0.9656618500007454    steps: 135     evaluation reward: 1.36\n",
            "episode: 743   score: 0.0   memory length: 134816   epsilon: 0.9655311700007483    steps: 132     evaluation reward: 1.34\n",
            "episode: 744   score: 0.0   memory length: 134947   epsilon: 0.9654014800007511    steps: 131     evaluation reward: 1.32\n",
            "episode: 745   score: 2.0   memory length: 135149   epsilon: 0.9652015000007554    steps: 202     evaluation reward: 1.33\n",
            "episode: 746   score: 3.0   memory length: 135382   epsilon: 0.9649708300007604    steps: 233     evaluation reward: 1.36\n",
            "episode: 747   score: 0.0   memory length: 135516   epsilon: 0.9648381700007633    steps: 134     evaluation reward: 1.36\n",
            "episode: 748   score: 1.0   memory length: 135671   epsilon: 0.9646847200007667    steps: 155     evaluation reward: 1.36\n",
            "episode: 749   score: 0.0   memory length: 135802   epsilon: 0.9645550300007695    steps: 131     evaluation reward: 1.34\n",
            "episode: 750   score: 0.0   memory length: 135935   epsilon: 0.9644233600007723    steps: 133     evaluation reward: 1.33\n",
            "episode: 751   score: 1.0   memory length: 136099   epsilon: 0.9642610000007759    steps: 164     evaluation reward: 1.31\n",
            "episode: 752   score: 2.0   memory length: 136310   epsilon: 0.9640521100007804    steps: 211     evaluation reward: 1.3\n",
            "episode: 753   score: 2.0   memory length: 136512   epsilon: 0.9638521300007847    steps: 202     evaluation reward: 1.3\n",
            "episode: 754   score: 1.0   memory length: 136675   epsilon: 0.9636907600007882    steps: 163     evaluation reward: 1.31\n",
            "episode: 755   score: 0.0   memory length: 136812   epsilon: 0.9635551300007912    steps: 137     evaluation reward: 1.28\n",
            "episode: 756   score: 0.0   memory length: 136940   epsilon: 0.9634284100007939    steps: 128     evaluation reward: 1.27\n",
            "episode: 757   score: 0.0   memory length: 137080   epsilon: 0.9632898100007969    steps: 140     evaluation reward: 1.26\n",
            "episode: 758   score: 0.0   memory length: 137213   epsilon: 0.9631581400007998    steps: 133     evaluation reward: 1.26\n",
            "episode: 759   score: 0.0   memory length: 137341   epsilon: 0.9630314200008026    steps: 128     evaluation reward: 1.21\n",
            "episode: 760   score: 2.0   memory length: 137546   epsilon: 0.962828470000807    steps: 205     evaluation reward: 1.2\n",
            "episode: 761   score: 2.0   memory length: 137752   epsilon: 0.9626245300008114    steps: 206     evaluation reward: 1.21\n",
            "episode: 762   score: 2.0   memory length: 137957   epsilon: 0.9624215800008158    steps: 205     evaluation reward: 1.23\n",
            "episode: 763   score: 1.0   memory length: 138133   epsilon: 0.9622473400008196    steps: 176     evaluation reward: 1.23\n",
            "episode: 764   score: 1.0   memory length: 138291   epsilon: 0.962090920000823    steps: 158     evaluation reward: 1.23\n",
            "episode: 765   score: 1.0   memory length: 138466   epsilon: 0.9619176700008267    steps: 175     evaluation reward: 1.24\n",
            "episode: 766   score: 0.0   memory length: 138589   epsilon: 0.9617959000008294    steps: 123     evaluation reward: 1.23\n",
            "episode: 767   score: 3.0   memory length: 138826   epsilon: 0.9615612700008345    steps: 237     evaluation reward: 1.26\n",
            "episode: 768   score: 3.0   memory length: 139052   epsilon: 0.9613375300008393    steps: 226     evaluation reward: 1.28\n",
            "episode: 769   score: 0.0   memory length: 139181   epsilon: 0.9612098200008421    steps: 129     evaluation reward: 1.28\n",
            "episode: 770   score: 4.0   memory length: 139459   epsilon: 0.9609346000008481    steps: 278     evaluation reward: 1.3\n",
            "episode: 771   score: 3.0   memory length: 139686   epsilon: 0.960709870000853    steps: 227     evaluation reward: 1.33\n",
            "episode: 772   score: 0.0   memory length: 139826   epsilon: 0.960571270000856    steps: 140     evaluation reward: 1.33\n",
            "episode: 773   score: 2.0   memory length: 140018   epsilon: 0.9603811900008601    steps: 192     evaluation reward: 1.33\n",
            "episode: 774   score: 2.0   memory length: 140228   epsilon: 0.9601732900008646    steps: 210     evaluation reward: 1.32\n",
            "episode: 775   score: 3.0   memory length: 140440   epsilon: 0.9599634100008692    steps: 212     evaluation reward: 1.35\n",
            "episode: 776   score: 2.0   memory length: 140670   epsilon: 0.9597357100008741    steps: 230     evaluation reward: 1.37\n",
            "episode: 777   score: 1.0   memory length: 140846   epsilon: 0.9595614700008779    steps: 176     evaluation reward: 1.34\n",
            "episode: 778   score: 3.0   memory length: 141103   epsilon: 0.9593070400008834    steps: 257     evaluation reward: 1.37\n",
            "episode: 779   score: 7.0   memory length: 141351   epsilon: 0.9590615200008887    steps: 248     evaluation reward: 1.43\n",
            "episode: 780   score: 1.0   memory length: 141520   epsilon: 0.9588942100008924    steps: 169     evaluation reward: 1.44\n",
            "episode: 781   score: 0.0   memory length: 141650   epsilon: 0.9587655100008952    steps: 130     evaluation reward: 1.43\n",
            "episode: 782   score: 2.0   memory length: 141870   epsilon: 0.9585477100008999    steps: 220     evaluation reward: 1.44\n",
            "episode: 783   score: 1.0   memory length: 142041   epsilon: 0.9583784200009036    steps: 171     evaluation reward: 1.45\n",
            "episode: 784   score: 0.0   memory length: 142178   epsilon: 0.9582427900009065    steps: 137     evaluation reward: 1.41\n",
            "episode: 785   score: 2.0   memory length: 142381   epsilon: 0.9580418200009109    steps: 203     evaluation reward: 1.4\n",
            "episode: 786   score: 4.0   memory length: 142690   epsilon: 0.9577359100009175    steps: 309     evaluation reward: 1.43\n",
            "episode: 787   score: 0.0   memory length: 142822   epsilon: 0.9576052300009203    steps: 132     evaluation reward: 1.39\n",
            "episode: 788   score: 0.0   memory length: 142963   epsilon: 0.9574656400009234    steps: 141     evaluation reward: 1.37\n",
            "episode: 789   score: 2.0   memory length: 143149   epsilon: 0.9572815000009274    steps: 186     evaluation reward: 1.38\n",
            "episode: 790   score: 3.0   memory length: 143385   epsilon: 0.9570478600009324    steps: 236     evaluation reward: 1.36\n",
            "episode: 791   score: 0.0   memory length: 143515   epsilon: 0.9569191600009352    steps: 130     evaluation reward: 1.34\n",
            "episode: 792   score: 0.0   memory length: 143647   epsilon: 0.9567884800009381    steps: 132     evaluation reward: 1.33\n",
            "episode: 793   score: 8.0   memory length: 143993   epsilon: 0.9564459400009455    steps: 346     evaluation reward: 1.37\n",
            "episode: 794   score: 0.0   memory length: 144129   epsilon: 0.9563113000009484    steps: 136     evaluation reward: 1.36\n",
            "episode: 795   score: 2.0   memory length: 144331   epsilon: 0.9561113200009528    steps: 202     evaluation reward: 1.35\n",
            "episode: 796   score: 2.0   memory length: 144522   epsilon: 0.9559222300009569    steps: 191     evaluation reward: 1.34\n",
            "episode: 797   score: 1.0   memory length: 144676   epsilon: 0.9557697700009602    steps: 154     evaluation reward: 1.35\n",
            "episode: 798   score: 1.0   memory length: 144866   epsilon: 0.9555816700009643    steps: 190     evaluation reward: 1.36\n",
            "episode: 799   score: 2.0   memory length: 145071   epsilon: 0.9553787200009687    steps: 205     evaluation reward: 1.37\n",
            "episode: 800   score: 2.0   memory length: 145276   epsilon: 0.9551757700009731    steps: 205     evaluation reward: 1.36\n",
            "episode: 801   score: 2.0   memory length: 145476   epsilon: 0.9549777700009774    steps: 200     evaluation reward: 1.37\n",
            "episode: 802   score: 1.0   memory length: 145631   epsilon: 0.9548243200009807    steps: 155     evaluation reward: 1.34\n",
            "episode: 803   score: 0.0   memory length: 145757   epsilon: 0.9546995800009834    steps: 126     evaluation reward: 1.3\n",
            "episode: 804   score: 4.0   memory length: 146056   epsilon: 0.9544035700009899    steps: 299     evaluation reward: 1.32\n",
            "episode: 805   score: 1.0   memory length: 146208   epsilon: 0.9542530900009931    steps: 152     evaluation reward: 1.33\n",
            "episode: 806   score: 2.0   memory length: 146429   epsilon: 0.9540343000009979    steps: 221     evaluation reward: 1.34\n",
            "episode: 807   score: 1.0   memory length: 146604   epsilon: 0.9538610500010016    steps: 175     evaluation reward: 1.34\n",
            "episode: 808   score: 1.0   memory length: 146768   epsilon: 0.9536986900010052    steps: 164     evaluation reward: 1.34\n",
            "episode: 809   score: 0.0   memory length: 146913   epsilon: 0.9535551400010083    steps: 145     evaluation reward: 1.34\n",
            "episode: 810   score: 0.0   memory length: 147042   epsilon: 0.953427430001011    steps: 129     evaluation reward: 1.34\n",
            "episode: 811   score: 3.0   memory length: 147260   epsilon: 0.9532116100010157    steps: 218     evaluation reward: 1.36\n",
            "episode: 812   score: 1.0   memory length: 147419   epsilon: 0.9530542000010191    steps: 159     evaluation reward: 1.37\n",
            "episode: 813   score: 2.0   memory length: 147622   epsilon: 0.9528532300010235    steps: 203     evaluation reward: 1.36\n",
            "episode: 814   score: 1.0   memory length: 147798   epsilon: 0.9526789900010273    steps: 176     evaluation reward: 1.35\n",
            "episode: 815   score: 4.0   memory length: 148078   epsilon: 0.9524017900010333    steps: 280     evaluation reward: 1.38\n",
            "episode: 816   score: 0.0   memory length: 148211   epsilon: 0.9522701200010362    steps: 133     evaluation reward: 1.37\n",
            "episode: 817   score: 3.0   memory length: 148451   epsilon: 0.9520325200010413    steps: 240     evaluation reward: 1.38\n",
            "episode: 818   score: 3.0   memory length: 148677   epsilon: 0.9518087800010462    steps: 226     evaluation reward: 1.4\n",
            "episode: 819   score: 1.0   memory length: 148857   epsilon: 0.95163058000105    steps: 180     evaluation reward: 1.39\n",
            "episode: 820   score: 0.0   memory length: 148993   epsilon: 0.951495940001053    steps: 136     evaluation reward: 1.37\n",
            "episode: 821   score: 2.0   memory length: 149199   epsilon: 0.9512920000010574    steps: 206     evaluation reward: 1.39\n",
            "episode: 822   score: 1.0   memory length: 149374   epsilon: 0.9511187500010612    steps: 175     evaluation reward: 1.38\n",
            "episode: 823   score: 3.0   memory length: 149623   epsilon: 0.9508722400010665    steps: 249     evaluation reward: 1.4\n",
            "episode: 824   score: 2.0   memory length: 149809   epsilon: 0.9506881000010705    steps: 186     evaluation reward: 1.42\n",
            "now time :  2019-12-12 17:58:59.246523\n",
            "episode: 825   score: 3.0   memory length: 150053   epsilon: 0.9504465400010758    steps: 244     evaluation reward: 1.45\n",
            "episode: 826   score: 3.0   memory length: 150282   epsilon: 0.9502198300010807    steps: 229     evaluation reward: 1.48\n",
            "episode: 827   score: 3.0   memory length: 150544   epsilon: 0.9499604500010863    steps: 262     evaluation reward: 1.5\n",
            "episode: 828   score: 3.0   memory length: 150827   epsilon: 0.9496802800010924    steps: 283     evaluation reward: 1.5\n",
            "episode: 829   score: 1.0   memory length: 151011   epsilon: 0.9494981200010963    steps: 184     evaluation reward: 1.51\n",
            "episode: 830   score: 2.0   memory length: 151215   epsilon: 0.9492961600011007    steps: 204     evaluation reward: 1.52\n",
            "episode: 831   score: 1.0   memory length: 151399   epsilon: 0.9491140000011047    steps: 184     evaluation reward: 1.52\n",
            "episode: 832   score: 2.0   memory length: 151632   epsilon: 0.9488833300011097    steps: 233     evaluation reward: 1.53\n",
            "episode: 833   score: 1.0   memory length: 151788   epsilon: 0.948728890001113    steps: 156     evaluation reward: 1.53\n",
            "episode: 834   score: 1.0   memory length: 151963   epsilon: 0.9485556400011168    steps: 175     evaluation reward: 1.52\n",
            "episode: 835   score: 2.0   memory length: 152165   epsilon: 0.9483556600011211    steps: 202     evaluation reward: 1.54\n",
            "episode: 836   score: 0.0   memory length: 152303   epsilon: 0.9482190400011241    steps: 138     evaluation reward: 1.52\n",
            "episode: 837   score: 2.0   memory length: 152508   epsilon: 0.9480160900011285    steps: 205     evaluation reward: 1.54\n",
            "episode: 838   score: 3.0   memory length: 152731   epsilon: 0.9477953200011333    steps: 223     evaluation reward: 1.55\n",
            "episode: 839   score: 3.0   memory length: 153023   epsilon: 0.9475062400011396    steps: 292     evaluation reward: 1.56\n",
            "episode: 840   score: 1.0   memory length: 153180   epsilon: 0.947350810001143    steps: 157     evaluation reward: 1.56\n",
            "episode: 841   score: 2.0   memory length: 153381   epsilon: 0.9471518200011473    steps: 201     evaluation reward: 1.58\n",
            "episode: 842   score: 0.0   memory length: 153518   epsilon: 0.9470161900011502    steps: 137     evaluation reward: 1.58\n",
            "episode: 843   score: 0.0   memory length: 153663   epsilon: 0.9468726400011533    steps: 145     evaluation reward: 1.58\n",
            "episode: 844   score: 0.0   memory length: 153796   epsilon: 0.9467409700011562    steps: 133     evaluation reward: 1.58\n",
            "episode: 845   score: 1.0   memory length: 153955   epsilon: 0.9465835600011596    steps: 159     evaluation reward: 1.57\n",
            "episode: 846   score: 3.0   memory length: 154197   epsilon: 0.9463439800011648    steps: 242     evaluation reward: 1.57\n",
            "episode: 847   score: 2.0   memory length: 154385   epsilon: 0.9461578600011689    steps: 188     evaluation reward: 1.59\n",
            "episode: 848   score: 3.0   memory length: 154603   epsilon: 0.9459420400011735    steps: 218     evaluation reward: 1.61\n",
            "episode: 849   score: 2.0   memory length: 154807   epsilon: 0.9457400800011779    steps: 204     evaluation reward: 1.63\n",
            "episode: 850   score: 3.0   memory length: 155055   epsilon: 0.9454945600011833    steps: 248     evaluation reward: 1.66\n",
            "episode: 851   score: 3.0   memory length: 155297   epsilon: 0.9452549800011885    steps: 242     evaluation reward: 1.68\n",
            "episode: 852   score: 2.0   memory length: 155501   epsilon: 0.9450530200011928    steps: 204     evaluation reward: 1.68\n",
            "episode: 853   score: 1.0   memory length: 155676   epsilon: 0.9448797700011966    steps: 175     evaluation reward: 1.67\n",
            "episode: 854   score: 0.0   memory length: 155807   epsilon: 0.9447500800011994    steps: 131     evaluation reward: 1.66\n",
            "episode: 855   score: 1.0   memory length: 155974   epsilon: 0.944584750001203    steps: 167     evaluation reward: 1.67\n",
            "episode: 856   score: 1.0   memory length: 156139   epsilon: 0.9444214000012066    steps: 165     evaluation reward: 1.68\n",
            "episode: 857   score: 3.0   memory length: 156367   epsilon: 0.9441956800012115    steps: 228     evaluation reward: 1.71\n",
            "episode: 858   score: 0.0   memory length: 156499   epsilon: 0.9440650000012143    steps: 132     evaluation reward: 1.71\n",
            "episode: 859   score: 2.0   memory length: 156692   epsilon: 0.9438739300012184    steps: 193     evaluation reward: 1.73\n",
            "episode: 860   score: 0.0   memory length: 156823   epsilon: 0.9437442400012213    steps: 131     evaluation reward: 1.71\n",
            "episode: 861   score: 2.0   memory length: 157013   epsilon: 0.9435561400012253    steps: 190     evaluation reward: 1.71\n",
            "episode: 862   score: 1.0   memory length: 157173   epsilon: 0.9433977400012288    steps: 160     evaluation reward: 1.7\n",
            "episode: 863   score: 2.0   memory length: 157373   epsilon: 0.9431997400012331    steps: 200     evaluation reward: 1.71\n",
            "episode: 864   score: 1.0   memory length: 157541   epsilon: 0.9430334200012367    steps: 168     evaluation reward: 1.71\n",
            "episode: 865   score: 4.0   memory length: 157828   epsilon: 0.9427492900012429    steps: 287     evaluation reward: 1.74\n",
            "episode: 866   score: 3.0   memory length: 158045   epsilon: 0.9425344600012475    steps: 217     evaluation reward: 1.77\n",
            "episode: 867   score: 1.0   memory length: 158207   epsilon: 0.942374080001251    steps: 162     evaluation reward: 1.75\n",
            "episode: 868   score: 3.0   memory length: 158469   epsilon: 0.9421147000012566    steps: 262     evaluation reward: 1.75\n",
            "episode: 869   score: 2.0   memory length: 158654   epsilon: 0.9419315500012606    steps: 185     evaluation reward: 1.77\n",
            "episode: 870   score: 1.0   memory length: 158807   epsilon: 0.9417800800012639    steps: 153     evaluation reward: 1.74\n",
            "episode: 871   score: 0.0   memory length: 158939   epsilon: 0.9416494000012667    steps: 132     evaluation reward: 1.71\n",
            "episode: 872   score: 0.0   memory length: 159075   epsilon: 0.9415147600012697    steps: 136     evaluation reward: 1.71\n",
            "episode: 873   score: 2.0   memory length: 159267   epsilon: 0.9413246800012738    steps: 192     evaluation reward: 1.71\n",
            "episode: 874   score: 0.0   memory length: 159394   epsilon: 0.9411989500012765    steps: 127     evaluation reward: 1.69\n",
            "episode: 875   score: 0.0   memory length: 159524   epsilon: 0.9410702500012793    steps: 130     evaluation reward: 1.66\n",
            "episode: 876   score: 1.0   memory length: 159679   epsilon: 0.9409168000012826    steps: 155     evaluation reward: 1.65\n",
            "episode: 877   score: 2.0   memory length: 159892   epsilon: 0.9407059300012872    steps: 213     evaluation reward: 1.66\n",
            "episode: 878   score: 4.0   memory length: 160183   epsilon: 0.9404178400012935    steps: 291     evaluation reward: 1.67\n",
            "episode: 879   score: 4.0   memory length: 160486   epsilon: 0.9401178700013    steps: 303     evaluation reward: 1.64\n",
            "episode: 880   score: 1.0   memory length: 160641   epsilon: 0.9399644200013033    steps: 155     evaluation reward: 1.64\n",
            "episode: 881   score: 0.0   memory length: 160768   epsilon: 0.939838690001306    steps: 127     evaluation reward: 1.64\n",
            "episode: 882   score: 3.0   memory length: 161022   epsilon: 0.9395872300013115    steps: 254     evaluation reward: 1.65\n",
            "episode: 883   score: 1.0   memory length: 161193   epsilon: 0.9394179400013152    steps: 171     evaluation reward: 1.65\n",
            "episode: 884   score: 3.0   memory length: 161440   epsilon: 0.9391734100013205    steps: 247     evaluation reward: 1.68\n",
            "episode: 885   score: 2.0   memory length: 161667   epsilon: 0.9389486800013254    steps: 227     evaluation reward: 1.68\n",
            "episode: 886   score: 3.0   memory length: 161932   epsilon: 0.9386863300013311    steps: 265     evaluation reward: 1.67\n",
            "episode: 887   score: 2.0   memory length: 162139   epsilon: 0.9384814000013355    steps: 207     evaluation reward: 1.69\n",
            "episode: 888   score: 3.0   memory length: 162374   epsilon: 0.9382487500013406    steps: 235     evaluation reward: 1.72\n",
            "episode: 889   score: 2.0   memory length: 162574   epsilon: 0.9380507500013449    steps: 200     evaluation reward: 1.72\n",
            "episode: 890   score: 1.0   memory length: 162769   epsilon: 0.937857700001349    steps: 195     evaluation reward: 1.7\n",
            "episode: 891   score: 0.0   memory length: 162902   epsilon: 0.9377260300013519    steps: 133     evaluation reward: 1.7\n",
            "episode: 892   score: 4.0   memory length: 163201   epsilon: 0.9374300200013583    steps: 299     evaluation reward: 1.74\n",
            "episode: 893   score: 0.0   memory length: 163328   epsilon: 0.9373042900013611    steps: 127     evaluation reward: 1.66\n",
            "episode: 894   score: 4.0   memory length: 163595   epsilon: 0.9370399600013668    steps: 267     evaluation reward: 1.7\n",
            "episode: 895   score: 1.0   memory length: 163768   epsilon: 0.9368686900013705    steps: 173     evaluation reward: 1.69\n",
            "episode: 896   score: 0.0   memory length: 163900   epsilon: 0.9367380100013734    steps: 132     evaluation reward: 1.67\n",
            "episode: 897   score: 4.0   memory length: 164184   epsilon: 0.9364568500013795    steps: 284     evaluation reward: 1.7\n",
            "episode: 898   score: 1.0   memory length: 164365   epsilon: 0.9362776600013833    steps: 181     evaluation reward: 1.7\n",
            "episode: 899   score: 1.0   memory length: 164558   epsilon: 0.9360865900013875    steps: 193     evaluation reward: 1.69\n",
            "episode: 900   score: 2.0   memory length: 164766   epsilon: 0.935880670001392    steps: 208     evaluation reward: 1.69\n",
            "episode: 901   score: 3.0   memory length: 165019   epsilon: 0.9356302000013974    steps: 253     evaluation reward: 1.7\n",
            "episode: 902   score: 4.0   memory length: 165286   epsilon: 0.9353658700014031    steps: 267     evaluation reward: 1.73\n",
            "episode: 903   score: 6.0   memory length: 165666   epsilon: 0.9349896700014113    steps: 380     evaluation reward: 1.79\n",
            "episode: 904   score: 4.0   memory length: 165948   epsilon: 0.9347104900014174    steps: 282     evaluation reward: 1.79\n",
            "episode: 905   score: 2.0   memory length: 166130   epsilon: 0.9345303100014213    steps: 182     evaluation reward: 1.8\n",
            "episode: 906   score: 2.0   memory length: 166332   epsilon: 0.9343303300014256    steps: 202     evaluation reward: 1.8\n",
            "episode: 907   score: 0.0   memory length: 166462   epsilon: 0.9342016300014284    steps: 130     evaluation reward: 1.79\n",
            "episode: 908   score: 0.0   memory length: 166608   epsilon: 0.9340570900014316    steps: 146     evaluation reward: 1.78\n",
            "episode: 909   score: 1.0   memory length: 166775   epsilon: 0.9338917600014351    steps: 167     evaluation reward: 1.79\n",
            "episode: 910   score: 1.0   memory length: 166965   epsilon: 0.9337036600014392    steps: 190     evaluation reward: 1.8\n",
            "episode: 911   score: 1.0   memory length: 167150   epsilon: 0.9335205100014432    steps: 185     evaluation reward: 1.78\n",
            "episode: 912   score: 2.0   memory length: 167341   epsilon: 0.9333314200014473    steps: 191     evaluation reward: 1.79\n",
            "episode: 913   score: 0.0   memory length: 167468   epsilon: 0.93320569000145    steps: 127     evaluation reward: 1.77\n",
            "episode: 914   score: 0.0   memory length: 167600   epsilon: 0.9330750100014529    steps: 132     evaluation reward: 1.76\n",
            "episode: 915   score: 0.0   memory length: 167728   epsilon: 0.9329482900014556    steps: 128     evaluation reward: 1.72\n",
            "episode: 916   score: 0.0   memory length: 167857   epsilon: 0.9328205800014584    steps: 129     evaluation reward: 1.72\n",
            "episode: 917   score: 0.0   memory length: 167986   epsilon: 0.9326928700014612    steps: 129     evaluation reward: 1.69\n",
            "episode: 918   score: 1.0   memory length: 168159   epsilon: 0.9325216000014649    steps: 173     evaluation reward: 1.67\n",
            "episode: 919   score: 3.0   memory length: 168409   epsilon: 0.9322741000014703    steps: 250     evaluation reward: 1.69\n",
            "episode: 920   score: 1.0   memory length: 168595   epsilon: 0.9320899600014743    steps: 186     evaluation reward: 1.7\n",
            "episode: 921   score: 1.0   memory length: 168768   epsilon: 0.931918690001478    steps: 173     evaluation reward: 1.69\n",
            "episode: 922   score: 1.0   memory length: 168928   epsilon: 0.9317602900014814    steps: 160     evaluation reward: 1.69\n",
            "episode: 923   score: 4.0   memory length: 169225   epsilon: 0.9314662600014878    steps: 297     evaluation reward: 1.7\n",
            "episode: 924   score: 3.0   memory length: 169489   epsilon: 0.9312049000014935    steps: 264     evaluation reward: 1.71\n",
            "episode: 925   score: 0.0   memory length: 169617   epsilon: 0.9310781800014962    steps: 128     evaluation reward: 1.68\n",
            "episode: 926   score: 1.0   memory length: 169779   epsilon: 0.9309178000014997    steps: 162     evaluation reward: 1.66\n",
            "episode: 927   score: 0.0   memory length: 169911   epsilon: 0.9307871200015025    steps: 132     evaluation reward: 1.63\n",
            "episode: 928   score: 1.0   memory length: 170067   epsilon: 0.9306326800015059    steps: 156     evaluation reward: 1.61\n",
            "episode: 929   score: 2.0   memory length: 170285   epsilon: 0.9304168600015106    steps: 218     evaluation reward: 1.62\n",
            "episode: 930   score: 0.0   memory length: 170417   epsilon: 0.9302861800015134    steps: 132     evaluation reward: 1.6\n",
            "episode: 931   score: 0.0   memory length: 170543   epsilon: 0.9301614400015161    steps: 126     evaluation reward: 1.59\n",
            "episode: 932   score: 3.0   memory length: 170775   epsilon: 0.9299317600015211    steps: 232     evaluation reward: 1.6\n",
            "episode: 933   score: 1.0   memory length: 170950   epsilon: 0.9297585100015249    steps: 175     evaluation reward: 1.6\n",
            "episode: 934   score: 1.0   memory length: 171117   epsilon: 0.9295931800015285    steps: 167     evaluation reward: 1.6\n",
            "episode: 935   score: 2.0   memory length: 171324   epsilon: 0.9293882500015329    steps: 207     evaluation reward: 1.6\n",
            "episode: 936   score: 3.0   memory length: 171566   epsilon: 0.9291486700015381    steps: 242     evaluation reward: 1.63\n",
            "episode: 937   score: 3.0   memory length: 171818   epsilon: 0.9288991900015435    steps: 252     evaluation reward: 1.64\n",
            "episode: 938   score: 3.0   memory length: 172061   epsilon: 0.9286586200015488    steps: 243     evaluation reward: 1.64\n",
            "episode: 939   score: 0.0   memory length: 172186   epsilon: 0.9285348700015514    steps: 125     evaluation reward: 1.61\n",
            "episode: 940   score: 0.0   memory length: 172320   epsilon: 0.9284022100015543    steps: 134     evaluation reward: 1.6\n",
            "episode: 941   score: 0.0   memory length: 172470   epsilon: 0.9282537100015575    steps: 150     evaluation reward: 1.58\n",
            "episode: 942   score: 4.0   memory length: 172758   epsilon: 0.9279685900015637    steps: 288     evaluation reward: 1.62\n",
            "episode: 943   score: 2.0   memory length: 172980   epsilon: 0.9277488100015685    steps: 222     evaluation reward: 1.64\n",
            "episode: 944   score: 1.0   memory length: 173135   epsilon: 0.9275953600015718    steps: 155     evaluation reward: 1.65\n",
            "episode: 945   score: 0.0   memory length: 173258   epsilon: 0.9274735900015745    steps: 123     evaluation reward: 1.64\n",
            "episode: 946   score: 5.0   memory length: 173632   epsilon: 0.9271033300015825    steps: 374     evaluation reward: 1.66\n",
            "episode: 947   score: 2.0   memory length: 173854   epsilon: 0.9268835500015873    steps: 222     evaluation reward: 1.66\n",
            "episode: 948   score: 2.0   memory length: 174083   epsilon: 0.9266568400015922    steps: 229     evaluation reward: 1.65\n",
            "episode: 949   score: 0.0   memory length: 174212   epsilon: 0.926529130001595    steps: 129     evaluation reward: 1.63\n",
            "episode: 950   score: 2.0   memory length: 174433   epsilon: 0.9263103400015997    steps: 221     evaluation reward: 1.62\n",
            "episode: 951   score: 0.0   memory length: 174562   epsilon: 0.9261826300016025    steps: 129     evaluation reward: 1.59\n",
            "episode: 952   score: 1.0   memory length: 174748   epsilon: 0.9259984900016065    steps: 186     evaluation reward: 1.58\n",
            "episode: 953   score: 1.0   memory length: 174914   epsilon: 0.9258341500016101    steps: 166     evaluation reward: 1.58\n",
            "episode: 954   score: 4.0   memory length: 175161   epsilon: 0.9255896200016154    steps: 247     evaluation reward: 1.62\n",
            "episode: 955   score: 2.0   memory length: 175347   epsilon: 0.9254054800016194    steps: 186     evaluation reward: 1.63\n",
            "episode: 956   score: 1.0   memory length: 175508   epsilon: 0.9252460900016228    steps: 161     evaluation reward: 1.63\n",
            "episode: 957   score: 3.0   memory length: 175741   epsilon: 0.9250154200016278    steps: 233     evaluation reward: 1.63\n",
            "episode: 958   score: 0.0   memory length: 175887   epsilon: 0.924870880001631    steps: 146     evaluation reward: 1.63\n",
            "episode: 959   score: 3.0   memory length: 176122   epsilon: 0.924638230001636    steps: 235     evaluation reward: 1.64\n",
            "episode: 960   score: 3.0   memory length: 176352   epsilon: 0.924410530001641    steps: 230     evaluation reward: 1.67\n",
            "episode: 961   score: 2.0   memory length: 176560   epsilon: 0.9242046100016454    steps: 208     evaluation reward: 1.67\n",
            "episode: 962   score: 2.0   memory length: 176767   epsilon: 0.9239996800016499    steps: 207     evaluation reward: 1.68\n",
            "episode: 963   score: 5.0   memory length: 177094   epsilon: 0.9236759500016569    steps: 327     evaluation reward: 1.71\n",
            "episode: 964   score: 1.0   memory length: 177266   epsilon: 0.9235056700016606    steps: 172     evaluation reward: 1.71\n",
            "episode: 965   score: 0.0   memory length: 177399   epsilon: 0.9233740000016635    steps: 133     evaluation reward: 1.67\n",
            "episode: 966   score: 3.0   memory length: 177651   epsilon: 0.9231245200016689    steps: 252     evaluation reward: 1.67\n",
            "episode: 967   score: 2.0   memory length: 177853   epsilon: 0.9229245400016732    steps: 202     evaluation reward: 1.68\n",
            "episode: 968   score: 1.0   memory length: 178044   epsilon: 0.9227354500016773    steps: 191     evaluation reward: 1.66\n",
            "episode: 969   score: 1.0   memory length: 178204   epsilon: 0.9225770500016808    steps: 160     evaluation reward: 1.65\n",
            "episode: 970   score: 2.0   memory length: 178416   epsilon: 0.9223671700016853    steps: 212     evaluation reward: 1.66\n",
            "episode: 971   score: 2.0   memory length: 178621   epsilon: 0.9221642200016897    steps: 205     evaluation reward: 1.68\n",
            "episode: 972   score: 3.0   memory length: 178849   epsilon: 0.9219385000016946    steps: 228     evaluation reward: 1.71\n",
            "episode: 973   score: 0.0   memory length: 178977   epsilon: 0.9218117800016974    steps: 128     evaluation reward: 1.69\n",
            "episode: 974   score: 2.0   memory length: 179184   epsilon: 0.9216068500017018    steps: 207     evaluation reward: 1.71\n",
            "episode: 975   score: 0.0   memory length: 179315   epsilon: 0.9214771600017047    steps: 131     evaluation reward: 1.71\n",
            "episode: 976   score: 1.0   memory length: 179467   epsilon: 0.9213266800017079    steps: 152     evaluation reward: 1.71\n",
            "episode: 977   score: 1.0   memory length: 179640   epsilon: 0.9211554100017116    steps: 173     evaluation reward: 1.7\n",
            "episode: 978   score: 1.0   memory length: 179798   epsilon: 0.920998990001715    steps: 158     evaluation reward: 1.67\n",
            "episode: 979   score: 1.0   memory length: 179950   epsilon: 0.9208485100017183    steps: 152     evaluation reward: 1.64\n",
            "episode: 980   score: 1.0   memory length: 180124   epsilon: 0.920676250001722    steps: 174     evaluation reward: 1.64\n",
            "episode: 981   score: 3.0   memory length: 180361   epsilon: 0.9204416200017271    steps: 237     evaluation reward: 1.67\n",
            "episode: 982   score: 2.0   memory length: 180546   epsilon: 0.9202584700017311    steps: 185     evaluation reward: 1.66\n",
            "episode: 983   score: 1.0   memory length: 180720   epsilon: 0.9200862100017348    steps: 174     evaluation reward: 1.66\n",
            "episode: 984   score: 0.0   memory length: 180846   epsilon: 0.9199614700017376    steps: 126     evaluation reward: 1.63\n",
            "episode: 985   score: 1.0   memory length: 181023   epsilon: 0.9197862400017414    steps: 177     evaluation reward: 1.62\n",
            "episode: 986   score: 3.0   memory length: 181283   epsilon: 0.919528840001747    steps: 260     evaluation reward: 1.62\n",
            "episode: 987   score: 4.0   memory length: 181565   epsilon: 0.919249660001753    steps: 282     evaluation reward: 1.64\n",
            "episode: 988   score: 4.0   memory length: 181875   epsilon: 0.9189427600017597    steps: 310     evaluation reward: 1.65\n",
            "episode: 989   score: 0.0   memory length: 182000   epsilon: 0.9188190100017624    steps: 125     evaluation reward: 1.63\n",
            "episode: 990   score: 1.0   memory length: 182174   epsilon: 0.9186467500017661    steps: 174     evaluation reward: 1.63\n",
            "episode: 991   score: 2.0   memory length: 182393   epsilon: 0.9184299400017708    steps: 219     evaluation reward: 1.65\n",
            "episode: 992   score: 4.0   memory length: 182674   epsilon: 0.9181517500017768    steps: 281     evaluation reward: 1.65\n",
            "episode: 993   score: 2.0   memory length: 182867   epsilon: 0.917960680001781    steps: 193     evaluation reward: 1.67\n",
            "episode: 994   score: 1.0   memory length: 183031   epsilon: 0.9177983200017845    steps: 164     evaluation reward: 1.64\n",
            "episode: 995   score: 0.0   memory length: 183158   epsilon: 0.9176725900017872    steps: 127     evaluation reward: 1.63\n",
            "episode: 996   score: 2.0   memory length: 183368   epsilon: 0.9174646900017918    steps: 210     evaluation reward: 1.65\n",
            "episode: 997   score: 1.0   memory length: 183552   epsilon: 0.9172825300017957    steps: 184     evaluation reward: 1.62\n",
            "episode: 998   score: 1.0   memory length: 183712   epsilon: 0.9171241300017992    steps: 160     evaluation reward: 1.62\n",
            "episode: 999   score: 6.0   memory length: 184049   epsilon: 0.9167905000018064    steps: 337     evaluation reward: 1.67\n",
            "episode: 1000   score: 0.0   memory length: 184183   epsilon: 0.9166578400018093    steps: 134     evaluation reward: 1.65\n",
            "episode: 1001   score: 3.0   memory length: 184391   epsilon: 0.9164519200018137    steps: 208     evaluation reward: 1.65\n",
            "episode: 1002   score: 2.0   memory length: 184597   epsilon: 0.9162479800018182    steps: 206     evaluation reward: 1.63\n",
            "episode: 1003   score: 1.0   memory length: 184751   epsilon: 0.9160955200018215    steps: 154     evaluation reward: 1.58\n",
            "episode: 1004   score: 1.0   memory length: 184905   epsilon: 0.9159430600018248    steps: 154     evaluation reward: 1.55\n",
            "episode: 1005   score: 1.0   memory length: 185080   epsilon: 0.9157698100018286    steps: 175     evaluation reward: 1.54\n",
            "episode: 1006   score: 3.0   memory length: 185350   epsilon: 0.9155025100018344    steps: 270     evaluation reward: 1.55\n",
            "episode: 1007   score: 2.0   memory length: 185573   epsilon: 0.9152817400018392    steps: 223     evaluation reward: 1.57\n",
            "episode: 1008   score: 1.0   memory length: 185747   epsilon: 0.9151094800018429    steps: 174     evaluation reward: 1.58\n",
            "episode: 1009   score: 2.0   memory length: 185940   epsilon: 0.914918410001847    steps: 193     evaluation reward: 1.59\n",
            "episode: 1010   score: 0.0   memory length: 186066   epsilon: 0.9147936700018497    steps: 126     evaluation reward: 1.58\n",
            "episode: 1011   score: 2.0   memory length: 186294   epsilon: 0.9145679500018546    steps: 228     evaluation reward: 1.59\n",
            "episode: 1012   score: 1.0   memory length: 186456   epsilon: 0.9144075700018581    steps: 162     evaluation reward: 1.58\n",
            "episode: 1013   score: 2.0   memory length: 186665   epsilon: 0.9142006600018626    steps: 209     evaluation reward: 1.6\n",
            "episode: 1014   score: 4.0   memory length: 186935   epsilon: 0.9139333600018684    steps: 270     evaluation reward: 1.64\n",
            "episode: 1015   score: 2.0   memory length: 187161   epsilon: 0.9137096200018733    steps: 226     evaluation reward: 1.66\n",
            "episode: 1016   score: 1.0   memory length: 187337   epsilon: 0.9135353800018771    steps: 176     evaluation reward: 1.67\n",
            "episode: 1017   score: 4.0   memory length: 187598   epsilon: 0.9132769900018827    steps: 261     evaluation reward: 1.71\n",
            "episode: 1018   score: 2.0   memory length: 187799   epsilon: 0.913078000001887    steps: 201     evaluation reward: 1.72\n",
            "episode: 1019   score: 2.0   memory length: 187985   epsilon: 0.912893860001891    steps: 186     evaluation reward: 1.71\n",
            "episode: 1020   score: 2.0   memory length: 188206   epsilon: 0.9126750700018957    steps: 221     evaluation reward: 1.72\n",
            "episode: 1021   score: 1.0   memory length: 188362   epsilon: 0.9125206300018991    steps: 156     evaluation reward: 1.72\n",
            "episode: 1022   score: 3.0   memory length: 188599   epsilon: 0.9122860000019042    steps: 237     evaluation reward: 1.74\n",
            "episode: 1023   score: 2.0   memory length: 188822   epsilon: 0.912065230001909    steps: 223     evaluation reward: 1.72\n",
            "episode: 1024   score: 5.0   memory length: 189153   epsilon: 0.9117375400019161    steps: 331     evaluation reward: 1.74\n",
            "episode: 1025   score: 2.0   memory length: 189335   epsilon: 0.91155736000192    steps: 182     evaluation reward: 1.76\n",
            "episode: 1026   score: 1.0   memory length: 189495   epsilon: 0.9113989600019234    steps: 160     evaluation reward: 1.76\n",
            "episode: 1027   score: 2.0   memory length: 189691   epsilon: 0.9112049200019277    steps: 196     evaluation reward: 1.78\n",
            "episode: 1028   score: 2.0   memory length: 189914   epsilon: 0.9109841500019324    steps: 223     evaluation reward: 1.79\n",
            "episode: 1029   score: 3.0   memory length: 190147   epsilon: 0.9107534800019375    steps: 233     evaluation reward: 1.8\n",
            "episode: 1030   score: 3.0   memory length: 190368   epsilon: 0.9105346900019422    steps: 221     evaluation reward: 1.83\n",
            "episode: 1031   score: 2.0   memory length: 190581   epsilon: 0.9103238200019468    steps: 213     evaluation reward: 1.85\n",
            "episode: 1032   score: 0.0   memory length: 190707   epsilon: 0.9101990800019495    steps: 126     evaluation reward: 1.82\n",
            "episode: 1033   score: 2.0   memory length: 190918   epsilon: 0.909990190001954    steps: 211     evaluation reward: 1.83\n",
            "episode: 1034   score: 1.0   memory length: 191096   epsilon: 0.9098139700019579    steps: 178     evaluation reward: 1.83\n",
            "episode: 1035   score: 3.0   memory length: 191328   epsilon: 0.9095842900019628    steps: 232     evaluation reward: 1.84\n",
            "episode: 1036   score: 0.0   memory length: 191455   epsilon: 0.9094585600019656    steps: 127     evaluation reward: 1.81\n",
            "episode: 1037   score: 4.0   memory length: 191718   epsilon: 0.9091981900019712    steps: 263     evaluation reward: 1.82\n",
            "episode: 1038   score: 3.0   memory length: 191947   epsilon: 0.9089714800019761    steps: 229     evaluation reward: 1.82\n",
            "episode: 1039   score: 3.0   memory length: 192198   epsilon: 0.9087229900019815    steps: 251     evaluation reward: 1.85\n",
            "episode: 1040   score: 2.0   memory length: 192415   epsilon: 0.9085081600019862    steps: 217     evaluation reward: 1.87\n",
            "episode: 1041   score: 0.0   memory length: 192547   epsilon: 0.908377480001989    steps: 132     evaluation reward: 1.87\n",
            "episode: 1042   score: 2.0   memory length: 192771   epsilon: 0.9081557200019938    steps: 224     evaluation reward: 1.85\n",
            "episode: 1043   score: 1.0   memory length: 192950   epsilon: 0.9079785100019977    steps: 179     evaluation reward: 1.84\n",
            "episode: 1044   score: 3.0   memory length: 193189   epsilon: 0.9077419000020028    steps: 239     evaluation reward: 1.86\n",
            "episode: 1045   score: 3.0   memory length: 193445   epsilon: 0.9074884600020083    steps: 256     evaluation reward: 1.89\n",
            "episode: 1046   score: 2.0   memory length: 193658   epsilon: 0.9072775900020129    steps: 213     evaluation reward: 1.86\n",
            "episode: 1047   score: 6.0   memory length: 194003   epsilon: 0.9069360400020203    steps: 345     evaluation reward: 1.9\n",
            "episode: 1048   score: 4.0   memory length: 194279   epsilon: 0.9066628000020263    steps: 276     evaluation reward: 1.92\n",
            "episode: 1049   score: 1.0   memory length: 194445   epsilon: 0.9064984600020298    steps: 166     evaluation reward: 1.93\n",
            "episode: 1050   score: 2.0   memory length: 194646   epsilon: 0.9062994700020341    steps: 201     evaluation reward: 1.93\n",
            "episode: 1051   score: 2.0   memory length: 194841   epsilon: 0.9061064200020383    steps: 195     evaluation reward: 1.95\n",
            "episode: 1052   score: 6.0   memory length: 195216   epsilon: 0.9057351700020464    steps: 375     evaluation reward: 2.0\n",
            "episode: 1053   score: 0.0   memory length: 195365   epsilon: 0.9055876600020496    steps: 149     evaluation reward: 1.99\n",
            "episode: 1054   score: 1.0   memory length: 195525   epsilon: 0.905429260002053    steps: 160     evaluation reward: 1.96\n",
            "episode: 1055   score: 3.0   memory length: 195758   epsilon: 0.905198590002058    steps: 233     evaluation reward: 1.97\n",
            "episode: 1056   score: 3.0   memory length: 195988   epsilon: 0.904970890002063    steps: 230     evaluation reward: 1.99\n",
            "episode: 1057   score: 0.0   memory length: 196116   epsilon: 0.9048441700020657    steps: 128     evaluation reward: 1.96\n",
            "episode: 1058   score: 2.0   memory length: 196321   epsilon: 0.9046412200020701    steps: 205     evaluation reward: 1.98\n",
            "episode: 1059   score: 4.0   memory length: 196611   epsilon: 0.9043541200020764    steps: 290     evaluation reward: 1.99\n",
            "episode: 1060   score: 1.0   memory length: 196797   epsilon: 0.9041699800020804    steps: 186     evaluation reward: 1.97\n",
            "episode: 1061   score: 2.0   memory length: 196984   epsilon: 0.9039848500020844    steps: 187     evaluation reward: 1.97\n",
            "episode: 1062   score: 1.0   memory length: 197142   epsilon: 0.9038284300020878    steps: 158     evaluation reward: 1.96\n",
            "episode: 1063   score: 1.0   memory length: 197323   epsilon: 0.9036492400020917    steps: 181     evaluation reward: 1.92\n",
            "episode: 1064   score: 0.0   memory length: 197453   epsilon: 0.9035205400020945    steps: 130     evaluation reward: 1.91\n",
            "episode: 1065   score: 3.0   memory length: 197669   epsilon: 0.9033067000020991    steps: 216     evaluation reward: 1.94\n",
            "episode: 1066   score: 2.0   memory length: 197869   epsilon: 0.9031087000021034    steps: 200     evaluation reward: 1.93\n",
            "episode: 1067   score: 3.0   memory length: 198102   epsilon: 0.9028780300021084    steps: 233     evaluation reward: 1.94\n",
            "episode: 1068   score: 2.0   memory length: 198290   epsilon: 0.9026919100021125    steps: 188     evaluation reward: 1.95\n",
            "episode: 1069   score: 3.0   memory length: 198560   epsilon: 0.9024246100021183    steps: 270     evaluation reward: 1.97\n",
            "episode: 1070   score: 3.0   memory length: 198816   epsilon: 0.9021711700021238    steps: 256     evaluation reward: 1.98\n",
            "episode: 1071   score: 7.0   memory length: 199081   epsilon: 0.9019088200021295    steps: 265     evaluation reward: 2.03\n",
            "episode: 1072   score: 1.0   memory length: 199265   epsilon: 0.9017266600021334    steps: 184     evaluation reward: 2.01\n",
            "episode: 1073   score: 1.0   memory length: 199436   epsilon: 0.9015573700021371    steps: 171     evaluation reward: 2.02\n",
            "episode: 1074   score: 2.0   memory length: 199640   epsilon: 0.9013554100021415    steps: 204     evaluation reward: 2.02\n",
            "episode: 1075   score: 3.0   memory length: 199890   epsilon: 0.9011079100021469    steps: 250     evaluation reward: 2.05\n",
            "now time :  2019-12-12 18:18:28.133746\n",
            "episode: 1076   score: 11.0   memory length: 200354   epsilon: 0.9006485500021568    steps: 464     evaluation reward: 2.15\n",
            "episode: 1077   score: 3.0   memory length: 200603   epsilon: 0.9004020400021622    steps: 249     evaluation reward: 2.17\n",
            "episode: 1078   score: 0.0   memory length: 200727   epsilon: 0.9002792800021648    steps: 124     evaluation reward: 2.16\n",
            "episode: 1079   score: 0.0   memory length: 200854   epsilon: 0.9001535500021676    steps: 127     evaluation reward: 2.15\n",
            "episode: 1080   score: 3.0   memory length: 201105   epsilon: 0.899905060002173    steps: 251     evaluation reward: 2.17\n",
            "episode: 1081   score: 0.0   memory length: 201238   epsilon: 0.8997733900021758    steps: 133     evaluation reward: 2.14\n",
            "episode: 1082   score: 2.0   memory length: 201448   epsilon: 0.8995654900021803    steps: 210     evaluation reward: 2.14\n",
            "episode: 1083   score: 0.0   memory length: 201587   epsilon: 0.8994278800021833    steps: 139     evaluation reward: 2.13\n",
            "episode: 1084   score: 2.0   memory length: 201805   epsilon: 0.899212060002188    steps: 218     evaluation reward: 2.15\n",
            "episode: 1085   score: 5.0   memory length: 202122   epsilon: 0.8988982300021948    steps: 317     evaluation reward: 2.19\n",
            "episode: 1086   score: 6.0   memory length: 202507   epsilon: 0.8985170800022031    steps: 385     evaluation reward: 2.22\n",
            "episode: 1087   score: 0.0   memory length: 202633   epsilon: 0.8983923400022058    steps: 126     evaluation reward: 2.18\n",
            "episode: 1088   score: 0.0   memory length: 202766   epsilon: 0.8982606700022087    steps: 133     evaluation reward: 2.14\n",
            "episode: 1089   score: 2.0   memory length: 202962   epsilon: 0.8980666300022129    steps: 196     evaluation reward: 2.16\n",
            "episode: 1090   score: 1.0   memory length: 203121   epsilon: 0.8979092200022163    steps: 159     evaluation reward: 2.16\n",
            "episode: 1091   score: 2.0   memory length: 203310   epsilon: 0.8977221100022204    steps: 189     evaluation reward: 2.16\n",
            "episode: 1092   score: 2.0   memory length: 203495   epsilon: 0.8975389600022243    steps: 185     evaluation reward: 2.14\n",
            "episode: 1093   score: 1.0   memory length: 203676   epsilon: 0.8973597700022282    steps: 181     evaluation reward: 2.13\n",
            "episode: 1094   score: 0.0   memory length: 203807   epsilon: 0.897230080002231    steps: 131     evaluation reward: 2.12\n",
            "episode: 1095   score: 2.0   memory length: 204011   epsilon: 0.8970281200022354    steps: 204     evaluation reward: 2.14\n",
            "episode: 1096   score: 1.0   memory length: 204167   epsilon: 0.8968736800022388    steps: 156     evaluation reward: 2.13\n",
            "episode: 1097   score: 3.0   memory length: 204417   epsilon: 0.8966261800022441    steps: 250     evaluation reward: 2.15\n",
            "episode: 1098   score: 4.0   memory length: 204679   epsilon: 0.8963668000022498    steps: 262     evaluation reward: 2.18\n",
            "episode: 1099   score: 2.0   memory length: 204895   epsilon: 0.8961529600022544    steps: 216     evaluation reward: 2.14\n",
            "episode: 1100   score: 2.0   memory length: 205101   epsilon: 0.8959490200022588    steps: 206     evaluation reward: 2.16\n",
            "episode: 1101   score: 2.0   memory length: 205294   epsilon: 0.895757950002263    steps: 193     evaluation reward: 2.15\n",
            "episode: 1102   score: 3.0   memory length: 205509   epsilon: 0.8955451000022676    steps: 215     evaluation reward: 2.16\n",
            "episode: 1103   score: 2.0   memory length: 205715   epsilon: 0.895341160002272    steps: 206     evaluation reward: 2.17\n",
            "episode: 1104   score: 2.0   memory length: 205925   epsilon: 0.8951332600022766    steps: 210     evaluation reward: 2.18\n",
            "episode: 1105   score: 2.0   memory length: 206165   epsilon: 0.8948956600022817    steps: 240     evaluation reward: 2.19\n",
            "episode: 1106   score: 2.0   memory length: 206381   epsilon: 0.8946818200022864    steps: 216     evaluation reward: 2.18\n",
            "episode: 1107   score: 0.0   memory length: 206517   epsilon: 0.8945471800022893    steps: 136     evaluation reward: 2.16\n",
            "episode: 1108   score: 2.0   memory length: 206743   epsilon: 0.8943234400022941    steps: 226     evaluation reward: 2.17\n",
            "episode: 1109   score: 4.0   memory length: 207007   epsilon: 0.8940620800022998    steps: 264     evaluation reward: 2.19\n",
            "episode: 1110   score: 0.0   memory length: 207134   epsilon: 0.8939363500023025    steps: 127     evaluation reward: 2.19\n",
            "episode: 1111   score: 2.0   memory length: 207336   epsilon: 0.8937363700023069    steps: 202     evaluation reward: 2.19\n",
            "episode: 1112   score: 1.0   memory length: 207490   epsilon: 0.8935839100023102    steps: 154     evaluation reward: 2.19\n",
            "episode: 1113   score: 5.0   memory length: 207803   epsilon: 0.8932740400023169    steps: 313     evaluation reward: 2.22\n",
            "episode: 1114   score: 0.0   memory length: 207933   epsilon: 0.8931453400023197    steps: 130     evaluation reward: 2.18\n",
            "episode: 1115   score: 3.0   memory length: 208172   epsilon: 0.8929087300023248    steps: 239     evaluation reward: 2.19\n",
            "episode: 1116   score: 0.0   memory length: 208296   epsilon: 0.8927859700023275    steps: 124     evaluation reward: 2.18\n",
            "episode: 1117   score: 1.0   memory length: 208474   epsilon: 0.8926097500023313    steps: 178     evaluation reward: 2.15\n",
            "episode: 1118   score: 1.0   memory length: 208637   epsilon: 0.8924483800023348    steps: 163     evaluation reward: 2.14\n",
            "episode: 1119   score: 2.0   memory length: 208842   epsilon: 0.8922454300023392    steps: 205     evaluation reward: 2.14\n",
            "episode: 1120   score: 1.0   memory length: 209006   epsilon: 0.8920830700023428    steps: 164     evaluation reward: 2.13\n",
            "episode: 1121   score: 0.0   memory length: 209140   epsilon: 0.8919504100023457    steps: 134     evaluation reward: 2.12\n",
            "episode: 1122   score: 3.0   memory length: 209395   epsilon: 0.8916979600023511    steps: 255     evaluation reward: 2.12\n",
            "episode: 1123   score: 1.0   memory length: 209565   epsilon: 0.8915296600023548    steps: 170     evaluation reward: 2.11\n",
            "episode: 1124   score: 3.0   memory length: 209804   epsilon: 0.8912930500023599    steps: 239     evaluation reward: 2.09\n",
            "episode: 1125   score: 3.0   memory length: 210084   epsilon: 0.8910158500023659    steps: 280     evaluation reward: 2.1\n",
            "episode: 1126   score: 2.0   memory length: 210287   epsilon: 0.8908148800023703    steps: 203     evaluation reward: 2.11\n",
            "episode: 1127   score: 2.0   memory length: 210495   epsilon: 0.8906089600023748    steps: 208     evaluation reward: 2.11\n",
            "episode: 1128   score: 1.0   memory length: 210668   epsilon: 0.8904376900023785    steps: 173     evaluation reward: 2.1\n",
            "episode: 1129   score: 2.0   memory length: 210879   epsilon: 0.890228800002383    steps: 211     evaluation reward: 2.09\n",
            "episode: 1130   score: 1.0   memory length: 211040   epsilon: 0.8900694100023865    steps: 161     evaluation reward: 2.07\n",
            "episode: 1131   score: 0.0   memory length: 211166   epsilon: 0.8899446700023892    steps: 126     evaluation reward: 2.05\n",
            "episode: 1132   score: 1.0   memory length: 211349   epsilon: 0.8897635000023931    steps: 183     evaluation reward: 2.06\n",
            "episode: 1133   score: 2.0   memory length: 211550   epsilon: 0.8895645100023974    steps: 201     evaluation reward: 2.06\n",
            "episode: 1134   score: 2.0   memory length: 211749   epsilon: 0.8893675000024017    steps: 199     evaluation reward: 2.07\n",
            "episode: 1135   score: 2.0   memory length: 211959   epsilon: 0.8891596000024062    steps: 210     evaluation reward: 2.06\n",
            "episode: 1136   score: 4.0   memory length: 212239   epsilon: 0.8888824000024123    steps: 280     evaluation reward: 2.1\n",
            "episode: 1137   score: 0.0   memory length: 212379   epsilon: 0.8887438000024153    steps: 140     evaluation reward: 2.06\n",
            "episode: 1138   score: 1.0   memory length: 212541   epsilon: 0.8885834200024187    steps: 162     evaluation reward: 2.04\n",
            "episode: 1139   score: 0.0   memory length: 212666   epsilon: 0.8884596700024214    steps: 125     evaluation reward: 2.01\n",
            "episode: 1140   score: 1.0   memory length: 212843   epsilon: 0.8882844400024252    steps: 177     evaluation reward: 2.0\n",
            "episode: 1141   score: 1.0   memory length: 213014   epsilon: 0.8881151500024289    steps: 171     evaluation reward: 2.01\n",
            "episode: 1142   score: 4.0   memory length: 213302   epsilon: 0.8878300300024351    steps: 288     evaluation reward: 2.03\n",
            "episode: 1143   score: 1.0   memory length: 213468   epsilon: 0.8876656900024387    steps: 166     evaluation reward: 2.03\n",
            "episode: 1144   score: 1.0   memory length: 213640   epsilon: 0.8874954100024424    steps: 172     evaluation reward: 2.01\n",
            "episode: 1145   score: 4.0   memory length: 213889   epsilon: 0.8872489000024477    steps: 249     evaluation reward: 2.02\n",
            "episode: 1146   score: 4.0   memory length: 214185   epsilon: 0.8869558600024541    steps: 296     evaluation reward: 2.04\n",
            "episode: 1147   score: 3.0   memory length: 214422   epsilon: 0.8867212300024592    steps: 237     evaluation reward: 2.01\n",
            "episode: 1148   score: 4.0   memory length: 214701   epsilon: 0.8864450200024652    steps: 279     evaluation reward: 2.01\n",
            "episode: 1149   score: 2.0   memory length: 214911   epsilon: 0.8862371200024697    steps: 210     evaluation reward: 2.02\n",
            "episode: 1150   score: 1.0   memory length: 215066   epsilon: 0.886083670002473    steps: 155     evaluation reward: 2.01\n",
            "episode: 1151   score: 2.0   memory length: 215279   epsilon: 0.8858728000024776    steps: 213     evaluation reward: 2.01\n",
            "episode: 1152   score: 1.0   memory length: 215452   epsilon: 0.8857015300024813    steps: 173     evaluation reward: 1.96\n",
            "episode: 1153   score: 1.0   memory length: 215622   epsilon: 0.885533230002485    steps: 170     evaluation reward: 1.97\n",
            "episode: 1154   score: 5.0   memory length: 215939   epsilon: 0.8852194000024918    steps: 317     evaluation reward: 2.01\n",
            "episode: 1155   score: 1.0   memory length: 216090   epsilon: 0.885069910002495    steps: 151     evaluation reward: 1.99\n",
            "episode: 1156   score: 1.0   memory length: 216259   epsilon: 0.8849026000024987    steps: 169     evaluation reward: 1.97\n",
            "episode: 1157   score: 1.0   memory length: 216422   epsilon: 0.8847412300025022    steps: 163     evaluation reward: 1.98\n",
            "episode: 1158   score: 3.0   memory length: 216704   epsilon: 0.8844620500025082    steps: 282     evaluation reward: 1.99\n",
            "episode: 1159   score: 3.0   memory length: 216960   epsilon: 0.8842086100025137    steps: 256     evaluation reward: 1.98\n",
            "episode: 1160   score: 3.0   memory length: 217210   epsilon: 0.8839611100025191    steps: 250     evaluation reward: 2.0\n",
            "episode: 1161   score: 5.0   memory length: 217523   epsilon: 0.8836512400025258    steps: 313     evaluation reward: 2.03\n",
            "episode: 1162   score: 5.0   memory length: 217813   epsilon: 0.883364140002532    steps: 290     evaluation reward: 2.07\n",
            "episode: 1163   score: 1.0   memory length: 217993   epsilon: 0.8831859400025359    steps: 180     evaluation reward: 2.07\n",
            "episode: 1164   score: 4.0   memory length: 218319   epsilon: 0.8828632000025429    steps: 326     evaluation reward: 2.11\n",
            "episode: 1165   score: 1.0   memory length: 218483   epsilon: 0.8827008400025464    steps: 164     evaluation reward: 2.09\n",
            "episode: 1166   score: 3.0   memory length: 218700   epsilon: 0.8824860100025511    steps: 217     evaluation reward: 2.1\n",
            "episode: 1167   score: 3.0   memory length: 218959   epsilon: 0.8822296000025567    steps: 259     evaluation reward: 2.1\n",
            "episode: 1168   score: 4.0   memory length: 219236   epsilon: 0.8819553700025626    steps: 277     evaluation reward: 2.12\n",
            "episode: 1169   score: 6.0   memory length: 219606   epsilon: 0.8815890700025706    steps: 370     evaluation reward: 2.15\n",
            "episode: 1170   score: 2.0   memory length: 219801   epsilon: 0.8813960200025748    steps: 195     evaluation reward: 2.14\n",
            "episode: 1171   score: 2.0   memory length: 220021   epsilon: 0.8811782200025795    steps: 220     evaluation reward: 2.09\n",
            "episode: 1172   score: 1.0   memory length: 220183   epsilon: 0.881017840002583    steps: 162     evaluation reward: 2.09\n",
            "episode: 1173   score: 6.0   memory length: 220556   epsilon: 0.880648570002591    steps: 373     evaluation reward: 2.14\n",
            "episode: 1174   score: 2.0   memory length: 220744   epsilon: 0.880462450002595    steps: 188     evaluation reward: 2.14\n",
            "episode: 1175   score: 1.0   memory length: 220900   epsilon: 0.8803080100025984    steps: 156     evaluation reward: 2.12\n",
            "episode: 1176   score: 2.0   memory length: 221119   epsilon: 0.8800912000026031    steps: 219     evaluation reward: 2.03\n",
            "episode: 1177   score: 3.0   memory length: 221363   epsilon: 0.8798496400026083    steps: 244     evaluation reward: 2.03\n",
            "episode: 1178   score: 5.0   memory length: 221660   epsilon: 0.8795556100026147    steps: 297     evaluation reward: 2.08\n",
            "episode: 1179   score: 8.0   memory length: 222053   epsilon: 0.8791665400026232    steps: 393     evaluation reward: 2.16\n",
            "episode: 1180   score: 3.0   memory length: 222318   epsilon: 0.8789041900026289    steps: 265     evaluation reward: 2.16\n",
            "episode: 1181   score: 1.0   memory length: 222482   epsilon: 0.8787418300026324    steps: 164     evaluation reward: 2.17\n",
            "episode: 1182   score: 3.0   memory length: 222745   epsilon: 0.878481460002638    steps: 263     evaluation reward: 2.18\n",
            "episode: 1183   score: 1.0   memory length: 222905   epsilon: 0.8783230600026415    steps: 160     evaluation reward: 2.19\n",
            "episode: 1184   score: 3.0   memory length: 223173   epsilon: 0.8780577400026472    steps: 268     evaluation reward: 2.2\n",
            "episode: 1185   score: 2.0   memory length: 223379   epsilon: 0.8778538000026517    steps: 206     evaluation reward: 2.17\n",
            "episode: 1186   score: 2.0   memory length: 223590   epsilon: 0.8776449100026562    steps: 211     evaluation reward: 2.13\n",
            "episode: 1187   score: 3.0   memory length: 223862   epsilon: 0.877375630002662    steps: 272     evaluation reward: 2.16\n",
            "episode: 1188   score: 4.0   memory length: 224109   epsilon: 0.8771311000026674    steps: 247     evaluation reward: 2.2\n",
            "episode: 1189   score: 1.0   memory length: 224263   epsilon: 0.8769786400026707    steps: 154     evaluation reward: 2.19\n",
            "episode: 1190   score: 5.0   memory length: 224543   epsilon: 0.8767014400026767    steps: 280     evaluation reward: 2.23\n",
            "episode: 1191   score: 0.0   memory length: 224668   epsilon: 0.8765776900026794    steps: 125     evaluation reward: 2.21\n",
            "episode: 1192   score: 7.0   memory length: 224919   epsilon: 0.8763292000026848    steps: 251     evaluation reward: 2.26\n",
            "episode: 1193   score: 2.0   memory length: 225139   epsilon: 0.8761114000026895    steps: 220     evaluation reward: 2.27\n",
            "episode: 1194   score: 1.0   memory length: 225314   epsilon: 0.8759381500026933    steps: 175     evaluation reward: 2.28\n",
            "episode: 1195   score: 4.0   memory length: 225595   epsilon: 0.8756599600026993    steps: 281     evaluation reward: 2.3\n",
            "episode: 1196   score: 1.0   memory length: 225753   epsilon: 0.8755035400027027    steps: 158     evaluation reward: 2.3\n",
            "episode: 1197   score: 2.0   memory length: 225950   epsilon: 0.8753085100027069    steps: 197     evaluation reward: 2.29\n",
            "episode: 1198   score: 3.0   memory length: 226170   epsilon: 0.8750907100027117    steps: 220     evaluation reward: 2.28\n",
            "episode: 1199   score: 1.0   memory length: 226346   epsilon: 0.8749164700027154    steps: 176     evaluation reward: 2.27\n",
            "episode: 1200   score: 2.0   memory length: 226560   epsilon: 0.87470461000272    steps: 214     evaluation reward: 2.27\n",
            "episode: 1201   score: 2.0   memory length: 226765   epsilon: 0.8745016600027244    steps: 205     evaluation reward: 2.27\n",
            "episode: 1202   score: 2.0   memory length: 226951   epsilon: 0.8743175200027284    steps: 186     evaluation reward: 2.26\n",
            "episode: 1203   score: 4.0   memory length: 227216   epsilon: 0.8740551700027341    steps: 265     evaluation reward: 2.28\n",
            "episode: 1204   score: 0.0   memory length: 227342   epsilon: 0.8739304300027368    steps: 126     evaluation reward: 2.26\n",
            "episode: 1205   score: 5.0   memory length: 227720   epsilon: 0.873556210002745    steps: 378     evaluation reward: 2.29\n",
            "episode: 1206   score: 0.0   memory length: 227856   epsilon: 0.8734215700027479    steps: 136     evaluation reward: 2.27\n",
            "episode: 1207   score: 1.0   memory length: 228016   epsilon: 0.8732631700027513    steps: 160     evaluation reward: 2.28\n",
            "episode: 1208   score: 0.0   memory length: 228142   epsilon: 0.873138430002754    steps: 126     evaluation reward: 2.26\n",
            "episode: 1209   score: 2.0   memory length: 228329   epsilon: 0.8729533000027581    steps: 187     evaluation reward: 2.24\n",
            "episode: 1210   score: 1.0   memory length: 228493   epsilon: 0.8727909400027616    steps: 164     evaluation reward: 2.25\n",
            "episode: 1211   score: 8.0   memory length: 228806   epsilon: 0.8724810700027683    steps: 313     evaluation reward: 2.31\n",
            "episode: 1212   score: 1.0   memory length: 228971   epsilon: 0.8723177200027719    steps: 165     evaluation reward: 2.31\n",
            "episode: 1213   score: 3.0   memory length: 229242   epsilon: 0.8720494300027777    steps: 271     evaluation reward: 2.29\n",
            "episode: 1214   score: 5.0   memory length: 229624   epsilon: 0.8716712500027859    steps: 382     evaluation reward: 2.34\n",
            "episode: 1215   score: 1.0   memory length: 229785   epsilon: 0.8715118600027894    steps: 161     evaluation reward: 2.32\n",
            "episode: 1216   score: 1.0   memory length: 229972   epsilon: 0.8713267300027934    steps: 187     evaluation reward: 2.33\n",
            "episode: 1217   score: 2.0   memory length: 230176   epsilon: 0.8711247700027978    steps: 204     evaluation reward: 2.34\n",
            "episode: 1218   score: 3.0   memory length: 230448   epsilon: 0.8708554900028036    steps: 272     evaluation reward: 2.36\n",
            "episode: 1219   score: 4.0   memory length: 230724   epsilon: 0.8705822500028095    steps: 276     evaluation reward: 2.38\n",
            "episode: 1220   score: 6.0   memory length: 231094   epsilon: 0.8702159500028175    steps: 370     evaluation reward: 2.43\n",
            "episode: 1221   score: 2.0   memory length: 231307   epsilon: 0.8700050800028221    steps: 213     evaluation reward: 2.45\n",
            "episode: 1222   score: 0.0   memory length: 231431   epsilon: 0.8698823200028247    steps: 124     evaluation reward: 2.42\n",
            "episode: 1223   score: 1.0   memory length: 231601   epsilon: 0.8697140200028284    steps: 170     evaluation reward: 2.42\n",
            "episode: 1224   score: 1.0   memory length: 231780   epsilon: 0.8695368100028322    steps: 179     evaluation reward: 2.4\n",
            "episode: 1225   score: 2.0   memory length: 231983   epsilon: 0.8693358400028366    steps: 203     evaluation reward: 2.39\n",
            "episode: 1226   score: 2.0   memory length: 232174   epsilon: 0.8691467500028407    steps: 191     evaluation reward: 2.39\n",
            "episode: 1227   score: 1.0   memory length: 232346   epsilon: 0.8689764700028444    steps: 172     evaluation reward: 2.38\n",
            "episode: 1228   score: 2.0   memory length: 232555   epsilon: 0.8687695600028489    steps: 209     evaluation reward: 2.39\n",
            "episode: 1229   score: 1.0   memory length: 232741   epsilon: 0.8685854200028529    steps: 186     evaluation reward: 2.38\n",
            "episode: 1230   score: 3.0   memory length: 233011   epsilon: 0.8683181200028587    steps: 270     evaluation reward: 2.4\n",
            "episode: 1231   score: 2.0   memory length: 233240   epsilon: 0.8680914100028636    steps: 229     evaluation reward: 2.42\n",
            "episode: 1232   score: 2.0   memory length: 233427   epsilon: 0.8679062800028676    steps: 187     evaluation reward: 2.43\n",
            "episode: 1233   score: 3.0   memory length: 233648   epsilon: 0.8676874900028724    steps: 221     evaluation reward: 2.44\n",
            "episode: 1234   score: 5.0   memory length: 233991   epsilon: 0.8673479200028797    steps: 343     evaluation reward: 2.47\n",
            "episode: 1235   score: 1.0   memory length: 234145   epsilon: 0.8671954600028831    steps: 154     evaluation reward: 2.46\n",
            "episode: 1236   score: 0.0   memory length: 234275   epsilon: 0.8670667600028859    steps: 130     evaluation reward: 2.42\n",
            "episode: 1237   score: 2.0   memory length: 234476   epsilon: 0.8668677700028902    steps: 201     evaluation reward: 2.44\n",
            "episode: 1238   score: 0.0   memory length: 234602   epsilon: 0.8667430300028929    steps: 126     evaluation reward: 2.43\n",
            "episode: 1239   score: 2.0   memory length: 234791   epsilon: 0.8665559200028969    steps: 189     evaluation reward: 2.45\n",
            "episode: 1240   score: 3.0   memory length: 235038   epsilon: 0.8663113900029022    steps: 247     evaluation reward: 2.47\n",
            "episode: 1241   score: 2.0   memory length: 235231   epsilon: 0.8661203200029064    steps: 193     evaluation reward: 2.48\n",
            "episode: 1242   score: 0.0   memory length: 235358   epsilon: 0.8659945900029091    steps: 127     evaluation reward: 2.44\n",
            "episode: 1243   score: 2.0   memory length: 235541   epsilon: 0.8658134200029131    steps: 183     evaluation reward: 2.45\n",
            "episode: 1244   score: 4.0   memory length: 235806   epsilon: 0.8655510700029188    steps: 265     evaluation reward: 2.48\n",
            "episode: 1245   score: 1.0   memory length: 235985   epsilon: 0.8653738600029226    steps: 179     evaluation reward: 2.45\n",
            "episode: 1246   score: 6.0   memory length: 236371   epsilon: 0.8649917200029309    steps: 386     evaluation reward: 2.47\n",
            "episode: 1247   score: 2.0   memory length: 236590   epsilon: 0.8647749100029356    steps: 219     evaluation reward: 2.46\n",
            "episode: 1248   score: 2.0   memory length: 236787   epsilon: 0.8645798800029398    steps: 197     evaluation reward: 2.44\n",
            "episode: 1249   score: 3.0   memory length: 237036   epsilon: 0.8643333700029452    steps: 249     evaluation reward: 2.45\n",
            "episode: 1250   score: 0.0   memory length: 237170   epsilon: 0.8642007100029481    steps: 134     evaluation reward: 2.44\n",
            "episode: 1251   score: 2.0   memory length: 237376   epsilon: 0.8639967700029525    steps: 206     evaluation reward: 2.44\n",
            "episode: 1252   score: 4.0   memory length: 237641   epsilon: 0.8637344200029582    steps: 265     evaluation reward: 2.47\n",
            "episode: 1253   score: 0.0   memory length: 237769   epsilon: 0.8636077000029609    steps: 128     evaluation reward: 2.46\n",
            "episode: 1254   score: 5.0   memory length: 238089   epsilon: 0.8632909000029678    steps: 320     evaluation reward: 2.46\n",
            "episode: 1255   score: 2.0   memory length: 238309   epsilon: 0.8630731000029725    steps: 220     evaluation reward: 2.47\n",
            "episode: 1256   score: 3.0   memory length: 238566   epsilon: 0.8628186700029781    steps: 257     evaluation reward: 2.49\n",
            "episode: 1257   score: 3.0   memory length: 238847   epsilon: 0.8625404800029841    steps: 281     evaluation reward: 2.51\n",
            "episode: 1258   score: 3.0   memory length: 239099   epsilon: 0.8622910000029895    steps: 252     evaluation reward: 2.51\n",
            "episode: 1259   score: 0.0   memory length: 239231   epsilon: 0.8621603200029924    steps: 132     evaluation reward: 2.48\n",
            "episode: 1260   score: 1.0   memory length: 239388   epsilon: 0.8620048900029957    steps: 157     evaluation reward: 2.46\n",
            "episode: 1261   score: 0.0   memory length: 239526   epsilon: 0.8618682700029987    steps: 138     evaluation reward: 2.41\n",
            "episode: 1262   score: 4.0   memory length: 239794   epsilon: 0.8616029500030045    steps: 268     evaluation reward: 2.4\n",
            "episode: 1263   score: 2.0   memory length: 239995   epsilon: 0.8614039600030088    steps: 201     evaluation reward: 2.41\n",
            "episode: 1264   score: 2.0   memory length: 240201   epsilon: 0.8612000200030132    steps: 206     evaluation reward: 2.39\n",
            "episode: 1265   score: 3.0   memory length: 240464   epsilon: 0.8609396500030189    steps: 263     evaluation reward: 2.41\n",
            "episode: 1266   score: 2.0   memory length: 240693   epsilon: 0.8607129400030238    steps: 229     evaluation reward: 2.4\n",
            "episode: 1267   score: 5.0   memory length: 240974   epsilon: 0.8604347500030298    steps: 281     evaluation reward: 2.42\n",
            "episode: 1268   score: 2.0   memory length: 241180   epsilon: 0.8602308100030343    steps: 206     evaluation reward: 2.4\n",
            "episode: 1269   score: 4.0   memory length: 241462   epsilon: 0.8599516300030403    steps: 282     evaluation reward: 2.38\n",
            "episode: 1270   score: 3.0   memory length: 241712   epsilon: 0.8597041300030457    steps: 250     evaluation reward: 2.39\n",
            "episode: 1271   score: 3.0   memory length: 241943   epsilon: 0.8594754400030507    steps: 231     evaluation reward: 2.4\n",
            "episode: 1272   score: 3.0   memory length: 242177   epsilon: 0.8592437800030557    steps: 234     evaluation reward: 2.42\n",
            "episode: 1273   score: 1.0   memory length: 242351   epsilon: 0.8590715200030594    steps: 174     evaluation reward: 2.37\n",
            "episode: 1274   score: 2.0   memory length: 242548   epsilon: 0.8588764900030637    steps: 197     evaluation reward: 2.37\n",
            "episode: 1275   score: 7.0   memory length: 242801   epsilon: 0.8586260200030691    steps: 253     evaluation reward: 2.43\n",
            "episode: 1276   score: 2.0   memory length: 243010   epsilon: 0.8584191100030736    steps: 209     evaluation reward: 2.43\n",
            "episode: 1277   score: 3.0   memory length: 243232   epsilon: 0.8581993300030784    steps: 222     evaluation reward: 2.43\n",
            "episode: 1278   score: 1.0   memory length: 243388   epsilon: 0.8580448900030817    steps: 156     evaluation reward: 2.39\n",
            "episode: 1279   score: 2.0   memory length: 243593   epsilon: 0.8578419400030861    steps: 205     evaluation reward: 2.33\n",
            "episode: 1280   score: 2.0   memory length: 243802   epsilon: 0.8576350300030906    steps: 209     evaluation reward: 2.32\n",
            "episode: 1281   score: 3.0   memory length: 244030   epsilon: 0.8574093100030955    steps: 228     evaluation reward: 2.34\n",
            "episode: 1282   score: 4.0   memory length: 244361   epsilon: 0.8570816200031026    steps: 331     evaluation reward: 2.35\n",
            "episode: 1283   score: 4.0   memory length: 244623   epsilon: 0.8568222400031082    steps: 262     evaluation reward: 2.38\n",
            "episode: 1284   score: 2.0   memory length: 244823   epsilon: 0.8566242400031125    steps: 200     evaluation reward: 2.37\n",
            "episode: 1285   score: 2.0   memory length: 245019   epsilon: 0.8564302000031168    steps: 196     evaluation reward: 2.37\n",
            "episode: 1286   score: 3.0   memory length: 245272   epsilon: 0.8561797300031222    steps: 253     evaluation reward: 2.38\n",
            "episode: 1287   score: 3.0   memory length: 245512   epsilon: 0.8559421300031274    steps: 240     evaluation reward: 2.38\n",
            "episode: 1288   score: 2.0   memory length: 245718   epsilon: 0.8557381900031318    steps: 206     evaluation reward: 2.36\n",
            "episode: 1289   score: 2.0   memory length: 245902   epsilon: 0.8555560300031357    steps: 184     evaluation reward: 2.37\n",
            "episode: 1290   score: 1.0   memory length: 246089   epsilon: 0.8553709000031398    steps: 187     evaluation reward: 2.33\n",
            "episode: 1291   score: 2.0   memory length: 246313   epsilon: 0.8551491400031446    steps: 224     evaluation reward: 2.35\n",
            "episode: 1292   score: 4.0   memory length: 246605   epsilon: 0.8548600600031508    steps: 292     evaluation reward: 2.32\n",
            "episode: 1293   score: 0.0   memory length: 246732   epsilon: 0.8547343300031536    steps: 127     evaluation reward: 2.3\n",
            "episode: 1294   score: 1.0   memory length: 246893   epsilon: 0.854574940003157    steps: 161     evaluation reward: 2.3\n",
            "episode: 1295   score: 2.0   memory length: 247095   epsilon: 0.8543749600031614    steps: 202     evaluation reward: 2.28\n",
            "episode: 1296   score: 4.0   memory length: 247391   epsilon: 0.8540819200031677    steps: 296     evaluation reward: 2.31\n",
            "episode: 1297   score: 3.0   memory length: 247620   epsilon: 0.8538552100031727    steps: 229     evaluation reward: 2.32\n",
            "episode: 1298   score: 7.0   memory length: 248051   epsilon: 0.8534285200031819    steps: 431     evaluation reward: 2.36\n",
            "episode: 1299   score: 1.0   memory length: 248205   epsilon: 0.8532760600031852    steps: 154     evaluation reward: 2.36\n",
            "episode: 1300   score: 3.0   memory length: 248485   epsilon: 0.8529988600031913    steps: 280     evaluation reward: 2.37\n",
            "episode: 1301   score: 0.0   memory length: 248626   epsilon: 0.8528592700031943    steps: 141     evaluation reward: 2.35\n",
            "episode: 1302   score: 1.0   memory length: 248786   epsilon: 0.8527008700031977    steps: 160     evaluation reward: 2.34\n",
            "episode: 1303   score: 3.0   memory length: 249047   epsilon: 0.8524424800032033    steps: 261     evaluation reward: 2.33\n",
            "episode: 1304   score: 2.0   memory length: 249255   epsilon: 0.8522365600032078    steps: 208     evaluation reward: 2.35\n",
            "episode: 1305   score: 4.0   memory length: 249531   epsilon: 0.8519633200032137    steps: 276     evaluation reward: 2.34\n",
            "episode: 1306   score: 5.0   memory length: 249842   epsilon: 0.8516554300032204    steps: 311     evaluation reward: 2.39\n",
            "now time :  2019-12-12 18:38:21.168878\n",
            "episode: 1307   score: 2.0   memory length: 250028   epsilon: 0.8514712900032244    steps: 186     evaluation reward: 2.4\n",
            "episode: 1308   score: 4.0   memory length: 250326   epsilon: 0.8511762700032308    steps: 298     evaluation reward: 2.44\n",
            "episode: 1309   score: 2.0   memory length: 250527   epsilon: 0.8509772800032351    steps: 201     evaluation reward: 2.44\n",
            "episode: 1310   score: 0.0   memory length: 250658   epsilon: 0.850847590003238    steps: 131     evaluation reward: 2.43\n",
            "episode: 1311   score: 1.0   memory length: 250819   epsilon: 0.8506882000032414    steps: 161     evaluation reward: 2.36\n",
            "episode: 1312   score: 4.0   memory length: 251108   epsilon: 0.8504020900032476    steps: 289     evaluation reward: 2.39\n",
            "episode: 1313   score: 3.0   memory length: 251323   epsilon: 0.8501892400032522    steps: 215     evaluation reward: 2.39\n",
            "episode: 1314   score: 1.0   memory length: 251506   epsilon: 0.8500080700032562    steps: 183     evaluation reward: 2.35\n",
            "episode: 1315   score: 5.0   memory length: 251810   epsilon: 0.8497071100032627    steps: 304     evaluation reward: 2.39\n",
            "episode: 1316   score: 3.0   memory length: 252081   epsilon: 0.8494388200032685    steps: 271     evaluation reward: 2.41\n",
            "episode: 1317   score: 3.0   memory length: 252330   epsilon: 0.8491923100032739    steps: 249     evaluation reward: 2.42\n",
            "episode: 1318   score: 3.0   memory length: 252573   epsilon: 0.8489517400032791    steps: 243     evaluation reward: 2.42\n",
            "episode: 1319   score: 0.0   memory length: 252695   epsilon: 0.8488309600032817    steps: 122     evaluation reward: 2.38\n",
            "episode: 1320   score: 1.0   memory length: 252868   epsilon: 0.8486596900032854    steps: 173     evaluation reward: 2.33\n",
            "episode: 1321   score: 3.0   memory length: 253121   epsilon: 0.8484092200032909    steps: 253     evaluation reward: 2.34\n",
            "episode: 1322   score: 2.0   memory length: 253314   epsilon: 0.848218150003295    steps: 193     evaluation reward: 2.36\n",
            "episode: 1323   score: 4.0   memory length: 253605   epsilon: 0.8479300600033013    steps: 291     evaluation reward: 2.39\n",
            "episode: 1324   score: 2.0   memory length: 253820   epsilon: 0.8477172100033059    steps: 215     evaluation reward: 2.4\n",
            "episode: 1325   score: 1.0   memory length: 253976   epsilon: 0.8475627700033093    steps: 156     evaluation reward: 2.39\n",
            "episode: 1326   score: 0.0   memory length: 254102   epsilon: 0.847438030003312    steps: 126     evaluation reward: 2.37\n",
            "episode: 1327   score: 2.0   memory length: 254320   epsilon: 0.8472222100033167    steps: 218     evaluation reward: 2.38\n",
            "episode: 1328   score: 5.0   memory length: 254622   epsilon: 0.8469232300033231    steps: 302     evaluation reward: 2.41\n",
            "episode: 1329   score: 2.0   memory length: 254804   epsilon: 0.8467430500033271    steps: 182     evaluation reward: 2.42\n",
            "episode: 1330   score: 1.0   memory length: 254966   epsilon: 0.8465826700033305    steps: 162     evaluation reward: 2.4\n",
            "episode: 1331   score: 1.0   memory length: 255147   epsilon: 0.8464034800033344    steps: 181     evaluation reward: 2.39\n",
            "episode: 1332   score: 4.0   memory length: 255465   epsilon: 0.8460886600033413    steps: 318     evaluation reward: 2.41\n",
            "episode: 1333   score: 2.0   memory length: 255687   epsilon: 0.845868880003346    steps: 222     evaluation reward: 2.4\n",
            "episode: 1334   score: 4.0   memory length: 255954   epsilon: 0.8456045500033518    steps: 267     evaluation reward: 2.39\n",
            "episode: 1335   score: 6.0   memory length: 256313   epsilon: 0.8452491400033595    steps: 359     evaluation reward: 2.44\n",
            "episode: 1336   score: 3.0   memory length: 256561   epsilon: 0.8450036200033648    steps: 248     evaluation reward: 2.47\n",
            "episode: 1337   score: 4.0   memory length: 256811   epsilon: 0.8447561200033702    steps: 250     evaluation reward: 2.49\n",
            "episode: 1338   score: 3.0   memory length: 257071   epsilon: 0.8444987200033758    steps: 260     evaluation reward: 2.52\n",
            "episode: 1339   score: 6.0   memory length: 257415   epsilon: 0.8441581600033832    steps: 344     evaluation reward: 2.56\n",
            "episode: 1340   score: 1.0   memory length: 257571   epsilon: 0.8440037200033865    steps: 156     evaluation reward: 2.54\n",
            "episode: 1341   score: 2.0   memory length: 257774   epsilon: 0.8438027500033909    steps: 203     evaluation reward: 2.54\n",
            "episode: 1342   score: 2.0   memory length: 257972   epsilon: 0.8436067300033951    steps: 198     evaluation reward: 2.56\n",
            "episode: 1343   score: 3.0   memory length: 258217   epsilon: 0.8433641800034004    steps: 245     evaluation reward: 2.57\n",
            "episode: 1344   score: 1.0   memory length: 258407   epsilon: 0.8431760800034045    steps: 190     evaluation reward: 2.54\n",
            "episode: 1345   score: 5.0   memory length: 258703   epsilon: 0.8428830400034109    steps: 296     evaluation reward: 2.58\n",
            "episode: 1346   score: 4.0   memory length: 258987   epsilon: 0.842601880003417    steps: 284     evaluation reward: 2.56\n",
            "episode: 1347   score: 1.0   memory length: 259155   epsilon: 0.8424355600034206    steps: 168     evaluation reward: 2.55\n",
            "episode: 1348   score: 2.0   memory length: 259376   epsilon: 0.8422167700034253    steps: 221     evaluation reward: 2.55\n",
            "episode: 1349   score: 2.0   memory length: 259577   epsilon: 0.8420177800034296    steps: 201     evaluation reward: 2.54\n",
            "episode: 1350   score: 3.0   memory length: 259804   epsilon: 0.8417930500034345    steps: 227     evaluation reward: 2.57\n",
            "episode: 1351   score: 5.0   memory length: 260153   epsilon: 0.841447540003442    steps: 349     evaluation reward: 2.6\n",
            "episode: 1352   score: 2.0   memory length: 260373   epsilon: 0.8412297400034467    steps: 220     evaluation reward: 2.58\n",
            "episode: 1353   score: 6.0   memory length: 260706   epsilon: 0.8409000700034539    steps: 333     evaluation reward: 2.64\n",
            "episode: 1354   score: 4.0   memory length: 260961   epsilon: 0.8406476200034594    steps: 255     evaluation reward: 2.63\n",
            "episode: 1355   score: 0.0   memory length: 261090   epsilon: 0.8405199100034622    steps: 129     evaluation reward: 2.61\n",
            "episode: 1356   score: 2.0   memory length: 261286   epsilon: 0.8403258700034664    steps: 196     evaluation reward: 2.6\n",
            "episode: 1357   score: 0.0   memory length: 261421   epsilon: 0.8401922200034693    steps: 135     evaluation reward: 2.57\n",
            "episode: 1358   score: 2.0   memory length: 261631   epsilon: 0.8399843200034738    steps: 210     evaluation reward: 2.56\n",
            "episode: 1359   score: 0.0   memory length: 261758   epsilon: 0.8398585900034765    steps: 127     evaluation reward: 2.56\n",
            "episode: 1360   score: 4.0   memory length: 262048   epsilon: 0.8395714900034827    steps: 290     evaluation reward: 2.59\n",
            "episode: 1361   score: 5.0   memory length: 262392   epsilon: 0.8392309300034901    steps: 344     evaluation reward: 2.64\n",
            "episode: 1362   score: 1.0   memory length: 262574   epsilon: 0.839050750003494    steps: 182     evaluation reward: 2.61\n",
            "episode: 1363   score: 3.0   memory length: 262840   epsilon: 0.8387874100034998    steps: 266     evaluation reward: 2.62\n",
            "episode: 1364   score: 4.0   memory length: 263139   epsilon: 0.8384914000035062    steps: 299     evaluation reward: 2.64\n",
            "episode: 1365   score: 1.0   memory length: 263316   epsilon: 0.83831617000351    steps: 177     evaluation reward: 2.62\n",
            "episode: 1366   score: 8.0   memory length: 263592   epsilon: 0.8380429300035159    steps: 276     evaluation reward: 2.68\n",
            "episode: 1367   score: 5.0   memory length: 263884   epsilon: 0.8377538500035222    steps: 292     evaluation reward: 2.68\n",
            "episode: 1368   score: 3.0   memory length: 264115   epsilon: 0.8375251600035272    steps: 231     evaluation reward: 2.69\n",
            "episode: 1369   score: 0.0   memory length: 264243   epsilon: 0.8373984400035299    steps: 128     evaluation reward: 2.65\n",
            "episode: 1370   score: 3.0   memory length: 264474   epsilon: 0.8371697500035349    steps: 231     evaluation reward: 2.65\n",
            "episode: 1371   score: 5.0   memory length: 264782   epsilon: 0.8368648300035415    steps: 308     evaluation reward: 2.67\n",
            "episode: 1372   score: 3.0   memory length: 265027   epsilon: 0.8366222800035468    steps: 245     evaluation reward: 2.67\n",
            "episode: 1373   score: 0.0   memory length: 265156   epsilon: 0.8364945700035495    steps: 129     evaluation reward: 2.66\n",
            "episode: 1374   score: 4.0   memory length: 265426   epsilon: 0.8362272700035553    steps: 270     evaluation reward: 2.68\n",
            "episode: 1375   score: 3.0   memory length: 265663   epsilon: 0.8359926400035604    steps: 237     evaluation reward: 2.64\n",
            "episode: 1376   score: 2.0   memory length: 265866   epsilon: 0.8357916700035648    steps: 203     evaluation reward: 2.64\n",
            "episode: 1377   score: 1.0   memory length: 266046   epsilon: 0.8356134700035687    steps: 180     evaluation reward: 2.62\n",
            "episode: 1378   score: 0.0   memory length: 266174   epsilon: 0.8354867500035714    steps: 128     evaluation reward: 2.61\n",
            "episode: 1379   score: 7.0   memory length: 266543   epsilon: 0.8351214400035794    steps: 369     evaluation reward: 2.66\n",
            "episode: 1380   score: 0.0   memory length: 266675   epsilon: 0.8349907600035822    steps: 132     evaluation reward: 2.64\n",
            "episode: 1381   score: 2.0   memory length: 266885   epsilon: 0.8347828600035867    steps: 210     evaluation reward: 2.63\n",
            "episode: 1382   score: 0.0   memory length: 267010   epsilon: 0.8346591100035894    steps: 125     evaluation reward: 2.59\n",
            "episode: 1383   score: 1.0   memory length: 267165   epsilon: 0.8345056600035927    steps: 155     evaluation reward: 2.56\n",
            "episode: 1384   score: 3.0   memory length: 267404   epsilon: 0.8342690500035979    steps: 239     evaluation reward: 2.57\n",
            "episode: 1385   score: 4.0   memory length: 267694   epsilon: 0.8339819500036041    steps: 290     evaluation reward: 2.59\n",
            "episode: 1386   score: 0.0   memory length: 267825   epsilon: 0.8338522600036069    steps: 131     evaluation reward: 2.56\n",
            "episode: 1387   score: 3.0   memory length: 268038   epsilon: 0.8336413900036115    steps: 213     evaluation reward: 2.56\n",
            "episode: 1388   score: 3.0   memory length: 268278   epsilon: 0.8334037900036166    steps: 240     evaluation reward: 2.57\n",
            "episode: 1389   score: 1.0   memory length: 268450   epsilon: 0.8332335100036203    steps: 172     evaluation reward: 2.56\n",
            "episode: 1390   score: 1.0   memory length: 268606   epsilon: 0.8330790700036237    steps: 156     evaluation reward: 2.56\n",
            "episode: 1391   score: 2.0   memory length: 268819   epsilon: 0.8328682000036283    steps: 213     evaluation reward: 2.56\n",
            "episode: 1392   score: 0.0   memory length: 268942   epsilon: 0.8327464300036309    steps: 123     evaluation reward: 2.52\n",
            "episode: 1393   score: 2.0   memory length: 269130   epsilon: 0.832560310003635    steps: 188     evaluation reward: 2.54\n",
            "episode: 1394   score: 2.0   memory length: 269331   epsilon: 0.8323613200036393    steps: 201     evaluation reward: 2.55\n",
            "episode: 1395   score: 1.0   memory length: 269493   epsilon: 0.8322009400036428    steps: 162     evaluation reward: 2.54\n",
            "episode: 1396   score: 2.0   memory length: 269691   epsilon: 0.832004920003647    steps: 198     evaluation reward: 2.52\n",
            "episode: 1397   score: 3.0   memory length: 269911   epsilon: 0.8317871200036517    steps: 220     evaluation reward: 2.52\n",
            "episode: 1398   score: 2.0   memory length: 270110   epsilon: 0.831590110003656    steps: 199     evaluation reward: 2.47\n",
            "episode: 1399   score: 1.0   memory length: 270293   epsilon: 0.83140894000366    steps: 183     evaluation reward: 2.47\n",
            "episode: 1400   score: 2.0   memory length: 270525   epsilon: 0.8311792600036649    steps: 232     evaluation reward: 2.46\n",
            "episode: 1401   score: 1.0   memory length: 270701   epsilon: 0.8310050200036687    steps: 176     evaluation reward: 2.47\n",
            "episode: 1402   score: 3.0   memory length: 270912   epsilon: 0.8307961300036732    steps: 211     evaluation reward: 2.49\n",
            "episode: 1403   score: 5.0   memory length: 271275   epsilon: 0.830436760003681    steps: 363     evaluation reward: 2.51\n",
            "episode: 1404   score: 3.0   memory length: 271509   epsilon: 0.8302051000036861    steps: 234     evaluation reward: 2.52\n",
            "episode: 1405   score: 4.0   memory length: 271811   epsilon: 0.8299061200036926    steps: 302     evaluation reward: 2.52\n",
            "episode: 1406   score: 2.0   memory length: 272035   epsilon: 0.8296843600036974    steps: 224     evaluation reward: 2.49\n",
            "episode: 1407   score: 2.0   memory length: 272219   epsilon: 0.8295022000037013    steps: 184     evaluation reward: 2.49\n",
            "episode: 1408   score: 4.0   memory length: 272512   epsilon: 0.8292121300037076    steps: 293     evaluation reward: 2.49\n",
            "episode: 1409   score: 0.0   memory length: 272641   epsilon: 0.8290844200037104    steps: 129     evaluation reward: 2.47\n",
            "episode: 1410   score: 3.0   memory length: 272884   epsilon: 0.8288438500037156    steps: 243     evaluation reward: 2.5\n",
            "episode: 1411   score: 2.0   memory length: 273076   epsilon: 0.8286537700037198    steps: 192     evaluation reward: 2.51\n",
            "episode: 1412   score: 2.0   memory length: 273275   epsilon: 0.828456760003724    steps: 199     evaluation reward: 2.49\n",
            "episode: 1413   score: 2.0   memory length: 273474   epsilon: 0.8282597500037283    steps: 199     evaluation reward: 2.48\n",
            "episode: 1414   score: 3.0   memory length: 273694   epsilon: 0.828041950003733    steps: 220     evaluation reward: 2.5\n",
            "episode: 1415   score: 4.0   memory length: 273940   epsilon: 0.8277984100037383    steps: 246     evaluation reward: 2.49\n",
            "episode: 1416   score: 0.0   memory length: 274068   epsilon: 0.8276716900037411    steps: 128     evaluation reward: 2.46\n",
            "episode: 1417   score: 2.0   memory length: 274249   epsilon: 0.827492500003745    steps: 181     evaluation reward: 2.45\n",
            "episode: 1418   score: 2.0   memory length: 274471   epsilon: 0.8272727200037497    steps: 222     evaluation reward: 2.44\n",
            "episode: 1419   score: 1.0   memory length: 274661   epsilon: 0.8270846200037538    steps: 190     evaluation reward: 2.45\n",
            "episode: 1420   score: 5.0   memory length: 274984   epsilon: 0.8267648500037608    steps: 323     evaluation reward: 2.49\n",
            "episode: 1421   score: 1.0   memory length: 275156   epsilon: 0.8265945700037645    steps: 172     evaluation reward: 2.47\n",
            "episode: 1422   score: 1.0   memory length: 275329   epsilon: 0.8264233000037682    steps: 173     evaluation reward: 2.46\n",
            "episode: 1423   score: 2.0   memory length: 275524   epsilon: 0.8262302500037724    steps: 195     evaluation reward: 2.44\n",
            "episode: 1424   score: 0.0   memory length: 275664   epsilon: 0.8260916500037754    steps: 140     evaluation reward: 2.42\n",
            "episode: 1425   score: 4.0   memory length: 275942   epsilon: 0.8258164300037814    steps: 278     evaluation reward: 2.45\n",
            "episode: 1426   score: 2.0   memory length: 276155   epsilon: 0.8256055600037859    steps: 213     evaluation reward: 2.47\n",
            "episode: 1427   score: 0.0   memory length: 276288   epsilon: 0.8254738900037888    steps: 133     evaluation reward: 2.45\n",
            "episode: 1428   score: 3.0   memory length: 276526   epsilon: 0.8252382700037939    steps: 238     evaluation reward: 2.43\n",
            "episode: 1429   score: 3.0   memory length: 276795   epsilon: 0.8249719600037997    steps: 269     evaluation reward: 2.44\n",
            "episode: 1430   score: 4.0   memory length: 277078   epsilon: 0.8246917900038058    steps: 283     evaluation reward: 2.47\n",
            "episode: 1431   score: 7.0   memory length: 277334   epsilon: 0.8244383500038113    steps: 256     evaluation reward: 2.53\n",
            "episode: 1432   score: 4.0   memory length: 277632   epsilon: 0.8241433300038177    steps: 298     evaluation reward: 2.53\n",
            "episode: 1433   score: 4.0   memory length: 277887   epsilon: 0.8238908800038232    steps: 255     evaluation reward: 2.55\n",
            "episode: 1434   score: 3.0   memory length: 278137   epsilon: 0.8236433800038285    steps: 250     evaluation reward: 2.54\n",
            "episode: 1435   score: 3.0   memory length: 278385   epsilon: 0.8233978600038339    steps: 248     evaluation reward: 2.51\n",
            "episode: 1436   score: 4.0   memory length: 278655   epsilon: 0.8231305600038397    steps: 270     evaluation reward: 2.52\n",
            "episode: 1437   score: 2.0   memory length: 278856   epsilon: 0.822931570003844    steps: 201     evaluation reward: 2.5\n",
            "episode: 1438   score: 3.0   memory length: 279101   epsilon: 0.8226890200038492    steps: 245     evaluation reward: 2.5\n",
            "episode: 1439   score: 2.0   memory length: 279303   epsilon: 0.8224890400038536    steps: 202     evaluation reward: 2.46\n",
            "episode: 1440   score: 2.0   memory length: 279506   epsilon: 0.822288070003858    steps: 203     evaluation reward: 2.47\n",
            "episode: 1441   score: 3.0   memory length: 279745   epsilon: 0.8220514600038631    steps: 239     evaluation reward: 2.48\n",
            "episode: 1442   score: 2.0   memory length: 279947   epsilon: 0.8218514800038674    steps: 202     evaluation reward: 2.48\n",
            "episode: 1443   score: 0.0   memory length: 280081   epsilon: 0.8217188200038703    steps: 134     evaluation reward: 2.45\n",
            "episode: 1444   score: 2.0   memory length: 280274   epsilon: 0.8215277500038745    steps: 193     evaluation reward: 2.46\n",
            "episode: 1445   score: 0.0   memory length: 280405   epsilon: 0.8213980600038773    steps: 131     evaluation reward: 2.41\n",
            "episode: 1446   score: 2.0   memory length: 280588   epsilon: 0.8212168900038812    steps: 183     evaluation reward: 2.39\n",
            "episode: 1447   score: 1.0   memory length: 280770   epsilon: 0.8210367100038851    steps: 182     evaluation reward: 2.39\n",
            "episode: 1448   score: 3.0   memory length: 281003   epsilon: 0.8208060400038901    steps: 233     evaluation reward: 2.4\n",
            "episode: 1449   score: 0.0   memory length: 281133   epsilon: 0.8206773400038929    steps: 130     evaluation reward: 2.38\n",
            "episode: 1450   score: 0.0   memory length: 281257   epsilon: 0.8205545800038956    steps: 124     evaluation reward: 2.35\n",
            "episode: 1451   score: 6.0   memory length: 281635   epsilon: 0.8201803600039037    steps: 378     evaluation reward: 2.36\n",
            "episode: 1452   score: 4.0   memory length: 281906   epsilon: 0.8199120700039095    steps: 271     evaluation reward: 2.38\n",
            "episode: 1453   score: 8.0   memory length: 282385   epsilon: 0.8194378600039198    steps: 479     evaluation reward: 2.4\n",
            "episode: 1454   score: 5.0   memory length: 282697   epsilon: 0.8191289800039265    steps: 312     evaluation reward: 2.41\n",
            "episode: 1455   score: 3.0   memory length: 282946   epsilon: 0.8188824700039319    steps: 249     evaluation reward: 2.44\n",
            "episode: 1456   score: 2.0   memory length: 283164   epsilon: 0.8186666500039366    steps: 218     evaluation reward: 2.44\n",
            "episode: 1457   score: 2.0   memory length: 283359   epsilon: 0.8184736000039408    steps: 195     evaluation reward: 2.46\n",
            "episode: 1458   score: 2.0   memory length: 283541   epsilon: 0.8182934200039447    steps: 182     evaluation reward: 2.46\n",
            "episode: 1459   score: 3.0   memory length: 283815   epsilon: 0.8180221600039506    steps: 274     evaluation reward: 2.49\n",
            "episode: 1460   score: 3.0   memory length: 284086   epsilon: 0.8177538700039564    steps: 271     evaluation reward: 2.48\n",
            "episode: 1461   score: 3.0   memory length: 284317   epsilon: 0.8175251800039613    steps: 231     evaluation reward: 2.46\n",
            "episode: 1462   score: 2.0   memory length: 284496   epsilon: 0.8173479700039652    steps: 179     evaluation reward: 2.47\n",
            "episode: 1463   score: 3.0   memory length: 284730   epsilon: 0.8171163100039702    steps: 234     evaluation reward: 2.47\n",
            "episode: 1464   score: 3.0   memory length: 284961   epsilon: 0.8168876200039752    steps: 231     evaluation reward: 2.46\n",
            "episode: 1465   score: 1.0   memory length: 285127   epsilon: 0.8167232800039788    steps: 166     evaluation reward: 2.46\n",
            "episode: 1466   score: 7.0   memory length: 285481   epsilon: 0.8163728200039864    steps: 354     evaluation reward: 2.45\n",
            "episode: 1467   score: 2.0   memory length: 285673   epsilon: 0.8161827400039905    steps: 192     evaluation reward: 2.42\n",
            "episode: 1468   score: 3.0   memory length: 285922   epsilon: 0.8159362300039958    steps: 249     evaluation reward: 2.42\n",
            "episode: 1469   score: 2.0   memory length: 286110   epsilon: 0.8157501100039999    steps: 188     evaluation reward: 2.44\n",
            "episode: 1470   score: 2.0   memory length: 286317   epsilon: 0.8155451800040043    steps: 207     evaluation reward: 2.43\n",
            "episode: 1471   score: 4.0   memory length: 286587   epsilon: 0.8152778800040101    steps: 270     evaluation reward: 2.42\n",
            "episode: 1472   score: 4.0   memory length: 286869   epsilon: 0.8149987000040162    steps: 282     evaluation reward: 2.43\n",
            "episode: 1473   score: 5.0   memory length: 287162   epsilon: 0.8147086300040225    steps: 293     evaluation reward: 2.48\n",
            "episode: 1474   score: 4.0   memory length: 287436   epsilon: 0.8144373700040284    steps: 274     evaluation reward: 2.48\n",
            "episode: 1475   score: 2.0   memory length: 287642   epsilon: 0.8142334300040328    steps: 206     evaluation reward: 2.47\n",
            "episode: 1476   score: 4.0   memory length: 287931   epsilon: 0.813947320004039    steps: 289     evaluation reward: 2.49\n",
            "episode: 1477   score: 3.0   memory length: 288189   epsilon: 0.8136919000040446    steps: 258     evaluation reward: 2.51\n",
            "episode: 1478   score: 3.0   memory length: 288412   epsilon: 0.8134711300040494    steps: 223     evaluation reward: 2.54\n",
            "episode: 1479   score: 2.0   memory length: 288631   epsilon: 0.8132543200040541    steps: 219     evaluation reward: 2.49\n",
            "episode: 1480   score: 2.0   memory length: 288814   epsilon: 0.813073150004058    steps: 183     evaluation reward: 2.51\n",
            "episode: 1481   score: 3.0   memory length: 289047   epsilon: 0.812842480004063    steps: 233     evaluation reward: 2.52\n",
            "episode: 1482   score: 2.0   memory length: 289245   epsilon: 0.8126464600040673    steps: 198     evaluation reward: 2.54\n",
            "episode: 1483   score: 2.0   memory length: 289428   epsilon: 0.8124652900040712    steps: 183     evaluation reward: 2.55\n",
            "episode: 1484   score: 7.0   memory length: 289810   epsilon: 0.8120871100040794    steps: 382     evaluation reward: 2.59\n",
            "episode: 1485   score: 1.0   memory length: 289977   epsilon: 0.811921780004083    steps: 167     evaluation reward: 2.56\n",
            "episode: 1486   score: 1.0   memory length: 290167   epsilon: 0.8117336800040871    steps: 190     evaluation reward: 2.57\n",
            "episode: 1487   score: 9.0   memory length: 290638   epsilon: 0.8112673900040972    steps: 471     evaluation reward: 2.63\n",
            "episode: 1488   score: 3.0   memory length: 290857   epsilon: 0.8110505800041019    steps: 219     evaluation reward: 2.63\n",
            "episode: 1489   score: 5.0   memory length: 291184   epsilon: 0.8107268500041089    steps: 327     evaluation reward: 2.67\n",
            "episode: 1490   score: 5.0   memory length: 291515   epsilon: 0.810399160004116    steps: 331     evaluation reward: 2.71\n",
            "episode: 1491   score: 6.0   memory length: 291879   epsilon: 0.8100388000041239    steps: 364     evaluation reward: 2.75\n",
            "episode: 1492   score: 3.0   memory length: 292121   epsilon: 0.8097992200041291    steps: 242     evaluation reward: 2.78\n",
            "episode: 1493   score: 1.0   memory length: 292277   epsilon: 0.8096447800041324    steps: 156     evaluation reward: 2.77\n",
            "episode: 1494   score: 2.0   memory length: 292468   epsilon: 0.8094556900041365    steps: 191     evaluation reward: 2.77\n",
            "episode: 1495   score: 2.0   memory length: 292663   epsilon: 0.8092626400041407    steps: 195     evaluation reward: 2.78\n",
            "episode: 1496   score: 2.0   memory length: 292864   epsilon: 0.809063650004145    steps: 201     evaluation reward: 2.78\n",
            "episode: 1497   score: 1.0   memory length: 293036   epsilon: 0.8088933700041487    steps: 172     evaluation reward: 2.76\n",
            "episode: 1498   score: 2.0   memory length: 293258   epsilon: 0.8086735900041535    steps: 222     evaluation reward: 2.76\n",
            "episode: 1499   score: 1.0   memory length: 293432   epsilon: 0.8085013300041572    steps: 174     evaluation reward: 2.76\n",
            "episode: 1500   score: 4.0   memory length: 293749   epsilon: 0.8081875000041641    steps: 317     evaluation reward: 2.78\n",
            "episode: 1501   score: 6.0   memory length: 294115   epsilon: 0.8078251600041719    steps: 366     evaluation reward: 2.83\n",
            "episode: 1502   score: 2.0   memory length: 294302   epsilon: 0.807640030004176    steps: 187     evaluation reward: 2.82\n",
            "episode: 1503   score: 2.0   memory length: 294499   epsilon: 0.8074450000041802    steps: 197     evaluation reward: 2.79\n",
            "episode: 1504   score: 3.0   memory length: 294714   epsilon: 0.8072321500041848    steps: 215     evaluation reward: 2.79\n",
            "episode: 1505   score: 2.0   memory length: 294898   epsilon: 0.8070499900041888    steps: 184     evaluation reward: 2.77\n",
            "episode: 1506   score: 4.0   memory length: 295177   epsilon: 0.8067737800041948    steps: 279     evaluation reward: 2.79\n",
            "episode: 1507   score: 7.0   memory length: 295499   epsilon: 0.8064550000042017    steps: 322     evaluation reward: 2.84\n",
            "episode: 1508   score: 5.0   memory length: 295851   epsilon: 0.8061065200042092    steps: 352     evaluation reward: 2.85\n",
            "episode: 1509   score: 2.0   memory length: 296072   epsilon: 0.805887730004214    steps: 221     evaluation reward: 2.87\n",
            "episode: 1510   score: 2.0   memory length: 296298   epsilon: 0.8056639900042188    steps: 226     evaluation reward: 2.86\n",
            "episode: 1511   score: 3.0   memory length: 296549   epsilon: 0.8054155000042242    steps: 251     evaluation reward: 2.87\n",
            "episode: 1512   score: 0.0   memory length: 296672   epsilon: 0.8052937300042269    steps: 123     evaluation reward: 2.85\n",
            "episode: 1513   score: 3.0   memory length: 296928   epsilon: 0.8050402900042324    steps: 256     evaluation reward: 2.86\n",
            "episode: 1514   score: 2.0   memory length: 297129   epsilon: 0.8048413000042367    steps: 201     evaluation reward: 2.85\n",
            "episode: 1515   score: 3.0   memory length: 297346   epsilon: 0.8046264700042414    steps: 217     evaluation reward: 2.84\n",
            "episode: 1516   score: 3.0   memory length: 297590   epsilon: 0.8043849100042466    steps: 244     evaluation reward: 2.87\n",
            "episode: 1517   score: 4.0   memory length: 297885   epsilon: 0.804092860004253    steps: 295     evaluation reward: 2.89\n",
            "episode: 1518   score: 4.0   memory length: 298157   epsilon: 0.8038235800042588    steps: 272     evaluation reward: 2.91\n",
            "episode: 1519   score: 3.0   memory length: 298411   epsilon: 0.8035721200042643    steps: 254     evaluation reward: 2.93\n",
            "episode: 1520   score: 0.0   memory length: 298542   epsilon: 0.8034424300042671    steps: 131     evaluation reward: 2.88\n",
            "episode: 1521   score: 3.0   memory length: 298800   epsilon: 0.8031870100042726    steps: 258     evaluation reward: 2.9\n",
            "episode: 1522   score: 1.0   memory length: 298961   epsilon: 0.8030276200042761    steps: 161     evaluation reward: 2.9\n",
            "episode: 1523   score: 2.0   memory length: 299175   epsilon: 0.8028157600042807    steps: 214     evaluation reward: 2.9\n",
            "episode: 1524   score: 1.0   memory length: 299326   epsilon: 0.8026662700042839    steps: 151     evaluation reward: 2.91\n",
            "episode: 1525   score: 1.0   memory length: 299491   epsilon: 0.8025029200042875    steps: 165     evaluation reward: 2.88\n",
            "episode: 1526   score: 2.0   memory length: 299716   epsilon: 0.8022801700042923    steps: 225     evaluation reward: 2.88\n",
            "episode: 1527   score: 4.0   memory length: 299984   epsilon: 0.8020148500042981    steps: 268     evaluation reward: 2.92\n",
            "now time :  2019-12-12 18:58:53.309623\n",
            "episode: 1528   score: 2.0   memory length: 300187   epsilon: 0.8018138800043024    steps: 203     evaluation reward: 2.91\n",
            "episode: 1529   score: 4.0   memory length: 300429   epsilon: 0.8015743000043076    steps: 242     evaluation reward: 2.92\n",
            "episode: 1530   score: 4.0   memory length: 300734   epsilon: 0.8012723500043142    steps: 305     evaluation reward: 2.92\n",
            "episode: 1531   score: 6.0   memory length: 301105   epsilon: 0.8009050600043222    steps: 371     evaluation reward: 2.91\n",
            "episode: 1532   score: 3.0   memory length: 301332   epsilon: 0.800680330004327    steps: 227     evaluation reward: 2.9\n",
            "episode: 1533   score: 4.0   memory length: 301625   epsilon: 0.8003902600043333    steps: 293     evaluation reward: 2.9\n",
            "episode: 1534   score: 1.0   memory length: 301782   epsilon: 0.8002348300043367    steps: 157     evaluation reward: 2.88\n",
            "episode: 1535   score: 3.0   memory length: 302052   epsilon: 0.7999675300043425    steps: 270     evaluation reward: 2.88\n",
            "episode: 1536   score: 4.0   memory length: 302320   epsilon: 0.7997022100043483    steps: 268     evaluation reward: 2.88\n",
            "episode: 1537   score: 3.0   memory length: 302569   epsilon: 0.7994557000043536    steps: 249     evaluation reward: 2.89\n",
            "episode: 1538   score: 5.0   memory length: 302884   epsilon: 0.7991438500043604    steps: 315     evaluation reward: 2.91\n",
            "episode: 1539   score: 4.0   memory length: 303200   epsilon: 0.7988310100043672    steps: 316     evaluation reward: 2.93\n",
            "episode: 1540   score: 1.0   memory length: 303378   epsilon: 0.798654790004371    steps: 178     evaluation reward: 2.92\n",
            "episode: 1541   score: 6.0   memory length: 303739   epsilon: 0.7982974000043788    steps: 361     evaluation reward: 2.95\n",
            "episode: 1542   score: 3.0   memory length: 303986   epsilon: 0.7980528700043841    steps: 247     evaluation reward: 2.96\n",
            "episode: 1543   score: 3.0   memory length: 304214   epsilon: 0.797827150004389    steps: 228     evaluation reward: 2.99\n",
            "episode: 1544   score: 3.0   memory length: 304448   epsilon: 0.797595490004394    steps: 234     evaluation reward: 3.0\n",
            "episode: 1545   score: 2.0   memory length: 304634   epsilon: 0.797411350004398    steps: 186     evaluation reward: 3.02\n",
            "episode: 1546   score: 1.0   memory length: 304812   epsilon: 0.7972351300044018    steps: 178     evaluation reward: 3.01\n",
            "episode: 1547   score: 4.0   memory length: 305092   epsilon: 0.7969579300044078    steps: 280     evaluation reward: 3.04\n",
            "episode: 1548   score: 2.0   memory length: 305278   epsilon: 0.7967737900044118    steps: 186     evaluation reward: 3.03\n",
            "episode: 1549   score: 5.0   memory length: 305587   epsilon: 0.7964678800044185    steps: 309     evaluation reward: 3.08\n",
            "episode: 1550   score: 4.0   memory length: 305898   epsilon: 0.7961599900044252    steps: 311     evaluation reward: 3.12\n",
            "episode: 1551   score: 2.0   memory length: 306105   epsilon: 0.7959550600044296    steps: 207     evaluation reward: 3.08\n",
            "episode: 1552   score: 4.0   memory length: 306411   epsilon: 0.7956521200044362    steps: 306     evaluation reward: 3.08\n",
            "episode: 1553   score: 4.0   memory length: 306687   epsilon: 0.7953788800044421    steps: 276     evaluation reward: 3.04\n",
            "episode: 1554   score: 2.0   memory length: 306888   epsilon: 0.7951798900044464    steps: 201     evaluation reward: 3.01\n",
            "episode: 1555   score: 3.0   memory length: 307124   epsilon: 0.7949462500044515    steps: 236     evaluation reward: 3.01\n",
            "episode: 1556   score: 2.0   memory length: 307345   epsilon: 0.7947274600044563    steps: 221     evaluation reward: 3.01\n",
            "episode: 1557   score: 8.0   memory length: 307784   epsilon: 0.7942928500044657    steps: 439     evaluation reward: 3.07\n",
            "episode: 1558   score: 1.0   memory length: 307935   epsilon: 0.794143360004469    steps: 151     evaluation reward: 3.06\n",
            "episode: 1559   score: 4.0   memory length: 308202   epsilon: 0.7938790300044747    steps: 267     evaluation reward: 3.07\n",
            "episode: 1560   score: 4.0   memory length: 308486   epsilon: 0.7935978700044808    steps: 284     evaluation reward: 3.08\n",
            "episode: 1561   score: 5.0   memory length: 308798   epsilon: 0.7932889900044875    steps: 312     evaluation reward: 3.1\n",
            "episode: 1562   score: 4.0   memory length: 309079   epsilon: 0.7930108000044935    steps: 281     evaluation reward: 3.12\n",
            "episode: 1563   score: 7.0   memory length: 309486   epsilon: 0.7926078700045023    steps: 407     evaluation reward: 3.16\n",
            "episode: 1564   score: 3.0   memory length: 309703   epsilon: 0.7923930400045069    steps: 217     evaluation reward: 3.16\n",
            "episode: 1565   score: 3.0   memory length: 309951   epsilon: 0.7921475200045123    steps: 248     evaluation reward: 3.18\n",
            "episode: 1566   score: 1.0   memory length: 310111   epsilon: 0.7919891200045157    steps: 160     evaluation reward: 3.12\n",
            "episode: 1567   score: 1.0   memory length: 310295   epsilon: 0.7918069600045197    steps: 184     evaluation reward: 3.11\n",
            "episode: 1568   score: 0.0   memory length: 310420   epsilon: 0.7916832100045224    steps: 125     evaluation reward: 3.08\n",
            "episode: 1569   score: 0.0   memory length: 310560   epsilon: 0.7915446100045254    steps: 140     evaluation reward: 3.06\n",
            "episode: 1570   score: 2.0   memory length: 310784   epsilon: 0.7913228500045302    steps: 224     evaluation reward: 3.06\n",
            "episode: 1571   score: 1.0   memory length: 310938   epsilon: 0.7911703900045335    steps: 154     evaluation reward: 3.03\n",
            "episode: 1572   score: 2.0   memory length: 311148   epsilon: 0.790962490004538    steps: 210     evaluation reward: 3.01\n",
            "episode: 1573   score: 5.0   memory length: 311460   epsilon: 0.7906536100045447    steps: 312     evaluation reward: 3.01\n",
            "episode: 1574   score: 3.0   memory length: 311705   epsilon: 0.79041106000455    steps: 245     evaluation reward: 3.0\n",
            "episode: 1575   score: 2.0   memory length: 311907   epsilon: 0.7902110800045543    steps: 202     evaluation reward: 3.0\n",
            "episode: 1576   score: 4.0   memory length: 312176   epsilon: 0.7899447700045601    steps: 269     evaluation reward: 3.0\n",
            "episode: 1577   score: 3.0   memory length: 312426   epsilon: 0.7896972700045655    steps: 250     evaluation reward: 3.0\n",
            "episode: 1578   score: 6.0   memory length: 312829   epsilon: 0.7892983000045741    steps: 403     evaluation reward: 3.03\n",
            "episode: 1579   score: 3.0   memory length: 313091   epsilon: 0.7890389200045798    steps: 262     evaluation reward: 3.04\n",
            "episode: 1580   score: 5.0   memory length: 313380   epsilon: 0.788752810004586    steps: 289     evaluation reward: 3.07\n",
            "episode: 1581   score: 4.0   memory length: 313660   epsilon: 0.788475610004592    steps: 280     evaluation reward: 3.08\n",
            "episode: 1582   score: 4.0   memory length: 313920   epsilon: 0.7882182100045976    steps: 260     evaluation reward: 3.1\n",
            "episode: 1583   score: 3.0   memory length: 314166   epsilon: 0.7879746700046029    steps: 246     evaluation reward: 3.11\n",
            "episode: 1584   score: 3.0   memory length: 314395   epsilon: 0.7877479600046078    steps: 229     evaluation reward: 3.07\n",
            "episode: 1585   score: 5.0   memory length: 314728   epsilon: 0.7874182900046149    steps: 333     evaluation reward: 3.11\n",
            "episode: 1586   score: 5.0   memory length: 315069   epsilon: 0.7870807000046223    steps: 341     evaluation reward: 3.15\n",
            "episode: 1587   score: 1.0   memory length: 315227   epsilon: 0.7869242800046257    steps: 158     evaluation reward: 3.07\n",
            "episode: 1588   score: 3.0   memory length: 315465   epsilon: 0.7866886600046308    steps: 238     evaluation reward: 3.07\n",
            "episode: 1589   score: 2.0   memory length: 315652   epsilon: 0.7865035300046348    steps: 187     evaluation reward: 3.04\n",
            "episode: 1590   score: 4.0   memory length: 315922   epsilon: 0.7862362300046406    steps: 270     evaluation reward: 3.03\n",
            "episode: 1591   score: 2.0   memory length: 316122   epsilon: 0.7860382300046449    steps: 200     evaluation reward: 2.99\n",
            "episode: 1592   score: 4.0   memory length: 316385   epsilon: 0.7857778600046506    steps: 263     evaluation reward: 3.0\n",
            "episode: 1593   score: 6.0   memory length: 316728   epsilon: 0.7854382900046579    steps: 343     evaluation reward: 3.05\n",
            "episode: 1594   score: 3.0   memory length: 316962   epsilon: 0.785206630004663    steps: 234     evaluation reward: 3.06\n",
            "episode: 1595   score: 3.0   memory length: 317178   epsilon: 0.7849927900046676    steps: 216     evaluation reward: 3.07\n",
            "episode: 1596   score: 0.0   memory length: 317313   epsilon: 0.7848591400046705    steps: 135     evaluation reward: 3.05\n",
            "episode: 1597   score: 4.0   memory length: 317603   epsilon: 0.7845720400046767    steps: 290     evaluation reward: 3.08\n",
            "episode: 1598   score: 0.0   memory length: 317738   epsilon: 0.7844383900046796    steps: 135     evaluation reward: 3.06\n",
            "episode: 1599   score: 3.0   memory length: 317983   epsilon: 0.7841958400046849    steps: 245     evaluation reward: 3.08\n",
            "episode: 1600   score: 4.0   memory length: 318249   epsilon: 0.7839325000046906    steps: 266     evaluation reward: 3.08\n",
            "episode: 1601   score: 1.0   memory length: 318444   epsilon: 0.7837394500046948    steps: 195     evaluation reward: 3.03\n",
            "episode: 1602   score: 6.0   memory length: 318830   epsilon: 0.7833573100047031    steps: 386     evaluation reward: 3.07\n",
            "episode: 1603   score: 2.0   memory length: 319020   epsilon: 0.7831692100047072    steps: 190     evaluation reward: 3.07\n",
            "episode: 1604   score: 2.0   memory length: 319205   epsilon: 0.7829860600047112    steps: 185     evaluation reward: 3.06\n",
            "episode: 1605   score: 0.0   memory length: 319347   epsilon: 0.7828454800047142    steps: 142     evaluation reward: 3.04\n",
            "episode: 1606   score: 6.0   memory length: 319687   epsilon: 0.7825088800047215    steps: 340     evaluation reward: 3.06\n",
            "episode: 1607   score: 0.0   memory length: 319811   epsilon: 0.7823861200047242    steps: 124     evaluation reward: 2.99\n",
            "episode: 1608   score: 1.0   memory length: 319988   epsilon: 0.782210890004728    steps: 177     evaluation reward: 2.95\n",
            "episode: 1609   score: 4.0   memory length: 320293   epsilon: 0.7819089400047345    steps: 305     evaluation reward: 2.97\n",
            "episode: 1610   score: 4.0   memory length: 320574   epsilon: 0.7816307500047406    steps: 281     evaluation reward: 2.99\n",
            "episode: 1611   score: 1.0   memory length: 320736   epsilon: 0.7814703700047441    steps: 162     evaluation reward: 2.97\n",
            "episode: 1612   score: 1.0   memory length: 320896   epsilon: 0.7813119700047475    steps: 160     evaluation reward: 2.98\n",
            "episode: 1613   score: 2.0   memory length: 321077   epsilon: 0.7811327800047514    steps: 181     evaluation reward: 2.97\n",
            "episode: 1614   score: 4.0   memory length: 321361   epsilon: 0.7808516200047575    steps: 284     evaluation reward: 2.99\n",
            "episode: 1615   score: 3.0   memory length: 321583   epsilon: 0.7806318400047623    steps: 222     evaluation reward: 2.99\n",
            "episode: 1616   score: 5.0   memory length: 321886   epsilon: 0.7803318700047688    steps: 303     evaluation reward: 3.01\n",
            "episode: 1617   score: 2.0   memory length: 322074   epsilon: 0.7801457500047728    steps: 188     evaluation reward: 2.99\n",
            "episode: 1618   score: 0.0   memory length: 322207   epsilon: 0.7800140800047757    steps: 133     evaluation reward: 2.95\n",
            "episode: 1619   score: 1.0   memory length: 322369   epsilon: 0.7798537000047792    steps: 162     evaluation reward: 2.93\n",
            "episode: 1620   score: 2.0   memory length: 322555   epsilon: 0.7796695600047832    steps: 186     evaluation reward: 2.95\n",
            "episode: 1621   score: 4.0   memory length: 322828   epsilon: 0.779399290004789    steps: 273     evaluation reward: 2.96\n",
            "episode: 1622   score: 8.0   memory length: 323197   epsilon: 0.779033980004797    steps: 369     evaluation reward: 3.03\n",
            "episode: 1623   score: 5.0   memory length: 323493   epsilon: 0.7787409400048033    steps: 296     evaluation reward: 3.06\n",
            "episode: 1624   score: 3.0   memory length: 323713   epsilon: 0.778523140004808    steps: 220     evaluation reward: 3.08\n",
            "episode: 1625   score: 3.0   memory length: 323971   epsilon: 0.7782677200048136    steps: 258     evaluation reward: 3.1\n",
            "episode: 1626   score: 1.0   memory length: 324152   epsilon: 0.7780885300048175    steps: 181     evaluation reward: 3.09\n",
            "episode: 1627   score: 4.0   memory length: 324455   epsilon: 0.777788560004824    steps: 303     evaluation reward: 3.09\n",
            "episode: 1628   score: 6.0   memory length: 324810   epsilon: 0.7774371100048316    steps: 355     evaluation reward: 3.13\n",
            "episode: 1629   score: 3.0   memory length: 325026   epsilon: 0.7772232700048363    steps: 216     evaluation reward: 3.12\n",
            "episode: 1630   score: 3.0   memory length: 325297   epsilon: 0.7769549800048421    steps: 271     evaluation reward: 3.11\n",
            "episode: 1631   score: 5.0   memory length: 325627   epsilon: 0.7766282800048492    steps: 330     evaluation reward: 3.1\n",
            "episode: 1632   score: 1.0   memory length: 325788   epsilon: 0.7764688900048526    steps: 161     evaluation reward: 3.08\n",
            "episode: 1633   score: 4.0   memory length: 326069   epsilon: 0.7761907000048587    steps: 281     evaluation reward: 3.08\n",
            "episode: 1634   score: 2.0   memory length: 326261   epsilon: 0.7760006200048628    steps: 192     evaluation reward: 3.09\n",
            "episode: 1635   score: 2.0   memory length: 326469   epsilon: 0.7757947000048673    steps: 208     evaluation reward: 3.08\n",
            "episode: 1636   score: 4.0   memory length: 326751   epsilon: 0.7755155200048733    steps: 282     evaluation reward: 3.08\n",
            "episode: 1637   score: 1.0   memory length: 326921   epsilon: 0.775347220004877    steps: 170     evaluation reward: 3.06\n",
            "episode: 1638   score: 5.0   memory length: 327248   epsilon: 0.775023490004884    steps: 327     evaluation reward: 3.06\n",
            "episode: 1639   score: 4.0   memory length: 327518   epsilon: 0.7747561900048898    steps: 270     evaluation reward: 3.06\n",
            "episode: 1640   score: 2.0   memory length: 327738   epsilon: 0.7745383900048946    steps: 220     evaluation reward: 3.07\n",
            "episode: 1641   score: 6.0   memory length: 328082   epsilon: 0.7741978300049019    steps: 344     evaluation reward: 3.07\n",
            "episode: 1642   score: 4.0   memory length: 328372   epsilon: 0.7739107300049082    steps: 290     evaluation reward: 3.08\n",
            "episode: 1643   score: 5.0   memory length: 328708   epsilon: 0.7735780900049154    steps: 336     evaluation reward: 3.1\n",
            "episode: 1644   score: 1.0   memory length: 328873   epsilon: 0.7734147400049189    steps: 165     evaluation reward: 3.08\n",
            "episode: 1645   score: 2.0   memory length: 329089   epsilon: 0.7732009000049236    steps: 216     evaluation reward: 3.08\n",
            "episode: 1646   score: 4.0   memory length: 329375   epsilon: 0.7729177600049297    steps: 286     evaluation reward: 3.11\n",
            "episode: 1647   score: 6.0   memory length: 329725   epsilon: 0.7725712600049373    steps: 350     evaluation reward: 3.13\n",
            "episode: 1648   score: 2.0   memory length: 329942   epsilon: 0.7723564300049419    steps: 217     evaluation reward: 3.13\n",
            "episode: 1649   score: 1.0   memory length: 330095   epsilon: 0.7722049600049452    steps: 153     evaluation reward: 3.09\n",
            "episode: 1650   score: 2.0   memory length: 330312   epsilon: 0.7719901300049499    steps: 217     evaluation reward: 3.07\n",
            "episode: 1651   score: 3.0   memory length: 330575   epsilon: 0.7717297600049555    steps: 263     evaluation reward: 3.08\n",
            "episode: 1652   score: 5.0   memory length: 330883   epsilon: 0.7714248400049621    steps: 308     evaluation reward: 3.09\n",
            "episode: 1653   score: 2.0   memory length: 331089   epsilon: 0.7712209000049666    steps: 206     evaluation reward: 3.07\n",
            "episode: 1654   score: 2.0   memory length: 331293   epsilon: 0.771018940004971    steps: 204     evaluation reward: 3.07\n",
            "episode: 1655   score: 3.0   memory length: 331525   epsilon: 0.7707892600049759    steps: 232     evaluation reward: 3.07\n",
            "episode: 1656   score: 2.0   memory length: 331729   epsilon: 0.7705873000049803    steps: 204     evaluation reward: 3.07\n",
            "episode: 1657   score: 4.0   memory length: 332011   epsilon: 0.7703081200049864    steps: 282     evaluation reward: 3.03\n",
            "episode: 1658   score: 3.0   memory length: 332244   epsilon: 0.7700774500049914    steps: 233     evaluation reward: 3.05\n",
            "episode: 1659   score: 0.0   memory length: 332370   epsilon: 0.7699527100049941    steps: 126     evaluation reward: 3.01\n",
            "episode: 1660   score: 3.0   memory length: 332594   epsilon: 0.7697309500049989    steps: 224     evaluation reward: 3.0\n",
            "episode: 1661   score: 5.0   memory length: 332907   epsilon: 0.7694210800050056    steps: 313     evaluation reward: 3.0\n",
            "episode: 1662   score: 2.0   memory length: 333095   epsilon: 0.7692349600050097    steps: 188     evaluation reward: 2.98\n",
            "episode: 1663   score: 1.0   memory length: 333270   epsilon: 0.7690617100050134    steps: 175     evaluation reward: 2.92\n",
            "episode: 1664   score: 7.0   memory length: 333650   epsilon: 0.7686855100050216    steps: 380     evaluation reward: 2.96\n",
            "episode: 1665   score: 2.0   memory length: 333833   epsilon: 0.7685043400050255    steps: 183     evaluation reward: 2.95\n",
            "episode: 1666   score: 4.0   memory length: 334105   epsilon: 0.7682350600050314    steps: 272     evaluation reward: 2.98\n",
            "episode: 1667   score: 4.0   memory length: 334383   epsilon: 0.7679598400050374    steps: 278     evaluation reward: 3.01\n",
            "episode: 1668   score: 2.0   memory length: 334589   epsilon: 0.7677559000050418    steps: 206     evaluation reward: 3.03\n",
            "episode: 1669   score: 4.0   memory length: 334857   epsilon: 0.7674905800050476    steps: 268     evaluation reward: 3.07\n",
            "episode: 1670   score: 2.0   memory length: 335046   epsilon: 0.7673034700050516    steps: 189     evaluation reward: 3.07\n",
            "episode: 1671   score: 5.0   memory length: 335348   epsilon: 0.7670044900050581    steps: 302     evaluation reward: 3.11\n",
            "episode: 1672   score: 3.0   memory length: 335593   epsilon: 0.7667619400050634    steps: 245     evaluation reward: 3.12\n",
            "episode: 1673   score: 4.0   memory length: 335874   epsilon: 0.7664837500050694    steps: 281     evaluation reward: 3.11\n",
            "episode: 1674   score: 5.0   memory length: 336172   epsilon: 0.7661887300050758    steps: 298     evaluation reward: 3.13\n",
            "episode: 1675   score: 4.0   memory length: 336491   epsilon: 0.7658729200050827    steps: 319     evaluation reward: 3.15\n",
            "episode: 1676   score: 3.0   memory length: 336728   epsilon: 0.7656382900050878    steps: 237     evaluation reward: 3.14\n",
            "episode: 1677   score: 3.0   memory length: 336945   epsilon: 0.7654234600050924    steps: 217     evaluation reward: 3.14\n",
            "episode: 1678   score: 5.0   memory length: 337312   epsilon: 0.7650601300051003    steps: 367     evaluation reward: 3.13\n",
            "episode: 1679   score: 6.0   memory length: 337692   epsilon: 0.7646839300051085    steps: 380     evaluation reward: 3.16\n",
            "episode: 1680   score: 3.0   memory length: 337907   epsilon: 0.7644710800051131    steps: 215     evaluation reward: 3.14\n",
            "episode: 1681   score: 1.0   memory length: 338082   epsilon: 0.7642978300051169    steps: 175     evaluation reward: 3.11\n",
            "episode: 1682   score: 3.0   memory length: 338350   epsilon: 0.7640325100051226    steps: 268     evaluation reward: 3.1\n",
            "episode: 1683   score: 5.0   memory length: 338687   epsilon: 0.7636988800051299    steps: 337     evaluation reward: 3.12\n",
            "episode: 1684   score: 1.0   memory length: 338838   epsilon: 0.7635493900051331    steps: 151     evaluation reward: 3.1\n",
            "episode: 1685   score: 0.0   memory length: 338964   epsilon: 0.7634246500051358    steps: 126     evaluation reward: 3.05\n",
            "episode: 1686   score: 2.0   memory length: 339157   epsilon: 0.76323358000514    steps: 193     evaluation reward: 3.02\n",
            "episode: 1687   score: 4.0   memory length: 339422   epsilon: 0.7629712300051457    steps: 265     evaluation reward: 3.05\n",
            "episode: 1688   score: 3.0   memory length: 339668   epsilon: 0.762727690005151    steps: 246     evaluation reward: 3.05\n",
            "episode: 1689   score: 1.0   memory length: 339836   epsilon: 0.7625613700051546    steps: 168     evaluation reward: 3.04\n",
            "episode: 1690   score: 4.0   memory length: 340105   epsilon: 0.7622950600051603    steps: 269     evaluation reward: 3.04\n",
            "episode: 1691   score: 2.0   memory length: 340312   epsilon: 0.7620901300051648    steps: 207     evaluation reward: 3.04\n",
            "episode: 1692   score: 1.0   memory length: 340470   epsilon: 0.7619337100051682    steps: 158     evaluation reward: 3.01\n",
            "episode: 1693   score: 4.0   memory length: 340748   epsilon: 0.7616584900051742    steps: 278     evaluation reward: 2.99\n",
            "episode: 1694   score: 3.0   memory length: 340985   epsilon: 0.7614238600051793    steps: 237     evaluation reward: 2.99\n",
            "episode: 1695   score: 2.0   memory length: 341181   epsilon: 0.7612298200051835    steps: 196     evaluation reward: 2.98\n",
            "episode: 1696   score: 4.0   memory length: 341437   epsilon: 0.760976380005189    steps: 256     evaluation reward: 3.02\n",
            "episode: 1697   score: 5.0   memory length: 341795   epsilon: 0.7606219600051967    steps: 358     evaluation reward: 3.03\n",
            "episode: 1698   score: 8.0   memory length: 342152   epsilon: 0.7602685300052043    steps: 357     evaluation reward: 3.11\n",
            "episode: 1699   score: 6.0   memory length: 342481   epsilon: 0.7599428200052114    steps: 329     evaluation reward: 3.14\n",
            "episode: 1700   score: 6.0   memory length: 342871   epsilon: 0.7595567200052198    steps: 390     evaluation reward: 3.16\n",
            "episode: 1701   score: 1.0   memory length: 343025   epsilon: 0.7594042600052231    steps: 154     evaluation reward: 3.16\n",
            "episode: 1702   score: 7.0   memory length: 343408   epsilon: 0.7590250900052313    steps: 383     evaluation reward: 3.17\n",
            "episode: 1703   score: 2.0   memory length: 343613   epsilon: 0.7588221400052357    steps: 205     evaluation reward: 3.17\n",
            "episode: 1704   score: 5.0   memory length: 343939   epsilon: 0.7584994000052427    steps: 326     evaluation reward: 3.2\n",
            "episode: 1705   score: 4.0   memory length: 344217   epsilon: 0.7582241800052487    steps: 278     evaluation reward: 3.24\n",
            "episode: 1706   score: 3.0   memory length: 344459   epsilon: 0.7579846000052539    steps: 242     evaluation reward: 3.21\n",
            "episode: 1707   score: 5.0   memory length: 344792   epsilon: 0.7576549300052611    steps: 333     evaluation reward: 3.26\n",
            "episode: 1708   score: 2.0   memory length: 344982   epsilon: 0.7574668300052652    steps: 190     evaluation reward: 3.27\n",
            "episode: 1709   score: 3.0   memory length: 345213   epsilon: 0.7572381400052701    steps: 231     evaluation reward: 3.26\n",
            "episode: 1710   score: 10.0   memory length: 345662   epsilon: 0.7567936300052798    steps: 449     evaluation reward: 3.32\n",
            "episode: 1711   score: 3.0   memory length: 345879   epsilon: 0.7565788000052844    steps: 217     evaluation reward: 3.34\n",
            "episode: 1712   score: 1.0   memory length: 346059   epsilon: 0.7564006000052883    steps: 180     evaluation reward: 3.34\n",
            "episode: 1713   score: 2.0   memory length: 346275   epsilon: 0.756186760005293    steps: 216     evaluation reward: 3.34\n",
            "episode: 1714   score: 6.0   memory length: 346604   epsilon: 0.7558610500053    steps: 329     evaluation reward: 3.36\n",
            "episode: 1715   score: 2.0   memory length: 346811   epsilon: 0.7556561200053045    steps: 207     evaluation reward: 3.35\n",
            "episode: 1716   score: 4.0   memory length: 347118   epsilon: 0.7553521900053111    steps: 307     evaluation reward: 3.34\n",
            "episode: 1717   score: 8.0   memory length: 347568   epsilon: 0.7549066900053207    steps: 450     evaluation reward: 3.4\n",
            "episode: 1718   score: 5.0   memory length: 347921   epsilon: 0.7545572200053283    steps: 353     evaluation reward: 3.45\n",
            "episode: 1719   score: 2.0   memory length: 348124   epsilon: 0.7543562500053327    steps: 203     evaluation reward: 3.46\n",
            "episode: 1720   score: 6.0   memory length: 348442   epsilon: 0.7540414300053395    steps: 318     evaluation reward: 3.5\n",
            "episode: 1721   score: 3.0   memory length: 348653   epsilon: 0.753832540005344    steps: 211     evaluation reward: 3.49\n",
            "episode: 1722   score: 2.0   memory length: 348857   epsilon: 0.7536305800053484    steps: 204     evaluation reward: 3.43\n",
            "episode: 1723   score: 3.0   memory length: 349090   epsilon: 0.7533999100053534    steps: 233     evaluation reward: 3.41\n",
            "episode: 1724   score: 2.0   memory length: 349283   epsilon: 0.7532088400053576    steps: 193     evaluation reward: 3.4\n",
            "episode: 1725   score: 3.0   memory length: 349524   epsilon: 0.7529702500053628    steps: 241     evaluation reward: 3.4\n",
            "episode: 1726   score: 3.0   memory length: 349774   epsilon: 0.7527227500053681    steps: 250     evaluation reward: 3.42\n",
            "episode: 1727   score: 0.0   memory length: 349906   epsilon: 0.752592070005371    steps: 132     evaluation reward: 3.38\n",
            "now time :  2019-12-12 19:20:04.448807\n",
            "episode: 1728   score: 2.0   memory length: 350109   epsilon: 0.7523911000053753    steps: 203     evaluation reward: 3.34\n",
            "episode: 1729   score: 3.0   memory length: 350354   epsilon: 0.7521485500053806    steps: 245     evaluation reward: 3.34\n",
            "episode: 1730   score: 2.0   memory length: 350545   epsilon: 0.7519594600053847    steps: 191     evaluation reward: 3.33\n",
            "episode: 1731   score: 4.0   memory length: 350792   epsilon: 0.75171493000539    steps: 247     evaluation reward: 3.32\n",
            "episode: 1732   score: 4.0   memory length: 351050   epsilon: 0.7514595100053956    steps: 258     evaluation reward: 3.35\n",
            "episode: 1733   score: 3.0   memory length: 351287   epsilon: 0.7512248800054007    steps: 237     evaluation reward: 3.34\n",
            "episode: 1734   score: 6.0   memory length: 351678   epsilon: 0.7508377900054091    steps: 391     evaluation reward: 3.38\n",
            "episode: 1735   score: 3.0   memory length: 351920   epsilon: 0.7505982100054143    steps: 242     evaluation reward: 3.39\n",
            "episode: 1736   score: 3.0   memory length: 352147   epsilon: 0.7503734800054191    steps: 227     evaluation reward: 3.38\n",
            "episode: 1737   score: 3.0   memory length: 352363   epsilon: 0.7501596400054238    steps: 216     evaluation reward: 3.4\n",
            "episode: 1738   score: 3.0   memory length: 352599   epsilon: 0.7499260000054289    steps: 236     evaluation reward: 3.38\n",
            "episode: 1739   score: 5.0   memory length: 352929   epsilon: 0.749599300005436    steps: 330     evaluation reward: 3.39\n",
            "episode: 1740   score: 2.0   memory length: 353161   epsilon: 0.7493696200054409    steps: 232     evaluation reward: 3.39\n",
            "episode: 1741   score: 4.0   memory length: 353465   epsilon: 0.7490686600054475    steps: 304     evaluation reward: 3.37\n",
            "episode: 1742   score: 3.0   memory length: 353697   epsilon: 0.7488389800054525    steps: 232     evaluation reward: 3.36\n",
            "episode: 1743   score: 3.0   memory length: 353954   epsilon: 0.748584550005458    steps: 257     evaluation reward: 3.34\n",
            "episode: 1744   score: 4.0   memory length: 354215   epsilon: 0.7483261600054636    steps: 261     evaluation reward: 3.37\n",
            "episode: 1745   score: 3.0   memory length: 354433   epsilon: 0.7481103400054683    steps: 218     evaluation reward: 3.38\n",
            "episode: 1746   score: 3.0   memory length: 354671   epsilon: 0.7478747200054734    steps: 238     evaluation reward: 3.37\n",
            "episode: 1747   score: 4.0   memory length: 354939   epsilon: 0.7476094000054792    steps: 268     evaluation reward: 3.35\n",
            "episode: 1748   score: 5.0   memory length: 355267   epsilon: 0.7472846800054862    steps: 328     evaluation reward: 3.38\n",
            "episode: 1749   score: 3.0   memory length: 355513   epsilon: 0.7470411400054915    steps: 246     evaluation reward: 3.4\n",
            "episode: 1750   score: 2.0   memory length: 355713   epsilon: 0.7468431400054958    steps: 200     evaluation reward: 3.4\n",
            "episode: 1751   score: 7.0   memory length: 356089   epsilon: 0.7464709000055039    steps: 376     evaluation reward: 3.44\n",
            "episode: 1752   score: 6.0   memory length: 356479   epsilon: 0.7460848000055122    steps: 390     evaluation reward: 3.45\n",
            "episode: 1753   score: 5.0   memory length: 356755   epsilon: 0.7458115600055182    steps: 276     evaluation reward: 3.48\n",
            "episode: 1754   score: 3.0   memory length: 356978   epsilon: 0.745590790005523    steps: 223     evaluation reward: 3.49\n",
            "episode: 1755   score: 5.0   memory length: 357268   epsilon: 0.7453036900055292    steps: 290     evaluation reward: 3.51\n",
            "episode: 1756   score: 4.0   memory length: 357539   epsilon: 0.745035400005535    steps: 271     evaluation reward: 3.53\n",
            "episode: 1757   score: 7.0   memory length: 357793   epsilon: 0.7447839400055405    steps: 254     evaluation reward: 3.56\n",
            "episode: 1758   score: 4.0   memory length: 358092   epsilon: 0.7444879300055469    steps: 299     evaluation reward: 3.57\n",
            "episode: 1759   score: 2.0   memory length: 358316   epsilon: 0.7442661700055517    steps: 224     evaluation reward: 3.59\n",
            "episode: 1760   score: 3.0   memory length: 358564   epsilon: 0.7440206500055571    steps: 248     evaluation reward: 3.59\n",
            "episode: 1761   score: 4.0   memory length: 358844   epsilon: 0.7437434500055631    steps: 280     evaluation reward: 3.58\n",
            "episode: 1762   score: 1.0   memory length: 359013   epsilon: 0.7435761400055667    steps: 169     evaluation reward: 3.57\n",
            "episode: 1763   score: 2.0   memory length: 359196   epsilon: 0.7433949700055706    steps: 183     evaluation reward: 3.58\n",
            "episode: 1764   score: 2.0   memory length: 359396   epsilon: 0.7431969700055749    steps: 200     evaluation reward: 3.53\n",
            "episode: 1765   score: 0.0   memory length: 359521   epsilon: 0.7430732200055776    steps: 125     evaluation reward: 3.51\n",
            "episode: 1766   score: 2.0   memory length: 359710   epsilon: 0.7428861100055817    steps: 189     evaluation reward: 3.49\n",
            "episode: 1767   score: 4.0   memory length: 359988   epsilon: 0.7426108900055877    steps: 278     evaluation reward: 3.49\n",
            "episode: 1768   score: 6.0   memory length: 360345   epsilon: 0.7422574600055953    steps: 357     evaluation reward: 3.53\n",
            "episode: 1769   score: 1.0   memory length: 360496   epsilon: 0.7421079700055986    steps: 151     evaluation reward: 3.5\n",
            "episode: 1770   score: 4.0   memory length: 360762   epsilon: 0.7418446300056043    steps: 266     evaluation reward: 3.52\n",
            "episode: 1771   score: 4.0   memory length: 361050   epsilon: 0.7415595100056105    steps: 288     evaluation reward: 3.51\n",
            "episode: 1772   score: 4.0   memory length: 361345   epsilon: 0.7412674600056168    steps: 295     evaluation reward: 3.52\n",
            "episode: 1773   score: 5.0   memory length: 361700   epsilon: 0.7409160100056245    steps: 355     evaluation reward: 3.53\n",
            "episode: 1774   score: 5.0   memory length: 362013   epsilon: 0.7406061400056312    steps: 313     evaluation reward: 3.53\n",
            "episode: 1775   score: 1.0   memory length: 362190   epsilon: 0.740430910005635    steps: 177     evaluation reward: 3.5\n",
            "episode: 1776   score: 5.0   memory length: 362530   epsilon: 0.7400943100056423    steps: 340     evaluation reward: 3.52\n",
            "episode: 1777   score: 8.0   memory length: 363023   epsilon: 0.7396062400056529    steps: 493     evaluation reward: 3.57\n",
            "episode: 1778   score: 1.0   memory length: 363184   epsilon: 0.7394468500056564    steps: 161     evaluation reward: 3.53\n",
            "episode: 1779   score: 6.0   memory length: 363574   epsilon: 0.7390607500056647    steps: 390     evaluation reward: 3.53\n",
            "episode: 1780   score: 4.0   memory length: 363872   epsilon: 0.7387657300056711    steps: 298     evaluation reward: 3.54\n",
            "episode: 1781   score: 3.0   memory length: 364130   epsilon: 0.7385103100056767    steps: 258     evaluation reward: 3.56\n",
            "episode: 1782   score: 4.0   memory length: 364403   epsilon: 0.7382400400056826    steps: 273     evaluation reward: 3.57\n",
            "episode: 1783   score: 4.0   memory length: 364661   epsilon: 0.7379846200056881    steps: 258     evaluation reward: 3.56\n",
            "episode: 1784   score: 4.0   memory length: 364939   epsilon: 0.7377094000056941    steps: 278     evaluation reward: 3.59\n",
            "episode: 1785   score: 3.0   memory length: 365162   epsilon: 0.7374886300056989    steps: 223     evaluation reward: 3.62\n",
            "episode: 1786   score: 3.0   memory length: 365404   epsilon: 0.7372490500057041    steps: 242     evaluation reward: 3.63\n",
            "episode: 1787   score: 5.0   memory length: 365769   epsilon: 0.7368877000057119    steps: 365     evaluation reward: 3.64\n",
            "episode: 1788   score: 3.0   memory length: 366017   epsilon: 0.7366421800057172    steps: 248     evaluation reward: 3.64\n",
            "episode: 1789   score: 1.0   memory length: 366173   epsilon: 0.7364877400057206    steps: 156     evaluation reward: 3.64\n",
            "episode: 1790   score: 3.0   memory length: 366385   epsilon: 0.7362778600057251    steps: 212     evaluation reward: 3.63\n",
            "episode: 1791   score: 2.0   memory length: 366565   epsilon: 0.736099660005729    steps: 180     evaluation reward: 3.63\n",
            "episode: 1792   score: 2.0   memory length: 366763   epsilon: 0.7359036400057333    steps: 198     evaluation reward: 3.64\n",
            "episode: 1793   score: 5.0   memory length: 367101   epsilon: 0.7355690200057405    steps: 338     evaluation reward: 3.65\n",
            "episode: 1794   score: 5.0   memory length: 367415   epsilon: 0.7352581600057473    steps: 314     evaluation reward: 3.67\n",
            "episode: 1795   score: 3.0   memory length: 367639   epsilon: 0.7350364000057521    steps: 224     evaluation reward: 3.68\n",
            "episode: 1796   score: 2.0   memory length: 367838   epsilon: 0.7348393900057564    steps: 199     evaluation reward: 3.66\n",
            "episode: 1797   score: 2.0   memory length: 368023   epsilon: 0.7346562400057604    steps: 185     evaluation reward: 3.63\n",
            "episode: 1798   score: 3.0   memory length: 368270   epsilon: 0.7344117100057657    steps: 247     evaluation reward: 3.58\n",
            "episode: 1799   score: 2.0   memory length: 368455   epsilon: 0.7342285600057696    steps: 185     evaluation reward: 3.54\n",
            "episode: 1800   score: 4.0   memory length: 368760   epsilon: 0.7339266100057762    steps: 305     evaluation reward: 3.52\n",
            "episode: 1801   score: 1.0   memory length: 368929   epsilon: 0.7337593000057798    steps: 169     evaluation reward: 3.52\n",
            "episode: 1802   score: 6.0   memory length: 369287   epsilon: 0.7334048800057875    steps: 358     evaluation reward: 3.51\n",
            "episode: 1803   score: 5.0   memory length: 369630   epsilon: 0.7330653100057949    steps: 343     evaluation reward: 3.54\n",
            "episode: 1804   score: 2.0   memory length: 369838   epsilon: 0.7328593900057994    steps: 208     evaluation reward: 3.51\n",
            "episode: 1805   score: 5.0   memory length: 370151   epsilon: 0.7325495200058061    steps: 313     evaluation reward: 3.52\n",
            "episode: 1806   score: 5.0   memory length: 370489   epsilon: 0.7322149000058134    steps: 338     evaluation reward: 3.54\n",
            "episode: 1807   score: 3.0   memory length: 370708   epsilon: 0.7319980900058181    steps: 219     evaluation reward: 3.52\n",
            "episode: 1808   score: 5.0   memory length: 371032   epsilon: 0.731677330005825    steps: 324     evaluation reward: 3.55\n",
            "episode: 1809   score: 3.0   memory length: 371243   epsilon: 0.7314684400058296    steps: 211     evaluation reward: 3.55\n",
            "episode: 1810   score: 3.0   memory length: 371478   epsilon: 0.7312357900058346    steps: 235     evaluation reward: 3.48\n",
            "episode: 1811   score: 5.0   memory length: 371793   epsilon: 0.7309239400058414    steps: 315     evaluation reward: 3.5\n",
            "episode: 1812   score: 6.0   memory length: 372159   epsilon: 0.7305616000058492    steps: 366     evaluation reward: 3.55\n",
            "episode: 1813   score: 4.0   memory length: 372446   epsilon: 0.7302774700058554    steps: 287     evaluation reward: 3.57\n",
            "episode: 1814   score: 4.0   memory length: 372733   epsilon: 0.7299933400058616    steps: 287     evaluation reward: 3.55\n",
            "episode: 1815   score: 3.0   memory length: 372970   epsilon: 0.7297587100058667    steps: 237     evaluation reward: 3.56\n",
            "episode: 1816   score: 3.0   memory length: 373206   epsilon: 0.7295250700058717    steps: 236     evaluation reward: 3.55\n",
            "episode: 1817   score: 3.0   memory length: 373432   epsilon: 0.7293013300058766    steps: 226     evaluation reward: 3.5\n",
            "episode: 1818   score: 1.0   memory length: 373619   epsilon: 0.7291162000058806    steps: 187     evaluation reward: 3.46\n",
            "episode: 1819   score: 2.0   memory length: 373819   epsilon: 0.7289182000058849    steps: 200     evaluation reward: 3.46\n",
            "episode: 1820   score: 3.0   memory length: 374044   epsilon: 0.7286954500058898    steps: 225     evaluation reward: 3.43\n",
            "episode: 1821   score: 12.0   memory length: 374473   epsilon: 0.728270740005899    steps: 429     evaluation reward: 3.52\n",
            "episode: 1822   score: 3.0   memory length: 374727   epsilon: 0.7280192800059044    steps: 254     evaluation reward: 3.53\n",
            "episode: 1823   score: 1.0   memory length: 374882   epsilon: 0.7278658300059078    steps: 155     evaluation reward: 3.51\n",
            "episode: 1824   score: 4.0   memory length: 375167   epsilon: 0.7275836800059139    steps: 285     evaluation reward: 3.53\n",
            "episode: 1825   score: 3.0   memory length: 375379   epsilon: 0.7273738000059184    steps: 212     evaluation reward: 3.53\n",
            "episode: 1826   score: 3.0   memory length: 375628   epsilon: 0.7271272900059238    steps: 249     evaluation reward: 3.53\n",
            "episode: 1827   score: 12.0   memory length: 376137   epsilon: 0.7266233800059347    steps: 509     evaluation reward: 3.65\n",
            "episode: 1828   score: 6.0   memory length: 376487   epsilon: 0.7262768800059423    steps: 350     evaluation reward: 3.69\n",
            "episode: 1829   score: 2.0   memory length: 376693   epsilon: 0.7260729400059467    steps: 206     evaluation reward: 3.68\n",
            "episode: 1830   score: 6.0   memory length: 377021   epsilon: 0.7257482200059537    steps: 328     evaluation reward: 3.72\n",
            "episode: 1831   score: 4.0   memory length: 377323   epsilon: 0.7254492400059602    steps: 302     evaluation reward: 3.72\n",
            "episode: 1832   score: 3.0   memory length: 377587   epsilon: 0.7251878800059659    steps: 264     evaluation reward: 3.71\n",
            "episode: 1833   score: 3.0   memory length: 377833   epsilon: 0.7249443400059712    steps: 246     evaluation reward: 3.71\n",
            "episode: 1834   score: 3.0   memory length: 378070   epsilon: 0.7247097100059763    steps: 237     evaluation reward: 3.68\n",
            "episode: 1835   score: 5.0   memory length: 378361   epsilon: 0.7244216200059825    steps: 291     evaluation reward: 3.7\n",
            "episode: 1836   score: 4.0   memory length: 378639   epsilon: 0.7241464000059885    steps: 278     evaluation reward: 3.71\n",
            "episode: 1837   score: 2.0   memory length: 378852   epsilon: 0.7239355300059931    steps: 213     evaluation reward: 3.7\n",
            "episode: 1838   score: 4.0   memory length: 379128   epsilon: 0.723662290005999    steps: 276     evaluation reward: 3.71\n",
            "episode: 1839   score: 4.0   memory length: 379398   epsilon: 0.7233949900060048    steps: 270     evaluation reward: 3.7\n",
            "episode: 1840   score: 5.0   memory length: 379737   epsilon: 0.7230593800060121    steps: 339     evaluation reward: 3.73\n",
            "episode: 1841   score: 5.0   memory length: 380054   epsilon: 0.7227455500060189    steps: 317     evaluation reward: 3.74\n",
            "episode: 1842   score: 4.0   memory length: 380323   epsilon: 0.7224792400060247    steps: 269     evaluation reward: 3.75\n",
            "episode: 1843   score: 2.0   memory length: 380512   epsilon: 0.7222921300060288    steps: 189     evaluation reward: 3.74\n",
            "episode: 1844   score: 7.0   memory length: 380862   epsilon: 0.7219456300060363    steps: 350     evaluation reward: 3.77\n",
            "episode: 1845   score: 5.0   memory length: 381189   epsilon: 0.7216219000060433    steps: 327     evaluation reward: 3.79\n",
            "episode: 1846   score: 4.0   memory length: 381436   epsilon: 0.7213773700060486    steps: 247     evaluation reward: 3.8\n",
            "episode: 1847   score: 6.0   memory length: 381798   epsilon: 0.7210189900060564    steps: 362     evaluation reward: 3.82\n",
            "episode: 1848   score: 2.0   memory length: 382005   epsilon: 0.7208140600060609    steps: 207     evaluation reward: 3.79\n",
            "episode: 1849   score: 5.0   memory length: 382310   epsilon: 0.7205121100060674    steps: 305     evaluation reward: 3.81\n",
            "episode: 1850   score: 5.0   memory length: 382647   epsilon: 0.7201784800060747    steps: 337     evaluation reward: 3.84\n",
            "episode: 1851   score: 8.0   memory length: 383115   epsilon: 0.7197151600060847    steps: 468     evaluation reward: 3.85\n",
            "episode: 1852   score: 6.0   memory length: 383467   epsilon: 0.7193666800060923    steps: 352     evaluation reward: 3.85\n",
            "episode: 1853   score: 3.0   memory length: 383700   epsilon: 0.7191360100060973    steps: 233     evaluation reward: 3.83\n",
            "episode: 1854   score: 1.0   memory length: 383855   epsilon: 0.7189825600061006    steps: 155     evaluation reward: 3.81\n",
            "episode: 1855   score: 4.0   memory length: 384126   epsilon: 0.7187142700061064    steps: 271     evaluation reward: 3.8\n",
            "episode: 1856   score: 1.0   memory length: 384281   epsilon: 0.7185608200061098    steps: 155     evaluation reward: 3.77\n",
            "episode: 1857   score: 2.0   memory length: 384487   epsilon: 0.7183568800061142    steps: 206     evaluation reward: 3.72\n",
            "episode: 1858   score: 5.0   memory length: 384837   epsilon: 0.7180103800061217    steps: 350     evaluation reward: 3.73\n",
            "episode: 1859   score: 7.0   memory length: 385243   epsilon: 0.7176084400061304    steps: 406     evaluation reward: 3.78\n",
            "episode: 1860   score: 3.0   memory length: 385469   epsilon: 0.7173847000061353    steps: 226     evaluation reward: 3.78\n",
            "episode: 1861   score: 6.0   memory length: 385812   epsilon: 0.7170451300061427    steps: 343     evaluation reward: 3.8\n",
            "episode: 1862   score: 3.0   memory length: 386031   epsilon: 0.7168283200061474    steps: 219     evaluation reward: 3.82\n",
            "episode: 1863   score: 3.0   memory length: 386267   epsilon: 0.7165946800061525    steps: 236     evaluation reward: 3.83\n",
            "episode: 1864   score: 10.0   memory length: 386666   epsilon: 0.716199670006161    steps: 399     evaluation reward: 3.91\n",
            "episode: 1865   score: 3.0   memory length: 386922   epsilon: 0.7159462300061665    steps: 256     evaluation reward: 3.94\n",
            "episode: 1866   score: 3.0   memory length: 387135   epsilon: 0.7157353600061711    steps: 213     evaluation reward: 3.95\n",
            "episode: 1867   score: 3.0   memory length: 387354   epsilon: 0.7155185500061758    steps: 219     evaluation reward: 3.94\n",
            "episode: 1868   score: 4.0   memory length: 387623   epsilon: 0.7152522400061816    steps: 269     evaluation reward: 3.92\n",
            "episode: 1869   score: 5.0   memory length: 387963   epsilon: 0.7149156400061889    steps: 340     evaluation reward: 3.96\n",
            "episode: 1870   score: 4.0   memory length: 388253   epsilon: 0.7146285400061951    steps: 290     evaluation reward: 3.96\n",
            "episode: 1871   score: 1.0   memory length: 388412   epsilon: 0.7144711300061986    steps: 159     evaluation reward: 3.93\n",
            "episode: 1872   score: 3.0   memory length: 388646   epsilon: 0.7142394700062036    steps: 234     evaluation reward: 3.92\n",
            "episode: 1873   score: 4.0   memory length: 388917   epsilon: 0.7139711800062094    steps: 271     evaluation reward: 3.91\n",
            "episode: 1874   score: 5.0   memory length: 389250   epsilon: 0.7136415100062166    steps: 333     evaluation reward: 3.91\n",
            "episode: 1875   score: 5.0   memory length: 389555   epsilon: 0.7133395600062231    steps: 305     evaluation reward: 3.95\n",
            "episode: 1876   score: 11.0   memory length: 389964   epsilon: 0.7129346500062319    steps: 409     evaluation reward: 4.01\n",
            "episode: 1877   score: 8.0   memory length: 390247   epsilon: 0.712654480006238    steps: 283     evaluation reward: 4.01\n",
            "episode: 1878   score: 2.0   memory length: 390460   epsilon: 0.7124436100062426    steps: 213     evaluation reward: 4.02\n",
            "episode: 1879   score: 5.0   memory length: 390755   epsilon: 0.7121515600062489    steps: 295     evaluation reward: 4.01\n",
            "episode: 1880   score: 5.0   memory length: 391072   epsilon: 0.7118377300062557    steps: 317     evaluation reward: 4.02\n",
            "episode: 1881   score: 5.0   memory length: 391350   epsilon: 0.7115625100062617    steps: 278     evaluation reward: 4.04\n",
            "episode: 1882   score: 6.0   memory length: 391680   epsilon: 0.7112358100062688    steps: 330     evaluation reward: 4.06\n",
            "episode: 1883   score: 6.0   memory length: 392063   epsilon: 0.710856640006277    steps: 383     evaluation reward: 4.08\n",
            "episode: 1884   score: 8.0   memory length: 392493   epsilon: 0.7104309400062863    steps: 430     evaluation reward: 4.12\n",
            "episode: 1885   score: 3.0   memory length: 392734   epsilon: 0.7101923500062914    steps: 241     evaluation reward: 4.12\n",
            "episode: 1886   score: 3.0   memory length: 392971   epsilon: 0.7099577200062965    steps: 237     evaluation reward: 4.12\n",
            "episode: 1887   score: 3.0   memory length: 393218   epsilon: 0.7097131900063018    steps: 247     evaluation reward: 4.1\n",
            "episode: 1888   score: 8.0   memory length: 393523   epsilon: 0.7094112400063084    steps: 305     evaluation reward: 4.15\n",
            "episode: 1889   score: 6.0   memory length: 393897   epsilon: 0.7090409800063164    steps: 374     evaluation reward: 4.2\n",
            "episode: 1890   score: 2.0   memory length: 394102   epsilon: 0.7088380300063208    steps: 205     evaluation reward: 4.19\n",
            "episode: 1891   score: 7.0   memory length: 394489   epsilon: 0.7084549000063292    steps: 387     evaluation reward: 4.24\n",
            "episode: 1892   score: 2.0   memory length: 394682   epsilon: 0.7082638300063333    steps: 193     evaluation reward: 4.24\n",
            "episode: 1893   score: 2.0   memory length: 394884   epsilon: 0.7080638500063376    steps: 202     evaluation reward: 4.21\n",
            "episode: 1894   score: 5.0   memory length: 395214   epsilon: 0.7077371500063447    steps: 330     evaluation reward: 4.21\n",
            "episode: 1895   score: 5.0   memory length: 395527   epsilon: 0.7074272800063515    steps: 313     evaluation reward: 4.23\n",
            "episode: 1896   score: 5.0   memory length: 395881   epsilon: 0.7070768200063591    steps: 354     evaluation reward: 4.26\n",
            "episode: 1897   score: 4.0   memory length: 396148   epsilon: 0.7068124900063648    steps: 267     evaluation reward: 4.28\n",
            "episode: 1898   score: 4.0   memory length: 396435   epsilon: 0.706528360006371    steps: 287     evaluation reward: 4.29\n",
            "episode: 1899   score: 2.0   memory length: 396624   epsilon: 0.706341250006375    steps: 189     evaluation reward: 4.29\n",
            "episode: 1900   score: 4.0   memory length: 396896   epsilon: 0.7060719700063809    steps: 272     evaluation reward: 4.29\n",
            "episode: 1901   score: 1.0   memory length: 397077   epsilon: 0.7058927800063848    steps: 181     evaluation reward: 4.29\n",
            "episode: 1902   score: 6.0   memory length: 397418   epsilon: 0.7055551900063921    steps: 341     evaluation reward: 4.29\n",
            "episode: 1903   score: 4.0   memory length: 397678   epsilon: 0.7052977900063977    steps: 260     evaluation reward: 4.28\n",
            "episode: 1904   score: 5.0   memory length: 397993   epsilon: 0.7049859400064045    steps: 315     evaluation reward: 4.31\n",
            "episode: 1905   score: 3.0   memory length: 398217   epsilon: 0.7047641800064093    steps: 224     evaluation reward: 4.29\n",
            "episode: 1906   score: 6.0   memory length: 398567   epsilon: 0.7044176800064168    steps: 350     evaluation reward: 4.3\n",
            "episode: 1907   score: 5.0   memory length: 398858   epsilon: 0.7041295900064231    steps: 291     evaluation reward: 4.32\n",
            "episode: 1908   score: 9.0   memory length: 399205   epsilon: 0.7037860600064305    steps: 347     evaluation reward: 4.36\n",
            "episode: 1909   score: 5.0   memory length: 399503   epsilon: 0.7034910400064369    steps: 298     evaluation reward: 4.38\n",
            "episode: 1910   score: 3.0   memory length: 399742   epsilon: 0.703254430006442    steps: 239     evaluation reward: 4.38\n",
            "episode: 1911   score: 1.0   memory length: 399902   epsilon: 0.7030960300064455    steps: 160     evaluation reward: 4.34\n",
            "now time :  2019-12-12 19:41:48.848678\n",
            "episode: 1912   score: 5.0   memory length: 400214   epsilon: 0.7027871500064522    steps: 312     evaluation reward: 4.33\n",
            "episode: 1913   score: 3.0   memory length: 400445   epsilon: 0.7025584600064572    steps: 231     evaluation reward: 4.32\n",
            "episode: 1914   score: 2.0   memory length: 400663   epsilon: 0.7023426400064618    steps: 218     evaluation reward: 4.3\n",
            "episode: 1915   score: 0.0   memory length: 400797   epsilon: 0.7022099800064647    steps: 134     evaluation reward: 4.27\n",
            "episode: 1916   score: 5.0   memory length: 401093   epsilon: 0.7019169400064711    steps: 296     evaluation reward: 4.29\n",
            "episode: 1917   score: 0.0   memory length: 401215   epsilon: 0.7017961600064737    steps: 122     evaluation reward: 4.26\n",
            "episode: 1918   score: 6.0   memory length: 401541   epsilon: 0.7014734200064807    steps: 326     evaluation reward: 4.31\n",
            "episode: 1919   score: 6.0   memory length: 401896   epsilon: 0.7011219700064883    steps: 355     evaluation reward: 4.35\n",
            "episode: 1920   score: 3.0   memory length: 402147   epsilon: 0.7008734800064937    steps: 251     evaluation reward: 4.35\n",
            "episode: 1921   score: 4.0   memory length: 402440   epsilon: 0.7005834100065    steps: 293     evaluation reward: 4.27\n",
            "episode: 1922   score: 5.0   memory length: 402748   epsilon: 0.7002784900065067    steps: 308     evaluation reward: 4.29\n",
            "episode: 1923   score: 6.0   memory length: 403075   epsilon: 0.6999547600065137    steps: 327     evaluation reward: 4.34\n",
            "episode: 1924   score: 5.0   memory length: 403401   epsilon: 0.6996320200065207    steps: 326     evaluation reward: 4.35\n",
            "episode: 1925   score: 5.0   memory length: 403725   epsilon: 0.6993112600065277    steps: 324     evaluation reward: 4.37\n",
            "episode: 1926   score: 3.0   memory length: 403962   epsilon: 0.6990766300065328    steps: 237     evaluation reward: 4.37\n",
            "episode: 1927   score: 4.0   memory length: 404229   epsilon: 0.6988123000065385    steps: 267     evaluation reward: 4.29\n",
            "episode: 1928   score: 3.0   memory length: 404451   epsilon: 0.6985925200065433    steps: 222     evaluation reward: 4.26\n",
            "episode: 1929   score: 1.0   memory length: 404608   epsilon: 0.6984370900065466    steps: 157     evaluation reward: 4.25\n",
            "episode: 1930   score: 3.0   memory length: 404841   epsilon: 0.6982064200065516    steps: 233     evaluation reward: 4.22\n",
            "episode: 1931   score: 7.0   memory length: 405251   epsilon: 0.6978005200065605    steps: 410     evaluation reward: 4.25\n",
            "episode: 1932   score: 6.0   memory length: 405618   epsilon: 0.6974371900065683    steps: 367     evaluation reward: 4.28\n",
            "episode: 1933   score: 5.0   memory length: 405956   epsilon: 0.6971025700065756    steps: 338     evaluation reward: 4.3\n",
            "episode: 1934   score: 5.0   memory length: 406285   epsilon: 0.6967768600065827    steps: 329     evaluation reward: 4.32\n",
            "episode: 1935   score: 4.0   memory length: 406548   epsilon: 0.6965164900065883    steps: 263     evaluation reward: 4.31\n",
            "episode: 1936   score: 3.0   memory length: 406804   epsilon: 0.6962630500065938    steps: 256     evaluation reward: 4.3\n",
            "episode: 1937   score: 2.0   memory length: 406988   epsilon: 0.6960808900065978    steps: 184     evaluation reward: 4.3\n",
            "episode: 1938   score: 2.0   memory length: 407180   epsilon: 0.6958908100066019    steps: 192     evaluation reward: 4.28\n",
            "episode: 1939   score: 9.0   memory length: 407647   epsilon: 0.695428480006612    steps: 467     evaluation reward: 4.33\n",
            "episode: 1940   score: 2.0   memory length: 407865   epsilon: 0.6952126600066166    steps: 218     evaluation reward: 4.3\n",
            "episode: 1941   score: 3.0   memory length: 408091   epsilon: 0.6949889200066215    steps: 226     evaluation reward: 4.28\n",
            "episode: 1942   score: 3.0   memory length: 408309   epsilon: 0.6947731000066262    steps: 218     evaluation reward: 4.27\n",
            "episode: 1943   score: 5.0   memory length: 408621   epsilon: 0.6944642200066329    steps: 312     evaluation reward: 4.3\n",
            "episode: 1944   score: 5.0   memory length: 408951   epsilon: 0.69413752000664    steps: 330     evaluation reward: 4.28\n",
            "episode: 1945   score: 3.0   memory length: 409210   epsilon: 0.6938811100066455    steps: 259     evaluation reward: 4.26\n",
            "episode: 1946   score: 5.0   memory length: 409506   epsilon: 0.6935880700066519    steps: 296     evaluation reward: 4.27\n",
            "episode: 1947   score: 4.0   memory length: 409763   epsilon: 0.6933336400066574    steps: 257     evaluation reward: 4.25\n",
            "episode: 1948   score: 3.0   memory length: 409980   epsilon: 0.6931188100066621    steps: 217     evaluation reward: 4.26\n",
            "episode: 1949   score: 9.0   memory length: 410451   epsilon: 0.6926525200066722    steps: 471     evaluation reward: 4.3\n",
            "episode: 1950   score: 3.0   memory length: 410701   epsilon: 0.6924050200066776    steps: 250     evaluation reward: 4.28\n",
            "episode: 1951   score: 6.0   memory length: 411041   epsilon: 0.6920684200066849    steps: 340     evaluation reward: 4.26\n",
            "episode: 1952   score: 3.0   memory length: 411259   epsilon: 0.6918526000066896    steps: 218     evaluation reward: 4.23\n",
            "episode: 1953   score: 6.0   memory length: 411569   epsilon: 0.6915457000066962    steps: 310     evaluation reward: 4.26\n",
            "episode: 1954   score: 7.0   memory length: 411972   epsilon: 0.6911467300067049    steps: 403     evaluation reward: 4.32\n",
            "episode: 1955   score: 5.0   memory length: 412296   epsilon: 0.6908259700067119    steps: 324     evaluation reward: 4.33\n",
            "episode: 1956   score: 1.0   memory length: 412454   epsilon: 0.6906695500067153    steps: 158     evaluation reward: 4.33\n",
            "episode: 1957   score: 12.0   memory length: 412962   epsilon: 0.6901666300067262    steps: 508     evaluation reward: 4.43\n",
            "episode: 1958   score: 3.0   memory length: 413180   epsilon: 0.6899508100067309    steps: 218     evaluation reward: 4.41\n",
            "episode: 1959   score: 5.0   memory length: 413525   epsilon: 0.6896092600067383    steps: 345     evaluation reward: 4.39\n",
            "episode: 1960   score: 7.0   memory length: 413902   epsilon: 0.6892360300067464    steps: 377     evaluation reward: 4.43\n",
            "episode: 1961   score: 3.0   memory length: 414138   epsilon: 0.6890023900067515    steps: 236     evaluation reward: 4.4\n",
            "episode: 1962   score: 4.0   memory length: 414424   epsilon: 0.6887192500067576    steps: 286     evaluation reward: 4.41\n",
            "episode: 1963   score: 6.0   memory length: 414790   epsilon: 0.6883569100067655    steps: 366     evaluation reward: 4.44\n",
            "episode: 1964   score: 3.0   memory length: 415033   epsilon: 0.6881163400067707    steps: 243     evaluation reward: 4.37\n",
            "episode: 1965   score: 2.0   memory length: 415255   epsilon: 0.6878965600067755    steps: 222     evaluation reward: 4.36\n",
            "episode: 1966   score: 3.0   memory length: 415487   epsilon: 0.6876668800067804    steps: 232     evaluation reward: 4.36\n",
            "episode: 1967   score: 4.0   memory length: 415755   epsilon: 0.6874015600067862    steps: 268     evaluation reward: 4.37\n",
            "episode: 1968   score: 3.0   memory length: 415974   epsilon: 0.6871847500067909    steps: 219     evaluation reward: 4.36\n",
            "episode: 1969   score: 2.0   memory length: 416174   epsilon: 0.6869867500067952    steps: 200     evaluation reward: 4.33\n",
            "episode: 1970   score: 5.0   memory length: 416510   epsilon: 0.6866541100068024    steps: 336     evaluation reward: 4.34\n",
            "episode: 1971   score: 2.0   memory length: 416705   epsilon: 0.6864610600068066    steps: 195     evaluation reward: 4.35\n",
            "episode: 1972   score: 3.0   memory length: 416946   epsilon: 0.6862224700068118    steps: 241     evaluation reward: 4.35\n",
            "episode: 1973   score: 6.0   memory length: 417271   epsilon: 0.6859007200068188    steps: 325     evaluation reward: 4.37\n",
            "episode: 1974   score: 5.0   memory length: 417611   epsilon: 0.6855641200068261    steps: 340     evaluation reward: 4.37\n",
            "episode: 1975   score: 4.0   memory length: 417910   epsilon: 0.6852681100068325    steps: 299     evaluation reward: 4.36\n",
            "episode: 1976   score: 3.0   memory length: 418161   epsilon: 0.6850196200068379    steps: 251     evaluation reward: 4.28\n",
            "episode: 1977   score: 1.0   memory length: 418315   epsilon: 0.6848671600068412    steps: 154     evaluation reward: 4.21\n",
            "episode: 1978   score: 4.0   memory length: 418591   epsilon: 0.6845939200068472    steps: 276     evaluation reward: 4.23\n",
            "episode: 1979   score: 6.0   memory length: 418964   epsilon: 0.6842246500068552    steps: 373     evaluation reward: 4.24\n",
            "episode: 1980   score: 4.0   memory length: 419249   epsilon: 0.6839425000068613    steps: 285     evaluation reward: 4.23\n",
            "episode: 1981   score: 3.0   memory length: 419517   epsilon: 0.6836771800068671    steps: 268     evaluation reward: 4.21\n",
            "episode: 1982   score: 3.0   memory length: 419753   epsilon: 0.6834435400068721    steps: 236     evaluation reward: 4.18\n",
            "episode: 1983   score: 5.0   memory length: 420084   epsilon: 0.6831158500068792    steps: 331     evaluation reward: 4.17\n",
            "episode: 1984   score: 1.0   memory length: 420236   epsilon: 0.6829653700068825    steps: 152     evaluation reward: 4.1\n",
            "episode: 1985   score: 4.0   memory length: 420526   epsilon: 0.6826782700068887    steps: 290     evaluation reward: 4.11\n",
            "episode: 1986   score: 7.0   memory length: 420938   epsilon: 0.6822703900068976    steps: 412     evaluation reward: 4.15\n",
            "episode: 1987   score: 6.0   memory length: 421260   epsilon: 0.6819516100069045    steps: 322     evaluation reward: 4.18\n",
            "episode: 1988   score: 6.0   memory length: 421598   epsilon: 0.6816169900069118    steps: 338     evaluation reward: 4.16\n",
            "episode: 1989   score: 8.0   memory length: 422016   epsilon: 0.6812031700069208    steps: 418     evaluation reward: 4.18\n",
            "episode: 1990   score: 4.0   memory length: 422285   epsilon: 0.6809368600069265    steps: 269     evaluation reward: 4.2\n",
            "episode: 1991   score: 7.0   memory length: 422675   epsilon: 0.6805507600069349    steps: 390     evaluation reward: 4.2\n",
            "episode: 1992   score: 3.0   memory length: 422905   epsilon: 0.6803230600069399    steps: 230     evaluation reward: 4.21\n",
            "episode: 1993   score: 5.0   memory length: 423211   epsilon: 0.6800201200069464    steps: 306     evaluation reward: 4.24\n",
            "episode: 1994   score: 1.0   memory length: 423383   epsilon: 0.6798498400069501    steps: 172     evaluation reward: 4.2\n",
            "episode: 1995   score: 5.0   memory length: 423697   epsilon: 0.6795389800069569    steps: 314     evaluation reward: 4.2\n",
            "episode: 1996   score: 4.0   memory length: 423948   epsilon: 0.6792904900069623    steps: 251     evaluation reward: 4.19\n",
            "episode: 1997   score: 5.0   memory length: 424279   epsilon: 0.6789628000069694    steps: 331     evaluation reward: 4.2\n",
            "episode: 1998   score: 2.0   memory length: 424472   epsilon: 0.6787717300069736    steps: 193     evaluation reward: 4.18\n",
            "episode: 1999   score: 10.0   memory length: 424920   epsilon: 0.6783282100069832    steps: 448     evaluation reward: 4.26\n",
            "episode: 2000   score: 3.0   memory length: 425143   epsilon: 0.678107440006988    steps: 223     evaluation reward: 4.25\n",
            "episode: 2001   score: 0.0   memory length: 425265   epsilon: 0.6779866600069906    steps: 122     evaluation reward: 4.24\n",
            "episode: 2002   score: 2.0   memory length: 425476   epsilon: 0.6777777700069951    steps: 211     evaluation reward: 4.2\n",
            "episode: 2003   score: 6.0   memory length: 425827   epsilon: 0.6774302800070027    steps: 351     evaluation reward: 4.22\n",
            "episode: 2004   score: 1.0   memory length: 426000   epsilon: 0.6772590100070064    steps: 173     evaluation reward: 4.18\n",
            "episode: 2005   score: 4.0   memory length: 426260   epsilon: 0.677001610007012    steps: 260     evaluation reward: 4.19\n",
            "episode: 2006   score: 3.0   memory length: 426478   epsilon: 0.6767857900070167    steps: 218     evaluation reward: 4.16\n",
            "episode: 2007   score: 4.0   memory length: 426778   epsilon: 0.6764887900070231    steps: 300     evaluation reward: 4.15\n",
            "episode: 2008   score: 4.0   memory length: 427057   epsilon: 0.6762125800070291    steps: 279     evaluation reward: 4.1\n",
            "episode: 2009   score: 6.0   memory length: 427399   epsilon: 0.6758740000070365    steps: 342     evaluation reward: 4.11\n",
            "episode: 2010   score: 5.0   memory length: 427690   epsilon: 0.6755859100070427    steps: 291     evaluation reward: 4.13\n",
            "episode: 2011   score: 0.0   memory length: 427821   epsilon: 0.6754562200070455    steps: 131     evaluation reward: 4.12\n",
            "episode: 2012   score: 0.0   memory length: 427950   epsilon: 0.6753285100070483    steps: 129     evaluation reward: 4.07\n",
            "episode: 2013   score: 4.0   memory length: 428217   epsilon: 0.675064180007054    steps: 267     evaluation reward: 4.08\n",
            "episode: 2014   score: 10.0   memory length: 428652   epsilon: 0.6746335300070634    steps: 435     evaluation reward: 4.16\n",
            "episode: 2015   score: 10.0   memory length: 429162   epsilon: 0.6741286300070743    steps: 510     evaluation reward: 4.26\n",
            "episode: 2016   score: 4.0   memory length: 429439   epsilon: 0.6738544000070803    steps: 277     evaluation reward: 4.25\n",
            "episode: 2017   score: 2.0   memory length: 429632   epsilon: 0.6736633300070844    steps: 193     evaluation reward: 4.27\n",
            "episode: 2018   score: 5.0   memory length: 429970   epsilon: 0.6733287100070917    steps: 338     evaluation reward: 4.26\n",
            "episode: 2019   score: 2.0   memory length: 430174   epsilon: 0.6731267500070961    steps: 204     evaluation reward: 4.22\n",
            "episode: 2020   score: 6.0   memory length: 430543   epsilon: 0.672761440007104    steps: 369     evaluation reward: 4.25\n",
            "episode: 2021   score: 6.0   memory length: 430901   epsilon: 0.6724070200071117    steps: 358     evaluation reward: 4.27\n",
            "episode: 2022   score: 5.0   memory length: 431205   epsilon: 0.6721060600071183    steps: 304     evaluation reward: 4.27\n",
            "episode: 2023   score: 1.0   memory length: 431361   epsilon: 0.6719516200071216    steps: 156     evaluation reward: 4.22\n",
            "episode: 2024   score: 5.0   memory length: 431680   epsilon: 0.6716358100071285    steps: 319     evaluation reward: 4.22\n",
            "episode: 2025   score: 5.0   memory length: 432010   epsilon: 0.6713091100071356    steps: 330     evaluation reward: 4.22\n",
            "episode: 2026   score: 5.0   memory length: 432334   epsilon: 0.6709883500071425    steps: 324     evaluation reward: 4.24\n",
            "episode: 2027   score: 2.0   memory length: 432552   epsilon: 0.6707725300071472    steps: 218     evaluation reward: 4.22\n",
            "episode: 2028   score: 4.0   memory length: 432817   epsilon: 0.6705101800071529    steps: 265     evaluation reward: 4.23\n",
            "episode: 2029   score: 3.0   memory length: 433047   epsilon: 0.6702824800071578    steps: 230     evaluation reward: 4.25\n",
            "episode: 2030   score: 8.0   memory length: 433475   epsilon: 0.669858760007167    steps: 428     evaluation reward: 4.3\n",
            "episode: 2031   score: 6.0   memory length: 433828   epsilon: 0.6695092900071746    steps: 353     evaluation reward: 4.29\n",
            "episode: 2032   score: 1.0   memory length: 433992   epsilon: 0.6693469300071782    steps: 164     evaluation reward: 4.24\n",
            "episode: 2033   score: 5.0   memory length: 434283   epsilon: 0.6690588400071844    steps: 291     evaluation reward: 4.24\n",
            "episode: 2034   score: 2.0   memory length: 434473   epsilon: 0.6688707400071885    steps: 190     evaluation reward: 4.21\n",
            "episode: 2035   score: 5.0   memory length: 434790   epsilon: 0.6685569100071953    steps: 317     evaluation reward: 4.22\n",
            "episode: 2036   score: 7.0   memory length: 435221   epsilon: 0.6681302200072046    steps: 431     evaluation reward: 4.26\n",
            "episode: 2037   score: 4.0   memory length: 435522   epsilon: 0.667832230007211    steps: 301     evaluation reward: 4.28\n",
            "episode: 2038   score: 2.0   memory length: 435735   epsilon: 0.6676213600072156    steps: 213     evaluation reward: 4.28\n",
            "episode: 2039   score: 4.0   memory length: 435996   epsilon: 0.6673629700072212    steps: 261     evaluation reward: 4.23\n",
            "episode: 2040   score: 4.0   memory length: 436275   epsilon: 0.6670867600072272    steps: 279     evaluation reward: 4.25\n",
            "episode: 2041   score: 3.0   memory length: 436511   epsilon: 0.6668531200072323    steps: 236     evaluation reward: 4.25\n",
            "episode: 2042   score: 2.0   memory length: 436722   epsilon: 0.6666442300072368    steps: 211     evaluation reward: 4.24\n",
            "episode: 2043   score: 4.0   memory length: 436988   epsilon: 0.6663808900072425    steps: 266     evaluation reward: 4.23\n",
            "episode: 2044   score: 3.0   memory length: 437204   epsilon: 0.6661670500072472    steps: 216     evaluation reward: 4.21\n",
            "episode: 2045   score: 10.0   memory length: 437602   epsilon: 0.6657730300072557    steps: 398     evaluation reward: 4.28\n",
            "episode: 2046   score: 14.0   memory length: 438124   epsilon: 0.665256250007267    steps: 522     evaluation reward: 4.37\n",
            "episode: 2047   score: 3.0   memory length: 438342   epsilon: 0.6650404300072716    steps: 218     evaluation reward: 4.36\n",
            "episode: 2048   score: 4.0   memory length: 438601   epsilon: 0.6647840200072772    steps: 259     evaluation reward: 4.37\n",
            "episode: 2049   score: 5.0   memory length: 438896   epsilon: 0.6644919700072836    steps: 295     evaluation reward: 4.33\n",
            "episode: 2050   score: 10.0   memory length: 439279   epsilon: 0.6641128000072918    steps: 383     evaluation reward: 4.4\n",
            "episode: 2051   score: 5.0   memory length: 439597   epsilon: 0.6637979800072986    steps: 318     evaluation reward: 4.39\n",
            "episode: 2052   score: 6.0   memory length: 439990   epsilon: 0.6634089100073071    steps: 393     evaluation reward: 4.42\n",
            "episode: 2053   score: 2.0   memory length: 440180   epsilon: 0.6632208100073111    steps: 190     evaluation reward: 4.38\n",
            "episode: 2054   score: 7.0   memory length: 440565   epsilon: 0.6628396600073194    steps: 385     evaluation reward: 4.38\n",
            "episode: 2055   score: 3.0   memory length: 440782   epsilon: 0.6626248300073241    steps: 217     evaluation reward: 4.36\n",
            "episode: 2056   score: 3.0   memory length: 441030   epsilon: 0.6623793100073294    steps: 248     evaluation reward: 4.38\n",
            "episode: 2057   score: 6.0   memory length: 441403   epsilon: 0.6620100400073374    steps: 373     evaluation reward: 4.32\n",
            "episode: 2058   score: 2.0   memory length: 441608   epsilon: 0.6618070900073418    steps: 205     evaluation reward: 4.31\n",
            "episode: 2059   score: 2.0   memory length: 441806   epsilon: 0.6616110700073461    steps: 198     evaluation reward: 4.28\n",
            "episode: 2060   score: 4.0   memory length: 442083   epsilon: 0.661336840007352    steps: 277     evaluation reward: 4.25\n",
            "episode: 2061   score: 2.0   memory length: 442289   epsilon: 0.6611329000073565    steps: 206     evaluation reward: 4.24\n",
            "episode: 2062   score: 4.0   memory length: 442565   epsilon: 0.6608596600073624    steps: 276     evaluation reward: 4.24\n",
            "episode: 2063   score: 3.0   memory length: 442783   epsilon: 0.6606438400073671    steps: 218     evaluation reward: 4.21\n",
            "episode: 2064   score: 4.0   memory length: 443057   epsilon: 0.660372580007373    steps: 274     evaluation reward: 4.22\n",
            "episode: 2065   score: 3.0   memory length: 443297   epsilon: 0.6601349800073781    steps: 240     evaluation reward: 4.23\n",
            "episode: 2066   score: 4.0   memory length: 443574   epsilon: 0.6598607500073841    steps: 277     evaluation reward: 4.24\n",
            "episode: 2067   score: 5.0   memory length: 443864   epsilon: 0.6595736500073903    steps: 290     evaluation reward: 4.25\n",
            "episode: 2068   score: 3.0   memory length: 444077   epsilon: 0.6593627800073949    steps: 213     evaluation reward: 4.25\n",
            "episode: 2069   score: 2.0   memory length: 444282   epsilon: 0.6591598300073993    steps: 205     evaluation reward: 4.25\n",
            "episode: 2070   score: 6.0   memory length: 444649   epsilon: 0.6587965000074072    steps: 367     evaluation reward: 4.26\n",
            "episode: 2071   score: 6.0   memory length: 445035   epsilon: 0.6584143600074155    steps: 386     evaluation reward: 4.3\n",
            "episode: 2072   score: 6.0   memory length: 445367   epsilon: 0.6580856800074226    steps: 332     evaluation reward: 4.33\n",
            "episode: 2073   score: 6.0   memory length: 445702   epsilon: 0.6577540300074298    steps: 335     evaluation reward: 4.33\n",
            "episode: 2074   score: 12.0   memory length: 446178   epsilon: 0.65728279000744    steps: 476     evaluation reward: 4.4\n",
            "episode: 2075   score: 11.0   memory length: 446631   epsilon: 0.6568343200074498    steps: 453     evaluation reward: 4.47\n",
            "episode: 2076   score: 6.0   memory length: 446991   epsilon: 0.6564779200074575    steps: 360     evaluation reward: 4.5\n",
            "episode: 2077   score: 8.0   memory length: 447464   epsilon: 0.6560096500074677    steps: 473     evaluation reward: 4.57\n",
            "episode: 2078   score: 2.0   memory length: 447665   epsilon: 0.655810660007472    steps: 201     evaluation reward: 4.55\n",
            "episode: 2079   score: 4.0   memory length: 447933   epsilon: 0.6555453400074778    steps: 268     evaluation reward: 4.53\n",
            "episode: 2080   score: 3.0   memory length: 448186   epsilon: 0.6552948700074832    steps: 253     evaluation reward: 4.52\n",
            "episode: 2081   score: 6.0   memory length: 448574   epsilon: 0.6549107500074915    steps: 388     evaluation reward: 4.55\n",
            "episode: 2082   score: 5.0   memory length: 448877   epsilon: 0.6546107800074981    steps: 303     evaluation reward: 4.57\n",
            "episode: 2083   score: 4.0   memory length: 449145   epsilon: 0.6543454600075038    steps: 268     evaluation reward: 4.56\n",
            "episode: 2084   score: 11.0   memory length: 449542   epsilon: 0.6539524300075124    steps: 397     evaluation reward: 4.66\n",
            "episode: 2085   score: 6.0   memory length: 449912   epsilon: 0.6535861300075203    steps: 370     evaluation reward: 4.68\n",
            "now time :  2019-12-12 20:04:10.912130\n",
            "episode: 2086   score: 6.0   memory length: 450242   epsilon: 0.6532594300075274    steps: 330     evaluation reward: 4.67\n",
            "episode: 2087   score: 7.0   memory length: 450622   epsilon: 0.6528832300075356    steps: 380     evaluation reward: 4.68\n",
            "episode: 2088   score: 1.0   memory length: 450806   epsilon: 0.6527010700075395    steps: 184     evaluation reward: 4.63\n",
            "episode: 2089   score: 2.0   memory length: 451010   epsilon: 0.6524991100075439    steps: 204     evaluation reward: 4.57\n",
            "episode: 2090   score: 4.0   memory length: 451294   epsilon: 0.65221795000755    steps: 284     evaluation reward: 4.57\n",
            "episode: 2091   score: 6.0   memory length: 451639   epsilon: 0.6518764000075574    steps: 345     evaluation reward: 4.56\n",
            "episode: 2092   score: 6.0   memory length: 451979   epsilon: 0.6515398000075647    steps: 340     evaluation reward: 4.59\n",
            "episode: 2093   score: 4.0   memory length: 452252   epsilon: 0.6512695300075706    steps: 273     evaluation reward: 4.58\n",
            "episode: 2094   score: 4.0   memory length: 452533   epsilon: 0.6509913400075766    steps: 281     evaluation reward: 4.61\n",
            "episode: 2095   score: 4.0   memory length: 452800   epsilon: 0.6507270100075824    steps: 267     evaluation reward: 4.6\n",
            "episode: 2096   score: 4.0   memory length: 453062   epsilon: 0.650467630007588    steps: 262     evaluation reward: 4.6\n",
            "episode: 2097   score: 6.0   memory length: 453450   epsilon: 0.6500835100075963    steps: 388     evaluation reward: 4.61\n",
            "episode: 2098   score: 4.0   memory length: 453737   epsilon: 0.6497993800076025    steps: 287     evaluation reward: 4.63\n",
            "episode: 2099   score: 5.0   memory length: 454044   epsilon: 0.6494954500076091    steps: 307     evaluation reward: 4.58\n",
            "episode: 2100   score: 7.0   memory length: 454435   epsilon: 0.6491083600076175    steps: 391     evaluation reward: 4.62\n",
            "episode: 2101   score: 5.0   memory length: 454725   epsilon: 0.6488212600076237    steps: 290     evaluation reward: 4.67\n",
            "episode: 2102   score: 2.0   memory length: 454929   epsilon: 0.6486193000076281    steps: 204     evaluation reward: 4.67\n",
            "episode: 2103   score: 9.0   memory length: 455305   epsilon: 0.6482470600076362    steps: 376     evaluation reward: 4.7\n",
            "episode: 2104   score: 6.0   memory length: 455669   epsilon: 0.647886700007644    steps: 364     evaluation reward: 4.75\n",
            "episode: 2105   score: 3.0   memory length: 455915   epsilon: 0.6476431600076493    steps: 246     evaluation reward: 4.74\n",
            "episode: 2106   score: 5.0   memory length: 456249   epsilon: 0.6473125000076565    steps: 334     evaluation reward: 4.76\n",
            "episode: 2107   score: 9.0   memory length: 456554   epsilon: 0.647010550007663    steps: 305     evaluation reward: 4.81\n",
            "episode: 2108   score: 3.0   memory length: 456784   epsilon: 0.646782850007668    steps: 230     evaluation reward: 4.8\n",
            "episode: 2109   score: 2.0   memory length: 456966   epsilon: 0.6466026700076719    steps: 182     evaluation reward: 4.76\n",
            "episode: 2110   score: 12.0   memory length: 457422   epsilon: 0.6461512300076817    steps: 456     evaluation reward: 4.83\n",
            "episode: 2111   score: 4.0   memory length: 457699   epsilon: 0.6458770000076877    steps: 277     evaluation reward: 4.87\n",
            "episode: 2112   score: 3.0   memory length: 457945   epsilon: 0.645633460007693    steps: 246     evaluation reward: 4.9\n",
            "episode: 2113   score: 3.0   memory length: 458184   epsilon: 0.6453968500076981    steps: 239     evaluation reward: 4.89\n",
            "episode: 2114   score: 8.0   memory length: 458616   epsilon: 0.6449691700077074    steps: 432     evaluation reward: 4.87\n",
            "episode: 2115   score: 6.0   memory length: 458975   epsilon: 0.6446137600077151    steps: 359     evaluation reward: 4.83\n",
            "episode: 2116   score: 8.0   memory length: 459397   epsilon: 0.6441959800077242    steps: 422     evaluation reward: 4.87\n",
            "episode: 2117   score: 3.0   memory length: 459631   epsilon: 0.6439643200077292    steps: 234     evaluation reward: 4.88\n",
            "episode: 2118   score: 8.0   memory length: 460064   epsilon: 0.6435356500077385    steps: 433     evaluation reward: 4.91\n",
            "episode: 2119   score: 7.0   memory length: 460322   epsilon: 0.643280230007744    steps: 258     evaluation reward: 4.96\n",
            "episode: 2120   score: 9.0   memory length: 460655   epsilon: 0.6429505600077512    steps: 333     evaluation reward: 4.99\n",
            "episode: 2121   score: 6.0   memory length: 460981   epsilon: 0.6426278200077582    steps: 326     evaluation reward: 4.99\n",
            "episode: 2122   score: 8.0   memory length: 461383   epsilon: 0.6422298400077668    steps: 402     evaluation reward: 5.02\n",
            "episode: 2123   score: 4.0   memory length: 461661   epsilon: 0.6419546200077728    steps: 278     evaluation reward: 5.05\n",
            "episode: 2124   score: 2.0   memory length: 461849   epsilon: 0.6417685000077769    steps: 188     evaluation reward: 5.02\n",
            "episode: 2125   score: 5.0   memory length: 462164   epsilon: 0.6414566500077836    steps: 315     evaluation reward: 5.02\n",
            "episode: 2126   score: 5.0   memory length: 462453   epsilon: 0.6411705400077898    steps: 289     evaluation reward: 5.02\n",
            "episode: 2127   score: 4.0   memory length: 462722   epsilon: 0.6409042300077956    steps: 269     evaluation reward: 5.04\n",
            "episode: 2128   score: 4.0   memory length: 463000   epsilon: 0.6406290100078016    steps: 278     evaluation reward: 5.04\n",
            "episode: 2129   score: 8.0   memory length: 463453   epsilon: 0.6401805400078113    steps: 453     evaluation reward: 5.09\n",
            "episode: 2130   score: 3.0   memory length: 463704   epsilon: 0.6399320500078167    steps: 251     evaluation reward: 5.04\n",
            "episode: 2131   score: 7.0   memory length: 464131   epsilon: 0.6395093200078259    steps: 427     evaluation reward: 5.05\n",
            "episode: 2132   score: 4.0   memory length: 464416   epsilon: 0.639227170007832    steps: 285     evaluation reward: 5.08\n",
            "episode: 2133   score: 3.0   memory length: 464633   epsilon: 0.6390123400078367    steps: 217     evaluation reward: 5.06\n",
            "episode: 2134   score: 3.0   memory length: 464892   epsilon: 0.6387559300078423    steps: 259     evaluation reward: 5.07\n",
            "episode: 2135   score: 2.0   memory length: 465094   epsilon: 0.6385559500078466    steps: 202     evaluation reward: 5.04\n",
            "episode: 2136   score: 5.0   memory length: 465408   epsilon: 0.6382450900078533    steps: 314     evaluation reward: 5.02\n",
            "episode: 2137   score: 2.0   memory length: 465601   epsilon: 0.6380540200078575    steps: 193     evaluation reward: 5.0\n",
            "episode: 2138   score: 4.0   memory length: 465855   epsilon: 0.637802560007863    steps: 254     evaluation reward: 5.02\n",
            "episode: 2139   score: 3.0   memory length: 466071   epsilon: 0.6375887200078676    steps: 216     evaluation reward: 5.01\n",
            "episode: 2140   score: 5.0   memory length: 466390   epsilon: 0.6372729100078744    steps: 319     evaluation reward: 5.02\n",
            "episode: 2141   score: 6.0   memory length: 466755   epsilon: 0.6369115600078823    steps: 365     evaluation reward: 5.05\n",
            "episode: 2142   score: 4.0   memory length: 467001   epsilon: 0.6366680200078876    steps: 246     evaluation reward: 5.07\n",
            "episode: 2143   score: 2.0   memory length: 467205   epsilon: 0.636466060007892    steps: 204     evaluation reward: 5.05\n",
            "episode: 2144   score: 5.0   memory length: 467540   epsilon: 0.6361344100078992    steps: 335     evaluation reward: 5.07\n",
            "episode: 2145   score: 7.0   memory length: 467864   epsilon: 0.6358136500079061    steps: 324     evaluation reward: 5.04\n",
            "episode: 2146   score: 11.0   memory length: 468280   epsilon: 0.6354018100079151    steps: 416     evaluation reward: 5.01\n",
            "episode: 2147   score: 7.0   memory length: 468680   epsilon: 0.6350058100079237    steps: 400     evaluation reward: 5.05\n",
            "episode: 2148   score: 5.0   memory length: 469004   epsilon: 0.6346850500079306    steps: 324     evaluation reward: 5.06\n",
            "episode: 2149   score: 4.0   memory length: 469275   epsilon: 0.6344167600079365    steps: 271     evaluation reward: 5.05\n",
            "episode: 2150   score: 3.0   memory length: 469530   epsilon: 0.6341643100079419    steps: 255     evaluation reward: 4.98\n",
            "episode: 2151   score: 4.0   memory length: 469809   epsilon: 0.6338881000079479    steps: 279     evaluation reward: 4.97\n",
            "episode: 2152   score: 8.0   memory length: 470243   epsilon: 0.6334584400079573    steps: 434     evaluation reward: 4.99\n",
            "episode: 2153   score: 10.0   memory length: 470768   epsilon: 0.6329386900079685    steps: 525     evaluation reward: 5.07\n",
            "episode: 2154   score: 2.0   memory length: 470954   epsilon: 0.6327545500079725    steps: 186     evaluation reward: 5.02\n",
            "episode: 2155   score: 3.0   memory length: 471189   epsilon: 0.6325219000079776    steps: 235     evaluation reward: 5.02\n",
            "episode: 2156   score: 6.0   memory length: 471538   epsilon: 0.6321763900079851    steps: 349     evaluation reward: 5.05\n",
            "episode: 2157   score: 5.0   memory length: 471883   epsilon: 0.6318348400079925    steps: 345     evaluation reward: 5.04\n",
            "episode: 2158   score: 7.0   memory length: 472270   epsilon: 0.6314517100080008    steps: 387     evaluation reward: 5.09\n",
            "episode: 2159   score: 4.0   memory length: 472541   epsilon: 0.6311834200080066    steps: 271     evaluation reward: 5.11\n",
            "episode: 2160   score: 4.0   memory length: 472845   epsilon: 0.6308824600080132    steps: 304     evaluation reward: 5.11\n",
            "episode: 2161   score: 5.0   memory length: 473162   epsilon: 0.63056863000802    steps: 317     evaluation reward: 5.14\n",
            "episode: 2162   score: 1.0   memory length: 473320   epsilon: 0.6304122100080234    steps: 158     evaluation reward: 5.11\n",
            "episode: 2163   score: 4.0   memory length: 473582   epsilon: 0.630152830008029    steps: 262     evaluation reward: 5.12\n",
            "episode: 2164   score: 6.0   memory length: 473931   epsilon: 0.6298073200080365    steps: 349     evaluation reward: 5.14\n",
            "episode: 2165   score: 3.0   memory length: 474165   epsilon: 0.6295756600080415    steps: 234     evaluation reward: 5.14\n",
            "episode: 2166   score: 15.0   memory length: 474596   epsilon: 0.6291489700080508    steps: 431     evaluation reward: 5.25\n",
            "episode: 2167   score: 6.0   memory length: 474931   epsilon: 0.628817320008058    steps: 335     evaluation reward: 5.26\n",
            "episode: 2168   score: 8.0   memory length: 475374   epsilon: 0.6283787500080675    steps: 443     evaluation reward: 5.31\n",
            "episode: 2169   score: 6.0   memory length: 475704   epsilon: 0.6280520500080746    steps: 330     evaluation reward: 5.35\n",
            "episode: 2170   score: 6.0   memory length: 476084   epsilon: 0.6276758500080828    steps: 380     evaluation reward: 5.35\n",
            "episode: 2171   score: 3.0   memory length: 476331   epsilon: 0.6274313200080881    steps: 247     evaluation reward: 5.32\n",
            "episode: 2172   score: 6.0   memory length: 476672   epsilon: 0.6270937300080954    steps: 341     evaluation reward: 5.32\n",
            "episode: 2173   score: 4.0   memory length: 476955   epsilon: 0.6268135600081015    steps: 283     evaluation reward: 5.3\n",
            "episode: 2174   score: 3.0   memory length: 477193   epsilon: 0.6265779400081066    steps: 238     evaluation reward: 5.21\n",
            "episode: 2175   score: 8.0   memory length: 477585   epsilon: 0.626189860008115    steps: 392     evaluation reward: 5.18\n",
            "episode: 2176   score: 4.0   memory length: 477856   epsilon: 0.6259215700081209    steps: 271     evaluation reward: 5.16\n",
            "episode: 2177   score: 3.0   memory length: 478091   epsilon: 0.6256889200081259    steps: 235     evaluation reward: 5.11\n",
            "episode: 2178   score: 9.0   memory length: 478436   epsilon: 0.6253473700081333    steps: 345     evaluation reward: 5.18\n",
            "episode: 2179   score: 3.0   memory length: 478657   epsilon: 0.6251285800081381    steps: 221     evaluation reward: 5.17\n",
            "episode: 2180   score: 10.0   memory length: 479059   epsilon: 0.6247306000081467    steps: 402     evaluation reward: 5.24\n",
            "episode: 2181   score: 7.0   memory length: 479477   epsilon: 0.6243167800081557    steps: 418     evaluation reward: 5.25\n",
            "episode: 2182   score: 6.0   memory length: 479836   epsilon: 0.6239613700081634    steps: 359     evaluation reward: 5.26\n",
            "episode: 2183   score: 5.0   memory length: 480179   epsilon: 0.6236218000081708    steps: 343     evaluation reward: 5.27\n",
            "episode: 2184   score: 6.0   memory length: 480524   epsilon: 0.6232802500081782    steps: 345     evaluation reward: 5.22\n",
            "episode: 2185   score: 7.0   memory length: 480924   epsilon: 0.6228842500081868    steps: 400     evaluation reward: 5.23\n",
            "episode: 2186   score: 6.0   memory length: 481309   epsilon: 0.6225031000081951    steps: 385     evaluation reward: 5.23\n",
            "episode: 2187   score: 10.0   memory length: 481813   epsilon: 0.6220041400082059    steps: 504     evaluation reward: 5.26\n",
            "episode: 2188   score: 7.0   memory length: 482215   epsilon: 0.6216061600082146    steps: 402     evaluation reward: 5.32\n",
            "episode: 2189   score: 3.0   memory length: 482450   epsilon: 0.6213735100082196    steps: 235     evaluation reward: 5.33\n",
            "episode: 2190   score: 2.0   memory length: 482634   epsilon: 0.6211913500082236    steps: 184     evaluation reward: 5.31\n",
            "episode: 2191   score: 4.0   memory length: 482921   epsilon: 0.6209072200082297    steps: 287     evaluation reward: 5.29\n",
            "episode: 2192   score: 8.0   memory length: 483207   epsilon: 0.6206240800082359    steps: 286     evaluation reward: 5.31\n",
            "episode: 2193   score: 16.0   memory length: 483651   epsilon: 0.6201845200082454    steps: 444     evaluation reward: 5.43\n",
            "episode: 2194   score: 5.0   memory length: 483974   epsilon: 0.6198647500082524    steps: 323     evaluation reward: 5.44\n",
            "episode: 2195   score: 5.0   memory length: 484285   epsilon: 0.619556860008259    steps: 311     evaluation reward: 5.45\n",
            "episode: 2196   score: 3.0   memory length: 484506   epsilon: 0.6193380700082638    steps: 221     evaluation reward: 5.44\n",
            "episode: 2197   score: 7.0   memory length: 484892   epsilon: 0.6189559300082721    steps: 386     evaluation reward: 5.45\n",
            "episode: 2198   score: 7.0   memory length: 485364   epsilon: 0.6184886500082822    steps: 472     evaluation reward: 5.48\n",
            "episode: 2199   score: 6.0   memory length: 485708   epsilon: 0.6181480900082896    steps: 344     evaluation reward: 5.49\n",
            "episode: 2200   score: 3.0   memory length: 485939   epsilon: 0.6179194000082946    steps: 231     evaluation reward: 5.45\n",
            "episode: 2201   score: 3.0   memory length: 486188   epsilon: 0.6176728900083    steps: 249     evaluation reward: 5.43\n",
            "episode: 2202   score: 3.0   memory length: 486410   epsilon: 0.6174531100083047    steps: 222     evaluation reward: 5.44\n",
            "episode: 2203   score: 8.0   memory length: 486866   epsilon: 0.6170016700083145    steps: 456     evaluation reward: 5.43\n",
            "episode: 2204   score: 3.0   memory length: 487080   epsilon: 0.6167898100083191    steps: 214     evaluation reward: 5.4\n",
            "episode: 2205   score: 2.0   memory length: 487269   epsilon: 0.6166027000083232    steps: 189     evaluation reward: 5.39\n",
            "episode: 2206   score: 4.0   memory length: 487568   epsilon: 0.6163066900083296    steps: 299     evaluation reward: 5.38\n",
            "episode: 2207   score: 9.0   memory length: 488023   epsilon: 0.6158562400083394    steps: 455     evaluation reward: 5.38\n",
            "episode: 2208   score: 3.0   memory length: 488238   epsilon: 0.615643390008344    steps: 215     evaluation reward: 5.38\n",
            "episode: 2209   score: 7.0   memory length: 488640   epsilon: 0.6152454100083526    steps: 402     evaluation reward: 5.43\n",
            "episode: 2210   score: 3.0   memory length: 488885   epsilon: 0.6150028600083579    steps: 245     evaluation reward: 5.34\n",
            "episode: 2211   score: 4.0   memory length: 489184   epsilon: 0.6147068500083643    steps: 299     evaluation reward: 5.34\n",
            "episode: 2212   score: 6.0   memory length: 489526   epsilon: 0.6143682700083717    steps: 342     evaluation reward: 5.37\n",
            "episode: 2213   score: 4.0   memory length: 489783   epsilon: 0.6141138400083772    steps: 257     evaluation reward: 5.38\n",
            "episode: 2214   score: 6.0   memory length: 490149   epsilon: 0.6137515000083851    steps: 366     evaluation reward: 5.36\n",
            "episode: 2215   score: 7.0   memory length: 490561   epsilon: 0.6133436200083939    steps: 412     evaluation reward: 5.37\n",
            "episode: 2216   score: 7.0   memory length: 490935   epsilon: 0.612973360008402    steps: 374     evaluation reward: 5.36\n",
            "episode: 2217   score: 6.0   memory length: 491268   epsilon: 0.6126436900084091    steps: 333     evaluation reward: 5.39\n",
            "episode: 2218   score: 6.0   memory length: 491593   epsilon: 0.6123219400084161    steps: 325     evaluation reward: 5.37\n",
            "episode: 2219   score: 4.0   memory length: 491902   epsilon: 0.6120160300084228    steps: 309     evaluation reward: 5.34\n",
            "episode: 2220   score: 6.0   memory length: 492293   epsilon: 0.6116289400084312    steps: 391     evaluation reward: 5.31\n",
            "episode: 2221   score: 8.0   memory length: 492716   epsilon: 0.6112101700084402    steps: 423     evaluation reward: 5.33\n",
            "episode: 2222   score: 4.0   memory length: 493038   epsilon: 0.6108913900084472    steps: 322     evaluation reward: 5.29\n",
            "episode: 2223   score: 6.0   memory length: 493418   epsilon: 0.6105151900084553    steps: 380     evaluation reward: 5.31\n",
            "episode: 2224   score: 14.0   memory length: 493995   epsilon: 0.6099439600084677    steps: 577     evaluation reward: 5.43\n",
            "episode: 2225   score: 6.0   memory length: 494382   epsilon: 0.609560830008476    steps: 387     evaluation reward: 5.44\n",
            "episode: 2226   score: 8.0   memory length: 494679   epsilon: 0.6092668000084824    steps: 297     evaluation reward: 5.47\n",
            "episode: 2227   score: 6.0   memory length: 495004   epsilon: 0.6089450500084894    steps: 325     evaluation reward: 5.49\n",
            "episode: 2228   score: 3.0   memory length: 495238   epsilon: 0.6087133900084944    steps: 234     evaluation reward: 5.48\n",
            "episode: 2229   score: 9.0   memory length: 495704   epsilon: 0.6082520500085045    steps: 466     evaluation reward: 5.49\n",
            "episode: 2230   score: 8.0   memory length: 496027   epsilon: 0.6079322800085114    steps: 323     evaluation reward: 5.54\n",
            "episode: 2231   score: 4.0   memory length: 496290   epsilon: 0.6076719100085171    steps: 263     evaluation reward: 5.51\n",
            "episode: 2232   score: 3.0   memory length: 496507   epsilon: 0.6074570800085217    steps: 217     evaluation reward: 5.5\n",
            "episode: 2233   score: 7.0   memory length: 496883   epsilon: 0.6070848400085298    steps: 376     evaluation reward: 5.54\n",
            "episode: 2234   score: 3.0   memory length: 497096   epsilon: 0.6068739700085344    steps: 213     evaluation reward: 5.54\n",
            "episode: 2235   score: 4.0   memory length: 497357   epsilon: 0.60661558000854    steps: 261     evaluation reward: 5.56\n",
            "episode: 2236   score: 7.0   memory length: 497727   epsilon: 0.6062492800085479    steps: 370     evaluation reward: 5.58\n",
            "episode: 2237   score: 4.0   memory length: 497995   epsilon: 0.6059839600085537    steps: 268     evaluation reward: 5.6\n",
            "episode: 2238   score: 6.0   memory length: 498338   epsilon: 0.6056443900085611    steps: 343     evaluation reward: 5.62\n",
            "episode: 2239   score: 4.0   memory length: 498613   epsilon: 0.605372140008567    steps: 275     evaluation reward: 5.63\n",
            "episode: 2240   score: 4.0   memory length: 498880   epsilon: 0.6051078100085727    steps: 267     evaluation reward: 5.62\n",
            "episode: 2241   score: 10.0   memory length: 499386   epsilon: 0.6046068700085836    steps: 506     evaluation reward: 5.66\n",
            "episode: 2242   score: 5.0   memory length: 499719   epsilon: 0.6042772000085908    steps: 333     evaluation reward: 5.67\n",
            "episode: 2243   score: 2.0   memory length: 499908   epsilon: 0.6040900900085948    steps: 189     evaluation reward: 5.67\n",
            "now time :  2019-12-12 20:27:14.930762\n",
            "episode: 2244   score: 6.0   memory length: 500264   epsilon: 0.6037376500086025    steps: 356     evaluation reward: 5.68\n",
            "episode: 2245   score: 3.0   memory length: 500499   epsilon: 0.6035050000086075    steps: 235     evaluation reward: 5.64\n",
            "episode: 2246   score: 7.0   memory length: 500873   epsilon: 0.6031347400086156    steps: 374     evaluation reward: 5.6\n",
            "episode: 2247   score: 7.0   memory length: 501231   epsilon: 0.6027803200086232    steps: 358     evaluation reward: 5.6\n",
            "episode: 2248   score: 5.0   memory length: 501525   epsilon: 0.6024892600086296    steps: 294     evaluation reward: 5.6\n",
            "episode: 2249   score: 13.0   memory length: 501890   epsilon: 0.6021279100086374    steps: 365     evaluation reward: 5.69\n",
            "episode: 2250   score: 7.0   memory length: 502281   epsilon: 0.6017408200086458    steps: 391     evaluation reward: 5.73\n",
            "episode: 2251   score: 4.0   memory length: 502558   epsilon: 0.6014665900086518    steps: 277     evaluation reward: 5.73\n",
            "episode: 2252   score: 4.0   memory length: 502804   epsilon: 0.6012230500086571    steps: 246     evaluation reward: 5.69\n",
            "episode: 2253   score: 5.0   memory length: 503121   epsilon: 0.6009092200086639    steps: 317     evaluation reward: 5.64\n",
            "episode: 2254   score: 7.0   memory length: 503531   epsilon: 0.6005033200086727    steps: 410     evaluation reward: 5.69\n",
            "episode: 2255   score: 12.0   memory length: 504066   epsilon: 0.5999736700086842    steps: 535     evaluation reward: 5.78\n",
            "episode: 2256   score: 3.0   memory length: 504279   epsilon: 0.5997628000086888    steps: 213     evaluation reward: 5.75\n",
            "episode: 2257   score: 2.0   memory length: 504481   epsilon: 0.5995628200086931    steps: 202     evaluation reward: 5.72\n",
            "episode: 2258   score: 6.0   memory length: 504889   epsilon: 0.5991589000087019    steps: 408     evaluation reward: 5.71\n",
            "episode: 2259   score: 4.0   memory length: 505151   epsilon: 0.5988995200087075    steps: 262     evaluation reward: 5.71\n",
            "episode: 2260   score: 7.0   memory length: 505524   epsilon: 0.5985302500087155    steps: 373     evaluation reward: 5.74\n",
            "episode: 2261   score: 3.0   memory length: 505796   epsilon: 0.5982609700087214    steps: 272     evaluation reward: 5.72\n",
            "episode: 2262   score: 5.0   memory length: 506091   epsilon: 0.5979689200087277    steps: 295     evaluation reward: 5.76\n",
            "episode: 2263   score: 5.0   memory length: 506394   epsilon: 0.5976689500087342    steps: 303     evaluation reward: 5.77\n",
            "episode: 2264   score: 9.0   memory length: 506869   epsilon: 0.5971987000087444    steps: 475     evaluation reward: 5.8\n",
            "episode: 2265   score: 5.0   memory length: 507182   epsilon: 0.5968888300087511    steps: 313     evaluation reward: 5.82\n",
            "episode: 2266   score: 3.0   memory length: 507401   epsilon: 0.5966720200087559    steps: 219     evaluation reward: 5.7\n",
            "episode: 2267   score: 5.0   memory length: 507735   epsilon: 0.596341360008763    steps: 334     evaluation reward: 5.69\n",
            "episode: 2268   score: 4.0   memory length: 507991   epsilon: 0.5960879200087685    steps: 256     evaluation reward: 5.65\n",
            "episode: 2269   score: 6.0   memory length: 508327   epsilon: 0.5957552800087758    steps: 336     evaluation reward: 5.65\n",
            "episode: 2270   score: 4.0   memory length: 508591   epsilon: 0.5954939200087814    steps: 264     evaluation reward: 5.63\n",
            "episode: 2271   score: 9.0   memory length: 509036   epsilon: 0.595053370008791    steps: 445     evaluation reward: 5.69\n",
            "episode: 2272   score: 3.0   memory length: 509259   epsilon: 0.5948326000087958    steps: 223     evaluation reward: 5.66\n",
            "episode: 2273   score: 5.0   memory length: 509571   epsilon: 0.5945237200088025    steps: 312     evaluation reward: 5.67\n",
            "episode: 2274   score: 3.0   memory length: 509789   epsilon: 0.5943079000088072    steps: 218     evaluation reward: 5.67\n",
            "episode: 2275   score: 3.0   memory length: 510018   epsilon: 0.5940811900088121    steps: 229     evaluation reward: 5.62\n",
            "episode: 2276   score: 7.0   memory length: 510402   epsilon: 0.5937010300088204    steps: 384     evaluation reward: 5.65\n",
            "episode: 2277   score: 1.0   memory length: 510576   epsilon: 0.5935287700088241    steps: 174     evaluation reward: 5.63\n",
            "episode: 2278   score: 6.0   memory length: 510962   epsilon: 0.5931466300088324    steps: 386     evaluation reward: 5.6\n",
            "episode: 2279   score: 3.0   memory length: 511185   epsilon: 0.5929258600088372    steps: 223     evaluation reward: 5.6\n",
            "episode: 2280   score: 7.0   memory length: 511585   epsilon: 0.5925298600088458    steps: 400     evaluation reward: 5.57\n",
            "episode: 2281   score: 1.0   memory length: 511748   epsilon: 0.5923684900088493    steps: 163     evaluation reward: 5.51\n",
            "episode: 2282   score: 3.0   memory length: 511968   epsilon: 0.592150690008854    steps: 220     evaluation reward: 5.48\n",
            "episode: 2283   score: 8.0   memory length: 512261   epsilon: 0.5918606200088603    steps: 293     evaluation reward: 5.51\n",
            "episode: 2284   score: 5.0   memory length: 512591   epsilon: 0.5915339200088674    steps: 330     evaluation reward: 5.5\n",
            "episode: 2285   score: 6.0   memory length: 512955   epsilon: 0.5911735600088752    steps: 364     evaluation reward: 5.49\n",
            "episode: 2286   score: 6.0   memory length: 513290   epsilon: 0.5908419100088824    steps: 335     evaluation reward: 5.49\n",
            "episode: 2287   score: 5.0   memory length: 513608   epsilon: 0.5905270900088893    steps: 318     evaluation reward: 5.44\n",
            "episode: 2288   score: 6.0   memory length: 513975   epsilon: 0.5901637600088971    steps: 367     evaluation reward: 5.43\n",
            "episode: 2289   score: 3.0   memory length: 514199   epsilon: 0.589942000008902    steps: 224     evaluation reward: 5.43\n",
            "episode: 2290   score: 4.0   memory length: 514505   epsilon: 0.5896390600089085    steps: 306     evaluation reward: 5.45\n",
            "episode: 2291   score: 6.0   memory length: 514848   epsilon: 0.5892994900089159    steps: 343     evaluation reward: 5.47\n",
            "episode: 2292   score: 3.0   memory length: 515082   epsilon: 0.5890678300089209    steps: 234     evaluation reward: 5.42\n",
            "episode: 2293   score: 8.0   memory length: 515507   epsilon: 0.5886470800089301    steps: 425     evaluation reward: 5.34\n",
            "episode: 2294   score: 3.0   memory length: 515727   epsilon: 0.5884292800089348    steps: 220     evaluation reward: 5.32\n",
            "episode: 2295   score: 7.0   memory length: 516129   epsilon: 0.5880313000089434    steps: 402     evaluation reward: 5.34\n",
            "episode: 2296   score: 8.0   memory length: 516431   epsilon: 0.5877323200089499    steps: 302     evaluation reward: 5.39\n",
            "episode: 2297   score: 10.0   memory length: 516795   epsilon: 0.5873719600089577    steps: 364     evaluation reward: 5.42\n",
            "episode: 2298   score: 5.0   memory length: 517099   epsilon: 0.5870710000089643    steps: 304     evaluation reward: 5.4\n",
            "episode: 2299   score: 2.0   memory length: 517284   epsilon: 0.5868878500089683    steps: 185     evaluation reward: 5.36\n",
            "episode: 2300   score: 4.0   memory length: 517538   epsilon: 0.5866363900089737    steps: 254     evaluation reward: 5.37\n",
            "episode: 2301   score: 8.0   memory length: 517920   epsilon: 0.5862582100089819    steps: 382     evaluation reward: 5.42\n",
            "episode: 2302   score: 13.0   memory length: 518382   epsilon: 0.5858008300089919    steps: 462     evaluation reward: 5.52\n",
            "episode: 2303   score: 4.0   memory length: 518666   epsilon: 0.585519670008998    steps: 284     evaluation reward: 5.48\n",
            "episode: 2304   score: 10.0   memory length: 519015   epsilon: 0.5851741600090055    steps: 349     evaluation reward: 5.55\n",
            "episode: 2305   score: 6.0   memory length: 519360   epsilon: 0.5848326100090129    steps: 345     evaluation reward: 5.59\n",
            "episode: 2306   score: 4.0   memory length: 519646   epsilon: 0.584549470009019    steps: 286     evaluation reward: 5.59\n",
            "episode: 2307   score: 5.0   memory length: 519951   epsilon: 0.5842475200090256    steps: 305     evaluation reward: 5.55\n",
            "episode: 2308   score: 7.0   memory length: 520361   epsilon: 0.5838416200090344    steps: 410     evaluation reward: 5.59\n",
            "episode: 2309   score: 5.0   memory length: 520668   epsilon: 0.583537690009041    steps: 307     evaluation reward: 5.57\n",
            "episode: 2310   score: 6.0   memory length: 521005   epsilon: 0.5832040600090482    steps: 337     evaluation reward: 5.6\n",
            "episode: 2311   score: 3.0   memory length: 521242   epsilon: 0.5829694300090533    steps: 237     evaluation reward: 5.59\n",
            "episode: 2312   score: 8.0   memory length: 521718   epsilon: 0.5824981900090636    steps: 476     evaluation reward: 5.61\n",
            "episode: 2313   score: 9.0   memory length: 522207   epsilon: 0.5820140800090741    steps: 489     evaluation reward: 5.66\n",
            "episode: 2314   score: 4.0   memory length: 522484   epsilon: 0.58173985000908    steps: 277     evaluation reward: 5.64\n",
            "episode: 2315   score: 4.0   memory length: 522771   epsilon: 0.5814557200090862    steps: 287     evaluation reward: 5.61\n",
            "episode: 2316   score: 2.0   memory length: 522991   epsilon: 0.5812379200090909    steps: 220     evaluation reward: 5.56\n",
            "episode: 2317   score: 6.0   memory length: 523321   epsilon: 0.580911220009098    steps: 330     evaluation reward: 5.56\n",
            "episode: 2318   score: 4.0   memory length: 523621   epsilon: 0.5806142200091045    steps: 300     evaluation reward: 5.54\n",
            "episode: 2319   score: 5.0   memory length: 523921   epsilon: 0.5803172200091109    steps: 300     evaluation reward: 5.55\n",
            "episode: 2320   score: 6.0   memory length: 524286   epsilon: 0.5799558700091187    steps: 365     evaluation reward: 5.55\n",
            "episode: 2321   score: 0.0   memory length: 524414   epsilon: 0.5798291500091215    steps: 128     evaluation reward: 5.47\n",
            "episode: 2322   score: 2.0   memory length: 524612   epsilon: 0.5796331300091258    steps: 198     evaluation reward: 5.45\n",
            "episode: 2323   score: 4.0   memory length: 524884   epsilon: 0.5793638500091316    steps: 272     evaluation reward: 5.43\n",
            "episode: 2324   score: 5.0   memory length: 525181   epsilon: 0.579069820009138    steps: 297     evaluation reward: 5.34\n",
            "episode: 2325   score: 3.0   memory length: 525425   epsilon: 0.5788282600091432    steps: 244     evaluation reward: 5.31\n",
            "episode: 2326   score: 4.0   memory length: 525713   epsilon: 0.5785431400091494    steps: 288     evaluation reward: 5.27\n",
            "episode: 2327   score: 3.0   memory length: 525952   epsilon: 0.5783065300091546    steps: 239     evaluation reward: 5.24\n",
            "episode: 2328   score: 11.0   memory length: 526356   epsilon: 0.5779065700091632    steps: 404     evaluation reward: 5.32\n",
            "episode: 2329   score: 8.0   memory length: 526636   epsilon: 0.5776293700091693    steps: 280     evaluation reward: 5.31\n",
            "episode: 2330   score: 6.0   memory length: 526981   epsilon: 0.5772878200091767    steps: 345     evaluation reward: 5.29\n",
            "episode: 2331   score: 4.0   memory length: 527276   epsilon: 0.576995770009183    steps: 295     evaluation reward: 5.29\n",
            "episode: 2332   score: 2.0   memory length: 527470   epsilon: 0.5768037100091872    steps: 194     evaluation reward: 5.28\n",
            "episode: 2333   score: 9.0   memory length: 527827   epsilon: 0.5764502800091948    steps: 357     evaluation reward: 5.3\n",
            "episode: 2334   score: 4.0   memory length: 528104   epsilon: 0.5761760500092008    steps: 277     evaluation reward: 5.31\n",
            "episode: 2335   score: 2.0   memory length: 528295   epsilon: 0.5759869600092049    steps: 191     evaluation reward: 5.29\n",
            "episode: 2336   score: 4.0   memory length: 528588   epsilon: 0.5756968900092112    steps: 293     evaluation reward: 5.26\n",
            "episode: 2337   score: 7.0   memory length: 528993   epsilon: 0.5752959400092199    steps: 405     evaluation reward: 5.29\n",
            "episode: 2338   score: 6.0   memory length: 529334   epsilon: 0.5749583500092272    steps: 341     evaluation reward: 5.29\n",
            "episode: 2339   score: 7.0   memory length: 529729   epsilon: 0.5745673000092357    steps: 395     evaluation reward: 5.32\n",
            "episode: 2340   score: 5.0   memory length: 530027   epsilon: 0.5742722800092421    steps: 298     evaluation reward: 5.33\n",
            "episode: 2341   score: 3.0   memory length: 530243   epsilon: 0.5740584400092468    steps: 216     evaluation reward: 5.26\n",
            "episode: 2342   score: 5.0   memory length: 530573   epsilon: 0.5737317400092539    steps: 330     evaluation reward: 5.26\n",
            "episode: 2343   score: 7.0   memory length: 530933   epsilon: 0.5733753400092616    steps: 360     evaluation reward: 5.31\n",
            "episode: 2344   score: 5.0   memory length: 531250   epsilon: 0.5730615100092684    steps: 317     evaluation reward: 5.3\n",
            "episode: 2345   score: 1.0   memory length: 531401   epsilon: 0.5729120200092717    steps: 151     evaluation reward: 5.28\n",
            "episode: 2346   score: 8.0   memory length: 531699   epsilon: 0.5726170000092781    steps: 298     evaluation reward: 5.29\n",
            "episode: 2347   score: 13.0   memory length: 532245   epsilon: 0.5720764600092898    steps: 546     evaluation reward: 5.35\n",
            "episode: 2348   score: 4.0   memory length: 532504   epsilon: 0.5718200500092954    steps: 259     evaluation reward: 5.34\n",
            "episode: 2349   score: 8.0   memory length: 532823   epsilon: 0.5715042400093022    steps: 319     evaluation reward: 5.29\n",
            "episode: 2350   score: 4.0   memory length: 533093   epsilon: 0.571236940009308    steps: 270     evaluation reward: 5.26\n",
            "episode: 2351   score: 7.0   memory length: 533504   epsilon: 0.5708300500093169    steps: 411     evaluation reward: 5.29\n",
            "episode: 2352   score: 4.0   memory length: 533746   epsilon: 0.5705904700093221    steps: 242     evaluation reward: 5.29\n",
            "episode: 2353   score: 13.0   memory length: 534320   epsilon: 0.5700222100093344    steps: 574     evaluation reward: 5.37\n",
            "episode: 2354   score: 4.0   memory length: 534581   epsilon: 0.56976382000934    steps: 261     evaluation reward: 5.34\n",
            "episode: 2355   score: 6.0   memory length: 534935   epsilon: 0.5694133600093476    steps: 354     evaluation reward: 5.28\n",
            "episode: 2356   score: 5.0   memory length: 535238   epsilon: 0.5691133900093541    steps: 303     evaluation reward: 5.3\n",
            "episode: 2357   score: 6.0   memory length: 535583   epsilon: 0.5687718400093615    steps: 345     evaluation reward: 5.34\n",
            "episode: 2358   score: 10.0   memory length: 535974   epsilon: 0.5683847500093699    steps: 391     evaluation reward: 5.38\n",
            "episode: 2359   score: 5.0   memory length: 536302   epsilon: 0.568060030009377    steps: 328     evaluation reward: 5.39\n",
            "episode: 2360   score: 9.0   memory length: 536769   epsilon: 0.567597700009387    steps: 467     evaluation reward: 5.41\n",
            "episode: 2361   score: 7.0   memory length: 537180   epsilon: 0.5671908100093959    steps: 411     evaluation reward: 5.45\n",
            "episode: 2362   score: 9.0   memory length: 537667   epsilon: 0.5667086800094063    steps: 487     evaluation reward: 5.49\n",
            "episode: 2363   score: 11.0   memory length: 538072   epsilon: 0.566307730009415    steps: 405     evaluation reward: 5.55\n",
            "episode: 2364   score: 2.0   memory length: 538271   epsilon: 0.5661107200094193    steps: 199     evaluation reward: 5.48\n",
            "episode: 2365   score: 1.0   memory length: 538423   epsilon: 0.5659602400094226    steps: 152     evaluation reward: 5.44\n",
            "episode: 2366   score: 9.0   memory length: 538917   epsilon: 0.5654711800094332    steps: 494     evaluation reward: 5.5\n",
            "episode: 2367   score: 7.0   memory length: 539316   epsilon: 0.5650761700094418    steps: 399     evaluation reward: 5.52\n",
            "episode: 2368   score: 6.0   memory length: 539695   epsilon: 0.5647009600094499    steps: 379     evaluation reward: 5.54\n",
            "episode: 2369   score: 9.0   memory length: 540024   epsilon: 0.564375250009457    steps: 329     evaluation reward: 5.57\n",
            "episode: 2370   score: 8.0   memory length: 540423   epsilon: 0.5639802400094656    steps: 399     evaluation reward: 5.61\n",
            "episode: 2371   score: 2.0   memory length: 540608   epsilon: 0.5637970900094695    steps: 185     evaluation reward: 5.54\n",
            "episode: 2372   score: 12.0   memory length: 541172   epsilon: 0.5632387300094817    steps: 564     evaluation reward: 5.63\n",
            "episode: 2373   score: 6.0   memory length: 541516   epsilon: 0.562898170009489    steps: 344     evaluation reward: 5.64\n",
            "episode: 2374   score: 4.0   memory length: 541816   epsilon: 0.5626011700094955    steps: 300     evaluation reward: 5.65\n",
            "episode: 2375   score: 5.0   memory length: 542116   epsilon: 0.562304170009502    steps: 300     evaluation reward: 5.67\n",
            "episode: 2376   score: 3.0   memory length: 542348   epsilon: 0.5620744900095069    steps: 232     evaluation reward: 5.63\n",
            "episode: 2377   score: 5.0   memory length: 542668   epsilon: 0.5617576900095138    steps: 320     evaluation reward: 5.67\n",
            "episode: 2378   score: 7.0   memory length: 543015   epsilon: 0.5614141600095213    steps: 347     evaluation reward: 5.68\n",
            "episode: 2379   score: 8.0   memory length: 543433   epsilon: 0.5610003400095303    steps: 418     evaluation reward: 5.73\n",
            "episode: 2380   score: 4.0   memory length: 543698   epsilon: 0.560737990009536    steps: 265     evaluation reward: 5.7\n",
            "episode: 2381   score: 8.0   memory length: 544124   epsilon: 0.5603162500095451    steps: 426     evaluation reward: 5.77\n",
            "episode: 2382   score: 10.0   memory length: 544517   epsilon: 0.5599271800095535    steps: 393     evaluation reward: 5.84\n",
            "episode: 2383   score: 7.0   memory length: 544885   epsilon: 0.5595628600095615    steps: 368     evaluation reward: 5.83\n",
            "episode: 2384   score: 5.0   memory length: 545182   epsilon: 0.5592688300095678    steps: 297     evaluation reward: 5.83\n",
            "episode: 2385   score: 4.0   memory length: 545431   epsilon: 0.5590223200095732    steps: 249     evaluation reward: 5.81\n",
            "episode: 2386   score: 4.0   memory length: 545722   epsilon: 0.5587342300095794    steps: 291     evaluation reward: 5.79\n",
            "episode: 2387   score: 6.0   memory length: 546066   epsilon: 0.5583936700095868    steps: 344     evaluation reward: 5.8\n",
            "episode: 2388   score: 6.0   memory length: 546418   epsilon: 0.5580451900095944    steps: 352     evaluation reward: 5.8\n",
            "episode: 2389   score: 4.0   memory length: 546661   epsilon: 0.5578046200095996    steps: 243     evaluation reward: 5.81\n",
            "episode: 2390   score: 11.0   memory length: 547124   epsilon: 0.5573462500096096    steps: 463     evaluation reward: 5.88\n",
            "episode: 2391   score: 4.0   memory length: 547389   epsilon: 0.5570839000096153    steps: 265     evaluation reward: 5.86\n",
            "episode: 2392   score: 8.0   memory length: 547819   epsilon: 0.5566582000096245    steps: 430     evaluation reward: 5.91\n",
            "episode: 2393   score: 4.0   memory length: 548094   epsilon: 0.5563859500096304    steps: 275     evaluation reward: 5.87\n",
            "episode: 2394   score: 13.0   memory length: 548474   epsilon: 0.5560097500096386    steps: 380     evaluation reward: 5.97\n",
            "episode: 2395   score: 4.0   memory length: 548733   epsilon: 0.5557533400096442    steps: 259     evaluation reward: 5.94\n",
            "episode: 2396   score: 12.0   memory length: 549216   epsilon: 0.5552751700096545    steps: 483     evaluation reward: 5.98\n",
            "episode: 2397   score: 7.0   memory length: 549625   epsilon: 0.5548702600096633    steps: 409     evaluation reward: 5.95\n",
            "episode: 2398   score: 7.0   memory length: 549884   epsilon: 0.5546138500096689    steps: 259     evaluation reward: 5.97\n",
            "now time :  2019-12-12 20:50:56.941601\n",
            "episode: 2399   score: 6.0   memory length: 550192   epsilon: 0.5543089300096755    steps: 308     evaluation reward: 6.01\n",
            "episode: 2400   score: 7.0   memory length: 550450   epsilon: 0.5540535100096811    steps: 258     evaluation reward: 6.04\n",
            "episode: 2401   score: 10.0   memory length: 550970   epsilon: 0.5535387100096922    steps: 520     evaluation reward: 6.06\n",
            "episode: 2402   score: 6.0   memory length: 551319   epsilon: 0.5531932000096997    steps: 349     evaluation reward: 5.99\n",
            "episode: 2403   score: 16.0   memory length: 551809   epsilon: 0.5527081000097103    steps: 490     evaluation reward: 6.11\n",
            "episode: 2404   score: 6.0   memory length: 552145   epsilon: 0.5523754600097175    steps: 336     evaluation reward: 6.07\n",
            "episode: 2405   score: 8.0   memory length: 552626   epsilon: 0.5518992700097278    steps: 481     evaluation reward: 6.09\n",
            "episode: 2406   score: 6.0   memory length: 552989   epsilon: 0.5515399000097356    steps: 363     evaluation reward: 6.11\n",
            "episode: 2407   score: 3.0   memory length: 553207   epsilon: 0.5513240800097403    steps: 218     evaluation reward: 6.09\n",
            "episode: 2408   score: 9.0   memory length: 553574   epsilon: 0.5509607500097482    steps: 367     evaluation reward: 6.11\n",
            "episode: 2409   score: 6.0   memory length: 553946   epsilon: 0.5505924700097562    steps: 372     evaluation reward: 6.12\n",
            "episode: 2410   score: 3.0   memory length: 554211   epsilon: 0.5503301200097619    steps: 265     evaluation reward: 6.09\n",
            "episode: 2411   score: 8.0   memory length: 554629   epsilon: 0.5499163000097709    steps: 418     evaluation reward: 6.14\n",
            "episode: 2412   score: 7.0   memory length: 555012   epsilon: 0.5495371300097791    steps: 383     evaluation reward: 6.13\n",
            "episode: 2413   score: 6.0   memory length: 555367   epsilon: 0.5491856800097867    steps: 355     evaluation reward: 6.1\n",
            "episode: 2414   score: 5.0   memory length: 555711   epsilon: 0.5488451200097941    steps: 344     evaluation reward: 6.11\n",
            "episode: 2415   score: 5.0   memory length: 556018   epsilon: 0.5485411900098007    steps: 307     evaluation reward: 6.12\n",
            "episode: 2416   score: 4.0   memory length: 556286   epsilon: 0.5482758700098065    steps: 268     evaluation reward: 6.14\n",
            "episode: 2417   score: 8.0   memory length: 556700   epsilon: 0.5478660100098154    steps: 414     evaluation reward: 6.16\n",
            "episode: 2418   score: 10.0   memory length: 557164   epsilon: 0.5474066500098254    steps: 464     evaluation reward: 6.22\n",
            "episode: 2419   score: 6.0   memory length: 557522   epsilon: 0.547052230009833    steps: 358     evaluation reward: 6.23\n",
            "episode: 2420   score: 3.0   memory length: 557763   epsilon: 0.5468136400098382    steps: 241     evaluation reward: 6.2\n",
            "episode: 2421   score: 7.0   memory length: 558177   epsilon: 0.5464037800098471    steps: 414     evaluation reward: 6.27\n",
            "episode: 2422   score: 6.0   memory length: 558560   epsilon: 0.5460246100098554    steps: 383     evaluation reward: 6.31\n",
            "episode: 2423   score: 4.0   memory length: 558829   epsilon: 0.5457583000098611    steps: 269     evaluation reward: 6.31\n",
            "episode: 2424   score: 5.0   memory length: 559162   epsilon: 0.5454286300098683    steps: 333     evaluation reward: 6.31\n",
            "episode: 2425   score: 4.0   memory length: 559436   epsilon: 0.5451573700098742    steps: 274     evaluation reward: 6.32\n",
            "episode: 2426   score: 8.0   memory length: 559830   epsilon: 0.5447673100098827    steps: 394     evaluation reward: 6.36\n",
            "episode: 2427   score: 4.0   memory length: 560130   epsilon: 0.5444703100098891    steps: 300     evaluation reward: 6.37\n",
            "episode: 2428   score: 5.0   memory length: 560431   epsilon: 0.5441723200098956    steps: 301     evaluation reward: 6.31\n",
            "episode: 2429   score: 6.0   memory length: 560786   epsilon: 0.5438208700099032    steps: 355     evaluation reward: 6.29\n",
            "episode: 2430   score: 11.0   memory length: 561173   epsilon: 0.5434377400099115    steps: 387     evaluation reward: 6.34\n",
            "episode: 2431   score: 14.0   memory length: 561597   epsilon: 0.5430179800099206    steps: 424     evaluation reward: 6.44\n",
            "episode: 2432   score: 9.0   memory length: 561940   epsilon: 0.542678410009928    steps: 343     evaluation reward: 6.51\n",
            "episode: 2433   score: 5.0   memory length: 562253   epsilon: 0.5423685400099347    steps: 313     evaluation reward: 6.47\n",
            "episode: 2434   score: 8.0   memory length: 562671   epsilon: 0.5419547200099437    steps: 418     evaluation reward: 6.51\n",
            "episode: 2435   score: 10.0   memory length: 563030   epsilon: 0.5415993100099514    steps: 359     evaluation reward: 6.59\n",
            "episode: 2436   score: 6.0   memory length: 563404   epsilon: 0.5412290500099595    steps: 374     evaluation reward: 6.61\n",
            "episode: 2437   score: 6.0   memory length: 563785   epsilon: 0.5408518600099677    steps: 381     evaluation reward: 6.6\n",
            "episode: 2438   score: 3.0   memory length: 564033   epsilon: 0.540606340009973    steps: 248     evaluation reward: 6.57\n",
            "episode: 2439   score: 7.0   memory length: 564406   epsilon: 0.540237070009981    steps: 373     evaluation reward: 6.57\n",
            "episode: 2440   score: 3.0   memory length: 564640   epsilon: 0.540005410009986    steps: 234     evaluation reward: 6.55\n",
            "episode: 2441   score: 4.0   memory length: 564926   epsilon: 0.5397222700099922    steps: 286     evaluation reward: 6.56\n",
            "episode: 2442   score: 10.0   memory length: 565473   epsilon: 0.5391807400100039    steps: 547     evaluation reward: 6.61\n",
            "episode: 2443   score: 7.0   memory length: 565883   epsilon: 0.5387748400100127    steps: 410     evaluation reward: 6.61\n",
            "episode: 2444   score: 11.0   memory length: 566162   epsilon: 0.5384986300100187    steps: 279     evaluation reward: 6.67\n",
            "episode: 2445   score: 6.0   memory length: 566529   epsilon: 0.5381353000100266    steps: 367     evaluation reward: 6.72\n",
            "episode: 2446   score: 6.0   memory length: 566908   epsilon: 0.5377600900100348    steps: 379     evaluation reward: 6.7\n",
            "episode: 2447   score: 7.0   memory length: 567157   epsilon: 0.5375135800100401    steps: 249     evaluation reward: 6.64\n",
            "episode: 2448   score: 9.0   memory length: 567661   epsilon: 0.537014620010051    steps: 504     evaluation reward: 6.69\n",
            "episode: 2449   score: 7.0   memory length: 568048   epsilon: 0.5366314900100593    steps: 387     evaluation reward: 6.68\n",
            "episode: 2450   score: 8.0   memory length: 568473   epsilon: 0.5362107400100684    steps: 425     evaluation reward: 6.72\n",
            "episode: 2451   score: 8.0   memory length: 568855   epsilon: 0.5358325600100766    steps: 382     evaluation reward: 6.73\n",
            "episode: 2452   score: 7.0   memory length: 569241   epsilon: 0.5354504200100849    steps: 386     evaluation reward: 6.76\n",
            "episode: 2453   score: 3.0   memory length: 569475   epsilon: 0.53521876001009    steps: 234     evaluation reward: 6.66\n",
            "episode: 2454   score: 7.0   memory length: 569844   epsilon: 0.5348534500100979    steps: 369     evaluation reward: 6.69\n",
            "episode: 2455   score: 3.0   memory length: 570070   epsilon: 0.5346297100101027    steps: 226     evaluation reward: 6.66\n",
            "episode: 2456   score: 11.0   memory length: 570513   epsilon: 0.5341911400101123    steps: 443     evaluation reward: 6.72\n",
            "episode: 2457   score: 5.0   memory length: 570842   epsilon: 0.5338654300101193    steps: 329     evaluation reward: 6.71\n",
            "episode: 2458   score: 5.0   memory length: 571175   epsilon: 0.5335357600101265    steps: 333     evaluation reward: 6.66\n",
            "episode: 2459   score: 10.0   memory length: 571522   epsilon: 0.5331922300101339    steps: 347     evaluation reward: 6.71\n",
            "episode: 2460   score: 4.0   memory length: 571826   epsilon: 0.5328912700101405    steps: 304     evaluation reward: 6.66\n",
            "episode: 2461   score: 5.0   memory length: 572139   epsilon: 0.5325814000101472    steps: 313     evaluation reward: 6.64\n",
            "episode: 2462   score: 5.0   memory length: 572459   epsilon: 0.5322646000101541    steps: 320     evaluation reward: 6.6\n",
            "episode: 2463   score: 4.0   memory length: 572710   epsilon: 0.5320161100101595    steps: 251     evaluation reward: 6.53\n",
            "episode: 2464   score: 9.0   memory length: 573155   epsilon: 0.531575560010169    steps: 445     evaluation reward: 6.6\n",
            "episode: 2465   score: 13.0   memory length: 573672   epsilon: 0.5310637300101801    steps: 517     evaluation reward: 6.72\n",
            "episode: 2466   score: 8.0   memory length: 573970   epsilon: 0.5307687100101866    steps: 298     evaluation reward: 6.71\n",
            "episode: 2467   score: 5.0   memory length: 574283   epsilon: 0.5304588400101933    steps: 313     evaluation reward: 6.69\n",
            "episode: 2468   score: 9.0   memory length: 574774   epsilon: 0.5299727500102038    steps: 491     evaluation reward: 6.72\n",
            "episode: 2469   score: 6.0   memory length: 575116   epsilon: 0.5296341700102112    steps: 342     evaluation reward: 6.69\n",
            "episode: 2470   score: 5.0   memory length: 575412   epsilon: 0.5293411300102175    steps: 296     evaluation reward: 6.66\n",
            "episode: 2471   score: 2.0   memory length: 575613   epsilon: 0.5291421400102219    steps: 201     evaluation reward: 6.66\n",
            "episode: 2472   score: 9.0   memory length: 575957   epsilon: 0.5288015800102293    steps: 344     evaluation reward: 6.63\n",
            "episode: 2473   score: 5.0   memory length: 576301   epsilon: 0.5284610200102366    steps: 344     evaluation reward: 6.62\n",
            "episode: 2474   score: 6.0   memory length: 576686   epsilon: 0.5280798700102449    steps: 385     evaluation reward: 6.64\n",
            "episode: 2475   score: 7.0   memory length: 577094   epsilon: 0.5276759500102537    steps: 408     evaluation reward: 6.66\n",
            "episode: 2476   score: 10.0   memory length: 577467   epsilon: 0.5273066800102617    steps: 373     evaluation reward: 6.73\n",
            "episode: 2477   score: 9.0   memory length: 577916   epsilon: 0.5268621700102714    steps: 449     evaluation reward: 6.77\n",
            "episode: 2478   score: 5.0   memory length: 578219   epsilon: 0.5265622000102779    steps: 303     evaluation reward: 6.75\n",
            "episode: 2479   score: 5.0   memory length: 578531   epsilon: 0.5262533200102846    steps: 312     evaluation reward: 6.72\n",
            "episode: 2480   score: 5.0   memory length: 578837   epsilon: 0.5259503800102912    steps: 306     evaluation reward: 6.73\n",
            "episode: 2481   score: 9.0   memory length: 579168   epsilon: 0.5256226900102983    steps: 331     evaluation reward: 6.74\n",
            "episode: 2482   score: 6.0   memory length: 579526   epsilon: 0.525268270010306    steps: 358     evaluation reward: 6.7\n",
            "episode: 2483   score: 7.0   memory length: 579916   epsilon: 0.5248821700103143    steps: 390     evaluation reward: 6.7\n",
            "episode: 2484   score: 2.0   memory length: 580133   epsilon: 0.524667340010319    steps: 217     evaluation reward: 6.67\n",
            "episode: 2485   score: 5.0   memory length: 580493   epsilon: 0.5243109400103267    steps: 360     evaluation reward: 6.68\n",
            "episode: 2486   score: 8.0   memory length: 580914   epsilon: 0.5238941500103358    steps: 421     evaluation reward: 6.72\n",
            "episode: 2487   score: 9.0   memory length: 581409   epsilon: 0.5234041000103464    steps: 495     evaluation reward: 6.75\n",
            "episode: 2488   score: 4.0   memory length: 581669   epsilon: 0.523146700010352    steps: 260     evaluation reward: 6.73\n",
            "episode: 2489   score: 6.0   memory length: 582046   epsilon: 0.5227734700103601    steps: 377     evaluation reward: 6.75\n",
            "episode: 2490   score: 3.0   memory length: 582286   epsilon: 0.5225358700103653    steps: 240     evaluation reward: 6.67\n",
            "episode: 2491   score: 5.0   memory length: 582621   epsilon: 0.5222042200103725    steps: 335     evaluation reward: 6.68\n",
            "episode: 2492   score: 4.0   memory length: 582875   epsilon: 0.5219527600103779    steps: 254     evaluation reward: 6.64\n",
            "episode: 2493   score: 5.0   memory length: 583182   epsilon: 0.5216488300103845    steps: 307     evaluation reward: 6.65\n",
            "episode: 2494   score: 6.0   memory length: 583566   epsilon: 0.5212686700103928    steps: 384     evaluation reward: 6.58\n",
            "episode: 2495   score: 11.0   memory length: 584064   epsilon: 0.5207756500104035    steps: 498     evaluation reward: 6.65\n",
            "episode: 2496   score: 5.0   memory length: 584364   epsilon: 0.5204786500104099    steps: 300     evaluation reward: 6.58\n",
            "episode: 2497   score: 6.0   memory length: 584746   epsilon: 0.5201004700104181    steps: 382     evaluation reward: 6.57\n",
            "episode: 2498   score: 3.0   memory length: 584959   epsilon: 0.5198896000104227    steps: 213     evaluation reward: 6.53\n",
            "episode: 2499   score: 5.0   memory length: 585272   epsilon: 0.5195797300104295    steps: 313     evaluation reward: 6.52\n",
            "episode: 2500   score: 4.0   memory length: 585545   epsilon: 0.5193094600104353    steps: 273     evaluation reward: 6.49\n",
            "episode: 2501   score: 4.0   memory length: 585828   epsilon: 0.5190292900104414    steps: 283     evaluation reward: 6.43\n",
            "episode: 2502   score: 6.0   memory length: 586196   epsilon: 0.5186649700104493    steps: 368     evaluation reward: 6.43\n",
            "episode: 2503   score: 3.0   memory length: 586435   epsilon: 0.5184283600104544    steps: 239     evaluation reward: 6.3\n",
            "episode: 2504   score: 5.0   memory length: 586761   epsilon: 0.5181056200104615    steps: 326     evaluation reward: 6.29\n",
            "episode: 2505   score: 4.0   memory length: 587078   epsilon: 0.5177917900104683    steps: 317     evaluation reward: 6.25\n",
            "episode: 2506   score: 5.0   memory length: 587383   epsilon: 0.5174898400104748    steps: 305     evaluation reward: 6.24\n",
            "episode: 2507   score: 11.0   memory length: 587780   epsilon: 0.5170968100104834    steps: 397     evaluation reward: 6.32\n",
            "episode: 2508   score: 10.0   memory length: 588178   epsilon: 0.5167027900104919    steps: 398     evaluation reward: 6.33\n",
            "episode: 2509   score: 2.0   memory length: 588360   epsilon: 0.5165226100104958    steps: 182     evaluation reward: 6.29\n",
            "episode: 2510   score: 6.0   memory length: 588721   epsilon: 0.5161652200105036    steps: 361     evaluation reward: 6.32\n",
            "episode: 2511   score: 5.0   memory length: 589022   epsilon: 0.51586723001051    steps: 301     evaluation reward: 6.29\n",
            "episode: 2512   score: 8.0   memory length: 589321   epsilon: 0.5155712200105165    steps: 299     evaluation reward: 6.3\n",
            "episode: 2513   score: 7.0   memory length: 589702   epsilon: 0.5151940300105247    steps: 381     evaluation reward: 6.31\n",
            "episode: 2514   score: 8.0   memory length: 590109   epsilon: 0.5147911000105334    steps: 407     evaluation reward: 6.34\n",
            "episode: 2515   score: 4.0   memory length: 590359   epsilon: 0.5145436000105388    steps: 250     evaluation reward: 6.33\n",
            "episode: 2516   score: 5.0   memory length: 590658   epsilon: 0.5142475900105452    steps: 299     evaluation reward: 6.34\n",
            "episode: 2517   score: 5.0   memory length: 590954   epsilon: 0.5139545500105516    steps: 296     evaluation reward: 6.31\n",
            "episode: 2518   score: 15.0   memory length: 591426   epsilon: 0.5134872700105617    steps: 472     evaluation reward: 6.36\n",
            "episode: 2519   score: 10.0   memory length: 591819   epsilon: 0.5130982000105702    steps: 393     evaluation reward: 6.4\n",
            "episode: 2520   score: 12.0   memory length: 592395   epsilon: 0.5125279600105825    steps: 576     evaluation reward: 6.49\n",
            "episode: 2521   score: 12.0   memory length: 592830   epsilon: 0.5120973100105919    steps: 435     evaluation reward: 6.54\n",
            "episode: 2522   score: 4.0   memory length: 593074   epsilon: 0.5118557500105971    steps: 244     evaluation reward: 6.52\n",
            "episode: 2523   score: 3.0   memory length: 593291   epsilon: 0.5116409200106018    steps: 217     evaluation reward: 6.51\n",
            "episode: 2524   score: 6.0   memory length: 593686   epsilon: 0.5112498700106103    steps: 395     evaluation reward: 6.52\n",
            "episode: 2525   score: 7.0   memory length: 594061   epsilon: 0.5108786200106183    steps: 375     evaluation reward: 6.55\n",
            "episode: 2526   score: 11.0   memory length: 594639   epsilon: 0.5103064000106308    steps: 578     evaluation reward: 6.58\n",
            "episode: 2527   score: 7.0   memory length: 594884   epsilon: 0.510063850010636    steps: 245     evaluation reward: 6.61\n",
            "episode: 2528   score: 3.0   memory length: 595108   epsilon: 0.5098420900106408    steps: 224     evaluation reward: 6.59\n",
            "episode: 2529   score: 3.0   memory length: 595356   epsilon: 0.5095965700106462    steps: 248     evaluation reward: 6.56\n",
            "episode: 2530   score: 10.0   memory length: 595773   epsilon: 0.5091837400106551    steps: 417     evaluation reward: 6.55\n",
            "episode: 2531   score: 4.0   memory length: 596041   epsilon: 0.5089184200106609    steps: 268     evaluation reward: 6.45\n",
            "episode: 2532   score: 6.0   memory length: 596363   epsilon: 0.5085996400106678    steps: 322     evaluation reward: 6.42\n",
            "episode: 2533   score: 12.0   memory length: 596775   epsilon: 0.5081917600106767    steps: 412     evaluation reward: 6.49\n",
            "episode: 2534   score: 8.0   memory length: 597204   epsilon: 0.5077670500106859    steps: 429     evaluation reward: 6.49\n",
            "episode: 2535   score: 2.0   memory length: 597397   epsilon: 0.50757598001069    steps: 193     evaluation reward: 6.41\n",
            "episode: 2536   score: 6.0   memory length: 597756   epsilon: 0.5072205700106978    steps: 359     evaluation reward: 6.41\n",
            "episode: 2537   score: 4.0   memory length: 598012   epsilon: 0.5069671300107033    steps: 256     evaluation reward: 6.39\n",
            "episode: 2538   score: 7.0   memory length: 598385   epsilon: 0.5065978600107113    steps: 373     evaluation reward: 6.43\n",
            "episode: 2539   score: 5.0   memory length: 598695   epsilon: 0.5062909600107179    steps: 310     evaluation reward: 6.41\n",
            "episode: 2540   score: 7.0   memory length: 598958   epsilon: 0.5060305900107236    steps: 263     evaluation reward: 6.45\n",
            "episode: 2541   score: 5.0   memory length: 599263   epsilon: 0.5057286400107301    steps: 305     evaluation reward: 6.46\n",
            "episode: 2542   score: 8.0   memory length: 599730   epsilon: 0.5052663100107402    steps: 467     evaluation reward: 6.44\n",
            "episode: 2543   score: 3.0   memory length: 599965   epsilon: 0.5050336600107452    steps: 235     evaluation reward: 6.4\n",
            "now time :  2019-12-12 21:15:07.015738\n",
            "episode: 2544   score: 7.0   memory length: 600226   epsilon: 0.5047752700107508    steps: 261     evaluation reward: 6.36\n",
            "episode: 2545   score: 7.0   memory length: 600628   epsilon: 0.5043772900107595    steps: 402     evaluation reward: 6.37\n",
            "episode: 2546   score: 5.0   memory length: 600923   epsilon: 0.5040852400107658    steps: 295     evaluation reward: 6.36\n",
            "episode: 2547   score: 9.0   memory length: 601276   epsilon: 0.5037357700107734    steps: 353     evaluation reward: 6.38\n",
            "episode: 2548   score: 5.0   memory length: 601579   epsilon: 0.5034358000107799    steps: 303     evaluation reward: 6.34\n",
            "episode: 2549   score: 9.0   memory length: 601913   epsilon: 0.5031051400107871    steps: 334     evaluation reward: 6.36\n",
            "episode: 2550   score: 5.0   memory length: 602256   epsilon: 0.5027655700107945    steps: 343     evaluation reward: 6.33\n",
            "episode: 2551   score: 5.0   memory length: 602556   epsilon: 0.5024685700108009    steps: 300     evaluation reward: 6.3\n",
            "episode: 2552   score: 5.0   memory length: 602851   epsilon: 0.5021765200108073    steps: 295     evaluation reward: 6.28\n",
            "episode: 2553   score: 5.0   memory length: 603140   epsilon: 0.5018904100108135    steps: 289     evaluation reward: 6.3\n",
            "episode: 2554   score: 9.0   memory length: 603596   epsilon: 0.5014389700108233    steps: 456     evaluation reward: 6.32\n",
            "episode: 2555   score: 7.0   memory length: 603993   epsilon: 0.5010459400108318    steps: 397     evaluation reward: 6.36\n",
            "episode: 2556   score: 14.0   memory length: 604367   epsilon: 0.5006756800108398    steps: 374     evaluation reward: 6.39\n",
            "episode: 2557   score: 5.0   memory length: 604693   epsilon: 0.5003529400108468    steps: 326     evaluation reward: 6.39\n",
            "episode: 2558   score: 7.0   memory length: 605092   epsilon: 0.4999579300108554    steps: 399     evaluation reward: 6.41\n",
            "episode: 2559   score: 9.0   memory length: 605430   epsilon: 0.4996233100108627    steps: 338     evaluation reward: 6.4\n",
            "episode: 2560   score: 6.0   memory length: 605798   epsilon: 0.4992589900108706    steps: 368     evaluation reward: 6.42\n",
            "episode: 2561   score: 5.0   memory length: 606127   epsilon: 0.49893328001087767    steps: 329     evaluation reward: 6.42\n",
            "episode: 2562   score: 6.0   memory length: 606476   epsilon: 0.49858777001088517    steps: 349     evaluation reward: 6.43\n",
            "episode: 2563   score: 4.0   memory length: 606765   epsilon: 0.4983016600108914    steps: 289     evaluation reward: 6.43\n",
            "episode: 2564   score: 12.0   memory length: 607230   epsilon: 0.4978413100109014    steps: 465     evaluation reward: 6.46\n",
            "episode: 2565   score: 10.0   memory length: 607590   epsilon: 0.4974849100109091    steps: 360     evaluation reward: 6.43\n",
            "episode: 2566   score: 7.0   memory length: 607988   epsilon: 0.49709089001091766    steps: 398     evaluation reward: 6.42\n",
            "episode: 2567   score: 13.0   memory length: 608481   epsilon: 0.49660282001092826    steps: 493     evaluation reward: 6.5\n",
            "episode: 2568   score: 7.0   memory length: 608914   epsilon: 0.49617415001093756    steps: 433     evaluation reward: 6.48\n",
            "episode: 2569   score: 8.0   memory length: 609324   epsilon: 0.4957682500109464    steps: 410     evaluation reward: 6.5\n",
            "episode: 2570   score: 15.0   memory length: 609773   epsilon: 0.495323740010956    steps: 449     evaluation reward: 6.6\n",
            "episode: 2571   score: 4.0   memory length: 610034   epsilon: 0.49506535001096164    steps: 261     evaluation reward: 6.62\n",
            "episode: 2572   score: 5.0   memory length: 610380   epsilon: 0.49472281001096907    steps: 346     evaluation reward: 6.58\n",
            "episode: 2573   score: 5.0   memory length: 610666   epsilon: 0.4944396700109752    steps: 286     evaluation reward: 6.58\n",
            "episode: 2574   score: 4.0   memory length: 610919   epsilon: 0.49418920001098066    steps: 253     evaluation reward: 6.56\n",
            "episode: 2575   score: 11.0   memory length: 611507   epsilon: 0.4936070800109933    steps: 588     evaluation reward: 6.6\n",
            "episode: 2576   score: 11.0   memory length: 611913   epsilon: 0.493205140011002    steps: 406     evaluation reward: 6.61\n",
            "episode: 2577   score: 4.0   memory length: 612172   epsilon: 0.4929487300110076    steps: 259     evaluation reward: 6.56\n",
            "episode: 2578   score: 13.0   memory length: 612529   epsilon: 0.49259530001101526    steps: 357     evaluation reward: 6.64\n",
            "episode: 2579   score: 9.0   memory length: 612996   epsilon: 0.4921329700110253    steps: 467     evaluation reward: 6.68\n",
            "episode: 2580   score: 15.0   memory length: 613424   epsilon: 0.4917092500110345    steps: 428     evaluation reward: 6.78\n",
            "episode: 2581   score: 7.0   memory length: 613798   epsilon: 0.49133899001104253    steps: 374     evaluation reward: 6.76\n",
            "episode: 2582   score: 10.0   memory length: 614183   epsilon: 0.4909578400110508    steps: 385     evaluation reward: 6.8\n",
            "episode: 2583   score: 4.0   memory length: 614469   epsilon: 0.49067470001105695    steps: 286     evaluation reward: 6.77\n",
            "episode: 2584   score: 9.0   memory length: 614809   epsilon: 0.49033810001106426    steps: 340     evaluation reward: 6.84\n",
            "episode: 2585   score: 9.0   memory length: 615149   epsilon: 0.49000150001107157    steps: 340     evaluation reward: 6.88\n",
            "episode: 2586   score: 7.0   memory length: 615532   epsilon: 0.4896223300110798    steps: 383     evaluation reward: 6.87\n",
            "episode: 2587   score: 8.0   memory length: 615933   epsilon: 0.4892253400110884    steps: 401     evaluation reward: 6.86\n",
            "episode: 2588   score: 8.0   memory length: 616360   epsilon: 0.4888026100110976    steps: 427     evaluation reward: 6.9\n",
            "episode: 2589   score: 8.0   memory length: 616687   epsilon: 0.4884788800111046    steps: 327     evaluation reward: 6.92\n",
            "episode: 2590   score: 4.0   memory length: 616938   epsilon: 0.48823039001111    steps: 251     evaluation reward: 6.93\n",
            "episode: 2591   score: 2.0   memory length: 617167   epsilon: 0.48800368001111494    steps: 229     evaluation reward: 6.9\n",
            "episode: 2592   score: 2.0   memory length: 617352   epsilon: 0.4878205300111189    steps: 185     evaluation reward: 6.88\n",
            "episode: 2593   score: 3.0   memory length: 617581   epsilon: 0.48759382001112384    steps: 229     evaluation reward: 6.86\n",
            "episode: 2594   score: 11.0   memory length: 618048   epsilon: 0.48713149001113387    steps: 467     evaluation reward: 6.91\n",
            "episode: 2595   score: 7.0   memory length: 618424   epsilon: 0.48675925001114195    steps: 376     evaluation reward: 6.87\n",
            "episode: 2596   score: 9.0   memory length: 618913   epsilon: 0.48627514001115246    steps: 489     evaluation reward: 6.91\n",
            "episode: 2597   score: 5.0   memory length: 619244   epsilon: 0.4859474500111596    steps: 331     evaluation reward: 6.9\n",
            "episode: 2598   score: 8.0   memory length: 619658   epsilon: 0.4855375900111685    steps: 414     evaluation reward: 6.95\n",
            "episode: 2599   score: 5.0   memory length: 619969   epsilon: 0.48522970001117516    steps: 311     evaluation reward: 6.95\n",
            "episode: 2600   score: 7.0   memory length: 620346   epsilon: 0.48485647001118326    steps: 377     evaluation reward: 6.98\n",
            "episode: 2601   score: 9.0   memory length: 620689   epsilon: 0.48451690001119063    steps: 343     evaluation reward: 7.03\n",
            "episode: 2602   score: 4.0   memory length: 620954   epsilon: 0.4842545500111963    steps: 265     evaluation reward: 7.01\n",
            "episode: 2603   score: 4.0   memory length: 621210   epsilon: 0.48400111001120183    steps: 256     evaluation reward: 7.02\n",
            "episode: 2604   score: 4.0   memory length: 621475   epsilon: 0.4837387600112075    steps: 265     evaluation reward: 7.01\n",
            "episode: 2605   score: 8.0   memory length: 621760   epsilon: 0.48345661001121365    steps: 285     evaluation reward: 7.05\n",
            "episode: 2606   score: 8.0   memory length: 622166   epsilon: 0.4830546700112224    steps: 406     evaluation reward: 7.08\n",
            "episode: 2607   score: 6.0   memory length: 622493   epsilon: 0.4827309400112294    steps: 327     evaluation reward: 7.03\n",
            "episode: 2608   score: 7.0   memory length: 622890   epsilon: 0.48233791001123794    steps: 397     evaluation reward: 7.0\n",
            "episode: 2609   score: 9.0   memory length: 623361   epsilon: 0.48187162001124806    steps: 471     evaluation reward: 7.07\n",
            "episode: 2610   score: 7.0   memory length: 623736   epsilon: 0.4815003700112561    steps: 375     evaluation reward: 7.08\n",
            "episode: 2611   score: 12.0   memory length: 624204   epsilon: 0.4810370500112662    steps: 468     evaluation reward: 7.15\n",
            "episode: 2612   score: 7.0   memory length: 624630   epsilon: 0.48061531001127533    steps: 426     evaluation reward: 7.14\n",
            "episode: 2613   score: 10.0   memory length: 625006   epsilon: 0.4802430700112834    steps: 376     evaluation reward: 7.17\n",
            "episode: 2614   score: 5.0   memory length: 625302   epsilon: 0.4799500300112898    steps: 296     evaluation reward: 7.14\n",
            "episode: 2615   score: 2.0   memory length: 625496   epsilon: 0.47975797001129394    steps: 194     evaluation reward: 7.12\n",
            "episode: 2616   score: 7.0   memory length: 625904   epsilon: 0.4793540500113027    steps: 408     evaluation reward: 7.14\n",
            "episode: 2617   score: 6.0   memory length: 626243   epsilon: 0.47901844001131    steps: 339     evaluation reward: 7.15\n",
            "episode: 2618   score: 12.0   memory length: 626693   epsilon: 0.47857294001131967    steps: 450     evaluation reward: 7.12\n",
            "episode: 2619   score: 13.0   memory length: 627266   epsilon: 0.478005670011332    steps: 573     evaluation reward: 7.15\n",
            "episode: 2620   score: 16.0   memory length: 627732   epsilon: 0.477544330011342    steps: 466     evaluation reward: 7.19\n",
            "episode: 2621   score: 7.0   memory length: 628112   epsilon: 0.47716813001135017    steps: 380     evaluation reward: 7.14\n",
            "episode: 2622   score: 7.0   memory length: 628461   epsilon: 0.47682262001135767    steps: 349     evaluation reward: 7.17\n",
            "episode: 2623   score: 8.0   memory length: 628904   epsilon: 0.4763840500113672    steps: 443     evaluation reward: 7.22\n",
            "episode: 2624   score: 9.0   memory length: 629236   epsilon: 0.4760553700113743    steps: 332     evaluation reward: 7.25\n",
            "episode: 2625   score: 7.0   memory length: 629660   epsilon: 0.47563561001138344    steps: 424     evaluation reward: 7.25\n",
            "episode: 2626   score: 11.0   memory length: 630211   epsilon: 0.4750901200113953    steps: 551     evaluation reward: 7.25\n",
            "episode: 2627   score: 10.0   memory length: 630588   epsilon: 0.4747168900114034    steps: 377     evaluation reward: 7.28\n",
            "episode: 2628   score: 10.0   memory length: 631161   epsilon: 0.4741496200114157    steps: 573     evaluation reward: 7.35\n",
            "episode: 2629   score: 4.0   memory length: 631442   epsilon: 0.47387143001142173    steps: 281     evaluation reward: 7.36\n",
            "episode: 2630   score: 4.0   memory length: 631713   epsilon: 0.47360314001142756    steps: 271     evaluation reward: 7.3\n",
            "episode: 2631   score: 9.0   memory length: 632062   epsilon: 0.47325763001143506    steps: 349     evaluation reward: 7.35\n",
            "episode: 2632   score: 7.0   memory length: 632459   epsilon: 0.4728646000114436    steps: 397     evaluation reward: 7.36\n",
            "episode: 2633   score: 9.0   memory length: 632825   epsilon: 0.47250226001145146    steps: 366     evaluation reward: 7.33\n",
            "episode: 2634   score: 14.0   memory length: 633239   epsilon: 0.47209240001146036    steps: 414     evaluation reward: 7.39\n",
            "episode: 2635   score: 9.0   memory length: 633554   epsilon: 0.4717805500114671    steps: 315     evaluation reward: 7.46\n",
            "episode: 2636   score: 8.0   memory length: 633961   epsilon: 0.4713776200114759    steps: 407     evaluation reward: 7.48\n",
            "episode: 2637   score: 11.0   memory length: 634387   epsilon: 0.47095588001148503    steps: 426     evaluation reward: 7.55\n",
            "episode: 2638   score: 5.0   memory length: 634688   epsilon: 0.4706578900114915    steps: 301     evaluation reward: 7.53\n",
            "episode: 2639   score: 15.0   memory length: 635208   epsilon: 0.4701430900115027    steps: 520     evaluation reward: 7.63\n",
            "episode: 2640   score: 6.0   memory length: 635544   epsilon: 0.4698104500115099    steps: 336     evaluation reward: 7.62\n",
            "episode: 2641   score: 6.0   memory length: 635895   epsilon: 0.46946296001151744    steps: 351     evaluation reward: 7.63\n",
            "episode: 2642   score: 11.0   memory length: 636434   epsilon: 0.468929350011529    steps: 539     evaluation reward: 7.66\n",
            "episode: 2643   score: 7.0   memory length: 636843   epsilon: 0.4685244400115378    steps: 409     evaluation reward: 7.7\n",
            "episode: 2644   score: 4.0   memory length: 637124   epsilon: 0.46824625001154385    steps: 281     evaluation reward: 7.67\n",
            "episode: 2645   score: 6.0   memory length: 637468   epsilon: 0.46790569001155125    steps: 344     evaluation reward: 7.66\n",
            "episode: 2646   score: 6.0   memory length: 637815   epsilon: 0.4675621600115587    steps: 347     evaluation reward: 7.67\n",
            "episode: 2647   score: 8.0   memory length: 638260   epsilon: 0.46712161001156827    steps: 445     evaluation reward: 7.66\n",
            "episode: 2648   score: 7.0   memory length: 638614   epsilon: 0.4667711500115759    steps: 354     evaluation reward: 7.68\n",
            "episode: 2649   score: 9.0   memory length: 639062   epsilon: 0.4663276300115855    steps: 448     evaluation reward: 7.68\n",
            "episode: 2650   score: 8.0   memory length: 639361   epsilon: 0.46603162001159193    steps: 299     evaluation reward: 7.71\n",
            "episode: 2651   score: 10.0   memory length: 639709   epsilon: 0.4656871000115994    steps: 348     evaluation reward: 7.76\n",
            "episode: 2652   score: 10.0   memory length: 640226   epsilon: 0.4651752700116105    steps: 517     evaluation reward: 7.81\n",
            "episode: 2653   score: 9.0   memory length: 640748   epsilon: 0.46465849001162174    steps: 522     evaluation reward: 7.85\n",
            "episode: 2654   score: 6.0   memory length: 641101   epsilon: 0.4643090200116293    steps: 353     evaluation reward: 7.82\n",
            "episode: 2655   score: 4.0   memory length: 641345   epsilon: 0.46406746001163457    steps: 244     evaluation reward: 7.79\n",
            "episode: 2656   score: 6.0   memory length: 641720   epsilon: 0.46369621001164263    steps: 375     evaluation reward: 7.71\n",
            "episode: 2657   score: 6.0   memory length: 642045   epsilon: 0.4633744600116496    steps: 325     evaluation reward: 7.72\n",
            "episode: 2658   score: 6.0   memory length: 642389   epsilon: 0.463033900011657    steps: 344     evaluation reward: 7.71\n",
            "episode: 2659   score: 4.0   memory length: 642671   epsilon: 0.46275472001166307    steps: 282     evaluation reward: 7.66\n",
            "episode: 2660   score: 8.0   memory length: 643143   epsilon: 0.4622874400116732    steps: 472     evaluation reward: 7.68\n",
            "episode: 2661   score: 7.0   memory length: 643494   epsilon: 0.46193995001168076    steps: 351     evaluation reward: 7.7\n",
            "episode: 2662   score: 4.0   memory length: 643761   epsilon: 0.4616756200116865    steps: 267     evaluation reward: 7.68\n",
            "episode: 2663   score: 5.0   memory length: 644076   epsilon: 0.46136377001169326    steps: 315     evaluation reward: 7.69\n",
            "episode: 2664   score: 5.0   memory length: 644382   epsilon: 0.46106083001169984    steps: 306     evaluation reward: 7.62\n",
            "episode: 2665   score: 5.0   memory length: 644674   epsilon: 0.4607717500117061    steps: 292     evaluation reward: 7.57\n",
            "episode: 2666   score: 5.0   memory length: 644972   epsilon: 0.4604767300117125    steps: 298     evaluation reward: 7.55\n",
            "episode: 2667   score: 14.0   memory length: 645518   epsilon: 0.45993619001172426    steps: 546     evaluation reward: 7.56\n",
            "episode: 2668   score: 5.0   memory length: 645837   epsilon: 0.4596203800117311    steps: 319     evaluation reward: 7.54\n",
            "episode: 2669   score: 4.0   memory length: 646106   epsilon: 0.4593540700117369    steps: 269     evaluation reward: 7.5\n",
            "episode: 2670   score: 5.0   memory length: 646406   epsilon: 0.45905707001174334    steps: 300     evaluation reward: 7.4\n",
            "episode: 2671   score: 6.0   memory length: 646767   epsilon: 0.4586996800117511    steps: 361     evaluation reward: 7.42\n",
            "episode: 2672   score: 9.0   memory length: 647090   epsilon: 0.45837991001175804    steps: 323     evaluation reward: 7.46\n",
            "episode: 2673   score: 6.0   memory length: 647475   epsilon: 0.4579987600117663    steps: 385     evaluation reward: 7.47\n",
            "episode: 2674   score: 15.0   memory length: 647884   epsilon: 0.4575938500117751    steps: 409     evaluation reward: 7.58\n",
            "episode: 2675   score: 10.0   memory length: 648305   epsilon: 0.45717706001178415    steps: 421     evaluation reward: 7.57\n",
            "episode: 2676   score: 5.0   memory length: 648618   epsilon: 0.4568671900117909    steps: 313     evaluation reward: 7.51\n",
            "episode: 2677   score: 9.0   memory length: 648952   epsilon: 0.45653653001179806    steps: 334     evaluation reward: 7.56\n",
            "episode: 2678   score: 10.0   memory length: 649347   epsilon: 0.45614548001180655    steps: 395     evaluation reward: 7.53\n",
            "episode: 2679   score: 5.0   memory length: 649652   epsilon: 0.4558435300118131    steps: 305     evaluation reward: 7.49\n",
            "now time :  2019-12-12 21:40:01.837856\n",
            "episode: 2680   score: 8.0   memory length: 650063   epsilon: 0.45543664001182194    steps: 411     evaluation reward: 7.42\n",
            "episode: 2681   score: 7.0   memory length: 650477   epsilon: 0.45502678001183083    steps: 414     evaluation reward: 7.42\n",
            "episode: 2682   score: 6.0   memory length: 650828   epsilon: 0.4546792900118384    steps: 351     evaluation reward: 7.38\n",
            "episode: 2683   score: 4.0   memory length: 651089   epsilon: 0.454420900011844    steps: 261     evaluation reward: 7.38\n",
            "episode: 2684   score: 8.0   memory length: 651526   epsilon: 0.4539882700118534    steps: 437     evaluation reward: 7.37\n",
            "episode: 2685   score: 7.0   memory length: 651883   epsilon: 0.45363484001186105    steps: 357     evaluation reward: 7.35\n",
            "episode: 2686   score: 4.0   memory length: 652166   epsilon: 0.45335467001186713    steps: 283     evaluation reward: 7.32\n",
            "episode: 2687   score: 4.0   memory length: 652468   epsilon: 0.4530556900118736    steps: 302     evaluation reward: 7.28\n",
            "episode: 2688   score: 4.0   memory length: 652728   epsilon: 0.4527982900118792    steps: 260     evaluation reward: 7.24\n",
            "episode: 2689   score: 9.0   memory length: 653076   epsilon: 0.4524537700118867    steps: 348     evaluation reward: 7.25\n",
            "episode: 2690   score: 5.0   memory length: 653390   epsilon: 0.45214291001189344    steps: 314     evaluation reward: 7.26\n",
            "episode: 2691   score: 9.0   memory length: 653722   epsilon: 0.4518142300119006    steps: 332     evaluation reward: 7.33\n",
            "episode: 2692   score: 8.0   memory length: 654130   epsilon: 0.45141031001190934    steps: 408     evaluation reward: 7.39\n",
            "episode: 2693   score: 5.0   memory length: 654432   epsilon: 0.45111133001191583    steps: 302     evaluation reward: 7.41\n",
            "episode: 2694   score: 10.0   memory length: 654814   epsilon: 0.45073315001192404    steps: 382     evaluation reward: 7.4\n",
            "episode: 2695   score: 7.0   memory length: 655218   epsilon: 0.4503331900119327    steps: 404     evaluation reward: 7.4\n",
            "episode: 2696   score: 5.0   memory length: 655521   epsilon: 0.45003322001193924    steps: 303     evaluation reward: 7.36\n",
            "episode: 2697   score: 4.0   memory length: 655803   epsilon: 0.4497540400119453    steps: 282     evaluation reward: 7.35\n",
            "episode: 2698   score: 9.0   memory length: 656242   epsilon: 0.44931943001195473    steps: 439     evaluation reward: 7.36\n",
            "episode: 2699   score: 12.0   memory length: 656712   epsilon: 0.44885413001196484    steps: 470     evaluation reward: 7.43\n",
            "episode: 2700   score: 8.0   memory length: 657150   epsilon: 0.44842051001197425    steps: 438     evaluation reward: 7.44\n",
            "episode: 2701   score: 4.0   memory length: 657410   epsilon: 0.44816311001197984    steps: 260     evaluation reward: 7.39\n",
            "episode: 2702   score: 5.0   memory length: 657708   epsilon: 0.44786809001198624    steps: 298     evaluation reward: 7.4\n",
            "episode: 2703   score: 13.0   memory length: 658059   epsilon: 0.4475206000119938    steps: 351     evaluation reward: 7.49\n",
            "episode: 2704   score: 9.0   memory length: 658544   epsilon: 0.4470404500120042    steps: 485     evaluation reward: 7.54\n",
            "episode: 2705   score: 15.0   memory length: 658991   epsilon: 0.4465979200120138    steps: 447     evaluation reward: 7.61\n",
            "episode: 2706   score: 7.0   memory length: 659392   epsilon: 0.44620093001202243    steps: 401     evaluation reward: 7.6\n",
            "episode: 2707   score: 8.0   memory length: 659801   epsilon: 0.4457960200120312    steps: 409     evaluation reward: 7.62\n",
            "episode: 2708   score: 11.0   memory length: 660242   epsilon: 0.4453594300120407    steps: 441     evaluation reward: 7.66\n",
            "episode: 2709   score: 7.0   memory length: 660622   epsilon: 0.44498323001204887    steps: 380     evaluation reward: 7.64\n",
            "episode: 2710   score: 6.0   memory length: 660964   epsilon: 0.4446446500120562    steps: 342     evaluation reward: 7.63\n",
            "episode: 2711   score: 7.0   memory length: 661333   epsilon: 0.44427934001206415    steps: 369     evaluation reward: 7.58\n",
            "episode: 2712   score: 6.0   memory length: 661720   epsilon: 0.44389621001207247    steps: 387     evaluation reward: 7.57\n",
            "episode: 2713   score: 5.0   memory length: 662015   epsilon: 0.4436041600120788    steps: 295     evaluation reward: 7.52\n",
            "episode: 2714   score: 5.0   memory length: 662342   epsilon: 0.44328043001208584    steps: 327     evaluation reward: 7.52\n",
            "episode: 2715   score: 13.0   memory length: 662802   epsilon: 0.4428250300120957    steps: 460     evaluation reward: 7.63\n",
            "episode: 2716   score: 9.0   memory length: 663267   epsilon: 0.4423646800121057    steps: 465     evaluation reward: 7.65\n",
            "episode: 2717   score: 7.0   memory length: 663651   epsilon: 0.44198452001211397    steps: 384     evaluation reward: 7.66\n",
            "episode: 2718   score: 9.0   memory length: 663989   epsilon: 0.44164990001212123    steps: 338     evaluation reward: 7.63\n",
            "episode: 2719   score: 6.0   memory length: 664367   epsilon: 0.44127568001212936    steps: 378     evaluation reward: 7.56\n",
            "episode: 2720   score: 12.0   memory length: 664821   epsilon: 0.4408262200121391    steps: 454     evaluation reward: 7.52\n",
            "episode: 2721   score: 7.0   memory length: 665219   epsilon: 0.44043220001214767    steps: 398     evaluation reward: 7.52\n",
            "episode: 2722   score: 4.0   memory length: 665466   epsilon: 0.440187670012153    steps: 247     evaluation reward: 7.49\n",
            "episode: 2723   score: 11.0   memory length: 665874   epsilon: 0.43978375001216174    steps: 408     evaluation reward: 7.52\n",
            "episode: 2724   score: 11.0   memory length: 666409   epsilon: 0.43925410001217324    steps: 535     evaluation reward: 7.54\n",
            "episode: 2725   score: 4.0   memory length: 666701   epsilon: 0.4389650200121795    steps: 292     evaluation reward: 7.51\n",
            "episode: 2726   score: 6.0   memory length: 667043   epsilon: 0.43862644001218687    steps: 342     evaluation reward: 7.46\n",
            "episode: 2727   score: 8.0   memory length: 667487   epsilon: 0.4381868800121964    steps: 444     evaluation reward: 7.44\n",
            "episode: 2728   score: 13.0   memory length: 668000   epsilon: 0.43767901001220744    steps: 513     evaluation reward: 7.47\n",
            "episode: 2729   score: 7.0   memory length: 668351   epsilon: 0.437331520012215    steps: 351     evaluation reward: 7.5\n",
            "episode: 2730   score: 17.0   memory length: 668928   epsilon: 0.4367602900122274    steps: 577     evaluation reward: 7.63\n",
            "episode: 2731   score: 6.0   memory length: 669304   epsilon: 0.43638805001223546    steps: 376     evaluation reward: 7.6\n",
            "episode: 2732   score: 10.0   memory length: 669676   epsilon: 0.43601977001224346    steps: 372     evaluation reward: 7.63\n",
            "episode: 2733   score: 10.0   memory length: 670095   epsilon: 0.43560496001225246    steps: 419     evaluation reward: 7.64\n",
            "episode: 2734   score: 9.0   memory length: 670495   epsilon: 0.43520896001226106    steps: 400     evaluation reward: 7.59\n",
            "episode: 2735   score: 3.0   memory length: 670718   epsilon: 0.43498819001226585    steps: 223     evaluation reward: 7.53\n",
            "episode: 2736   score: 7.0   memory length: 671137   epsilon: 0.43457338001227486    steps: 419     evaluation reward: 7.52\n",
            "episode: 2737   score: 11.0   memory length: 671521   epsilon: 0.4341932200122831    steps: 384     evaluation reward: 7.52\n",
            "episode: 2738   score: 11.0   memory length: 671975   epsilon: 0.43374376001229287    steps: 454     evaluation reward: 7.58\n",
            "episode: 2739   score: 3.0   memory length: 672195   epsilon: 0.4335259600122976    steps: 220     evaluation reward: 7.46\n",
            "episode: 2740   score: 15.0   memory length: 672833   epsilon: 0.4328943400123113    steps: 638     evaluation reward: 7.55\n",
            "episode: 2741   score: 11.0   memory length: 673299   epsilon: 0.4324330000123213    steps: 466     evaluation reward: 7.6\n",
            "episode: 2742   score: 10.0   memory length: 673643   epsilon: 0.4320924400123287    steps: 344     evaluation reward: 7.59\n",
            "episode: 2743   score: 12.0   memory length: 674102   epsilon: 0.4316380300123386    steps: 459     evaluation reward: 7.64\n",
            "episode: 2744   score: 6.0   memory length: 674465   epsilon: 0.4312786600123464    steps: 363     evaluation reward: 7.66\n",
            "episode: 2745   score: 7.0   memory length: 674884   epsilon: 0.4308638500123554    steps: 419     evaluation reward: 7.67\n",
            "episode: 2746   score: 5.0   memory length: 675196   epsilon: 0.4305549700123621    steps: 312     evaluation reward: 7.66\n",
            "episode: 2747   score: 6.0   memory length: 675559   epsilon: 0.4301956000123699    steps: 363     evaluation reward: 7.64\n",
            "episode: 2748   score: 4.0   memory length: 675823   epsilon: 0.42993424001237557    steps: 264     evaluation reward: 7.61\n",
            "episode: 2749   score: 6.0   memory length: 676196   epsilon: 0.4295649700123836    steps: 373     evaluation reward: 7.58\n",
            "episode: 2750   score: 17.0   memory length: 676727   epsilon: 0.429039280012395    steps: 531     evaluation reward: 7.67\n",
            "episode: 2751   score: 4.0   memory length: 676991   epsilon: 0.42877792001240067    steps: 264     evaluation reward: 7.61\n",
            "episode: 2752   score: 13.0   memory length: 677536   epsilon: 0.4282383700124124    steps: 545     evaluation reward: 7.64\n",
            "episode: 2753   score: 6.0   memory length: 677875   epsilon: 0.42790276001241967    steps: 339     evaluation reward: 7.61\n",
            "episode: 2754   score: 6.0   memory length: 678199   epsilon: 0.42758200001242663    steps: 324     evaluation reward: 7.61\n",
            "episode: 2755   score: 12.0   memory length: 678659   epsilon: 0.4271266000124365    steps: 460     evaluation reward: 7.69\n",
            "episode: 2756   score: 5.0   memory length: 678986   epsilon: 0.42680287001244355    steps: 327     evaluation reward: 7.68\n",
            "episode: 2757   score: 2.0   memory length: 679173   epsilon: 0.42661774001244757    steps: 187     evaluation reward: 7.64\n",
            "episode: 2758   score: 4.0   memory length: 679458   epsilon: 0.4263355900124537    steps: 285     evaluation reward: 7.62\n",
            "episode: 2759   score: 10.0   memory length: 679854   epsilon: 0.4259435500124622    steps: 396     evaluation reward: 7.68\n",
            "episode: 2760   score: 6.0   memory length: 680195   epsilon: 0.42560596001246953    steps: 341     evaluation reward: 7.66\n",
            "episode: 2761   score: 4.0   memory length: 680488   epsilon: 0.42531589001247583    steps: 293     evaluation reward: 7.63\n",
            "episode: 2762   score: 16.0   memory length: 681060   epsilon: 0.4247496100124881    steps: 572     evaluation reward: 7.75\n",
            "episode: 2763   score: 13.0   memory length: 681549   epsilon: 0.42426550001249863    steps: 489     evaluation reward: 7.83\n",
            "episode: 2764   score: 6.0   memory length: 681899   epsilon: 0.42391900001250615    steps: 350     evaluation reward: 7.84\n",
            "episode: 2765   score: 7.0   memory length: 682284   epsilon: 0.4235378500125144    steps: 385     evaluation reward: 7.86\n",
            "episode: 2766   score: 8.0   memory length: 682729   epsilon: 0.423097300012524    steps: 445     evaluation reward: 7.89\n",
            "episode: 2767   score: 6.0   memory length: 683069   epsilon: 0.4227607000125313    steps: 340     evaluation reward: 7.81\n",
            "episode: 2768   score: 6.0   memory length: 683428   epsilon: 0.422405290012539    steps: 359     evaluation reward: 7.82\n",
            "episode: 2769   score: 8.0   memory length: 683858   epsilon: 0.42197959001254826    steps: 430     evaluation reward: 7.86\n",
            "episode: 2770   score: 8.0   memory length: 684257   epsilon: 0.42158458001255683    steps: 399     evaluation reward: 7.89\n",
            "episode: 2771   score: 9.0   memory length: 684704   epsilon: 0.42114205001256644    steps: 447     evaluation reward: 7.92\n",
            "episode: 2772   score: 5.0   memory length: 685012   epsilon: 0.42083713001257306    steps: 308     evaluation reward: 7.88\n",
            "episode: 2773   score: 7.0   memory length: 685387   epsilon: 0.4204658800125811    steps: 375     evaluation reward: 7.89\n",
            "episode: 2774   score: 1.0   memory length: 685555   epsilon: 0.4202995600125847    steps: 168     evaluation reward: 7.75\n",
            "episode: 2775   score: 9.0   memory length: 686044   epsilon: 0.41981545001259524    steps: 489     evaluation reward: 7.74\n",
            "episode: 2776   score: 3.0   memory length: 686311   epsilon: 0.419551120012601    steps: 267     evaluation reward: 7.72\n",
            "episode: 2777   score: 8.0   memory length: 686754   epsilon: 0.4191125500126105    steps: 443     evaluation reward: 7.71\n",
            "episode: 2778   score: 5.0   memory length: 687070   epsilon: 0.4187997100126173    steps: 316     evaluation reward: 7.66\n",
            "episode: 2779   score: 5.0   memory length: 687347   epsilon: 0.41852548001262324    steps: 277     evaluation reward: 7.66\n",
            "episode: 2780   score: 8.0   memory length: 687756   epsilon: 0.41812057001263203    steps: 409     evaluation reward: 7.66\n",
            "episode: 2781   score: 12.0   memory length: 688183   epsilon: 0.4176978400126412    steps: 427     evaluation reward: 7.71\n",
            "episode: 2782   score: 6.0   memory length: 688521   epsilon: 0.4173632200126485    steps: 338     evaluation reward: 7.71\n",
            "episode: 2783   score: 10.0   memory length: 689056   epsilon: 0.41683357001265997    steps: 535     evaluation reward: 7.77\n",
            "episode: 2784   score: 7.0   memory length: 689398   epsilon: 0.4164949900126673    steps: 342     evaluation reward: 7.76\n",
            "episode: 2785   score: 4.0   memory length: 689669   epsilon: 0.41622670001267315    steps: 271     evaluation reward: 7.73\n",
            "episode: 2786   score: 6.0   memory length: 690018   epsilon: 0.41588119001268065    steps: 349     evaluation reward: 7.75\n",
            "episode: 2787   score: 7.0   memory length: 690394   epsilon: 0.4155089500126887    steps: 376     evaluation reward: 7.78\n",
            "episode: 2788   score: 10.0   memory length: 690782   epsilon: 0.41512483001269707    steps: 388     evaluation reward: 7.84\n",
            "episode: 2789   score: 10.0   memory length: 691189   epsilon: 0.4147219000127058    steps: 407     evaluation reward: 7.85\n",
            "episode: 2790   score: 2.0   memory length: 691382   epsilon: 0.41453083001270996    steps: 193     evaluation reward: 7.82\n",
            "episode: 2791   score: 5.0   memory length: 691697   epsilon: 0.41421898001271673    steps: 315     evaluation reward: 7.78\n",
            "episode: 2792   score: 10.0   memory length: 692193   epsilon: 0.4137279400127274    steps: 496     evaluation reward: 7.8\n",
            "episode: 2793   score: 4.0   memory length: 692457   epsilon: 0.41346658001273306    steps: 264     evaluation reward: 7.79\n",
            "episode: 2794   score: 2.0   memory length: 692657   epsilon: 0.41326858001273736    steps: 200     evaluation reward: 7.71\n",
            "episode: 2795   score: 6.0   memory length: 693020   epsilon: 0.41290921001274516    steps: 363     evaluation reward: 7.7\n",
            "episode: 2796   score: 11.0   memory length: 693429   epsilon: 0.41250430001275395    steps: 409     evaluation reward: 7.76\n",
            "episode: 2797   score: 10.0   memory length: 693796   epsilon: 0.41214097001276184    steps: 367     evaluation reward: 7.82\n",
            "episode: 2798   score: 8.0   memory length: 694079   epsilon: 0.4118608000127679    steps: 283     evaluation reward: 7.81\n",
            "episode: 2799   score: 7.0   memory length: 694501   epsilon: 0.411443020012777    steps: 422     evaluation reward: 7.76\n",
            "episode: 2800   score: 4.0   memory length: 694750   epsilon: 0.41119651001278235    steps: 249     evaluation reward: 7.72\n",
            "episode: 2801   score: 13.0   memory length: 695103   epsilon: 0.41084704001278993    steps: 353     evaluation reward: 7.81\n",
            "episode: 2802   score: 12.0   memory length: 695538   epsilon: 0.4104163900127993    steps: 435     evaluation reward: 7.88\n",
            "episode: 2803   score: 8.0   memory length: 696029   epsilon: 0.40993030001280983    steps: 491     evaluation reward: 7.83\n",
            "episode: 2804   score: 7.0   memory length: 696405   epsilon: 0.4095580600128179    steps: 376     evaluation reward: 7.81\n",
            "episode: 2805   score: 10.0   memory length: 696905   epsilon: 0.40906306001282866    steps: 500     evaluation reward: 7.76\n",
            "episode: 2806   score: 12.0   memory length: 697367   epsilon: 0.4086056800128386    steps: 462     evaluation reward: 7.81\n",
            "episode: 2807   score: 8.0   memory length: 697667   epsilon: 0.40830868001284504    steps: 300     evaluation reward: 7.81\n",
            "episode: 2808   score: 11.0   memory length: 698240   epsilon: 0.40774141001285735    steps: 573     evaluation reward: 7.81\n",
            "episode: 2809   score: 6.0   memory length: 698578   epsilon: 0.4074067900128646    steps: 338     evaluation reward: 7.8\n",
            "episode: 2810   score: 10.0   memory length: 699097   epsilon: 0.40689298001287577    steps: 519     evaluation reward: 7.84\n",
            "episode: 2811   score: 5.0   memory length: 699390   epsilon: 0.40660291001288207    steps: 293     evaluation reward: 7.82\n",
            "episode: 2812   score: 5.0   memory length: 699703   epsilon: 0.4062930400128888    steps: 313     evaluation reward: 7.81\n",
            "now time :  2019-12-12 22:05:26.980681\n",
            "episode: 2813   score: 10.0   memory length: 700082   epsilon: 0.40591783001289694    steps: 379     evaluation reward: 7.86\n",
            "episode: 2814   score: 7.0   memory length: 700491   epsilon: 0.40551292001290573    steps: 409     evaluation reward: 7.88\n",
            "episode: 2815   score: 13.0   memory length: 700834   epsilon: 0.4051733500129131    steps: 343     evaluation reward: 7.88\n",
            "episode: 2816   score: 3.0   memory length: 701061   epsilon: 0.404948620012918    steps: 227     evaluation reward: 7.82\n",
            "episode: 2817   score: 7.0   memory length: 701427   epsilon: 0.40458628001292585    steps: 366     evaluation reward: 7.82\n",
            "episode: 2818   score: 7.0   memory length: 701834   epsilon: 0.4041833500129346    steps: 407     evaluation reward: 7.8\n",
            "episode: 2819   score: 10.0   memory length: 702365   epsilon: 0.403657660012946    steps: 531     evaluation reward: 7.84\n",
            "episode: 2820   score: 4.0   memory length: 702631   epsilon: 0.4033943200129517    steps: 266     evaluation reward: 7.76\n",
            "episode: 2821   score: 7.0   memory length: 702999   epsilon: 0.40303000001295963    steps: 368     evaluation reward: 7.76\n",
            "episode: 2822   score: 14.0   memory length: 703547   epsilon: 0.4024874800129714    steps: 548     evaluation reward: 7.86\n",
            "episode: 2823   score: 14.0   memory length: 703955   epsilon: 0.4020835600129802    steps: 408     evaluation reward: 7.89\n",
            "episode: 2824   score: 11.0   memory length: 704394   epsilon: 0.4016489500129896    steps: 439     evaluation reward: 7.89\n",
            "episode: 2825   score: 13.0   memory length: 704887   epsilon: 0.4011608800130002    steps: 493     evaluation reward: 7.98\n",
            "episode: 2826   score: 9.0   memory length: 705278   epsilon: 0.4007737900130086    steps: 391     evaluation reward: 8.01\n",
            "episode: 2827   score: 6.0   memory length: 705604   epsilon: 0.4004510500130156    steps: 326     evaluation reward: 7.99\n",
            "episode: 2828   score: 7.0   memory length: 705958   epsilon: 0.4001005900130232    steps: 354     evaluation reward: 7.93\n",
            "episode: 2829   score: 13.0   memory length: 706320   epsilon: 0.399742210013031    steps: 362     evaluation reward: 7.99\n",
            "episode: 2830   score: 6.0   memory length: 706653   epsilon: 0.39941254001303816    steps: 333     evaluation reward: 7.88\n",
            "episode: 2831   score: 3.0   memory length: 706872   epsilon: 0.39919573001304287    steps: 219     evaluation reward: 7.85\n",
            "episode: 2832   score: 7.0   memory length: 707272   epsilon: 0.39879973001305147    steps: 400     evaluation reward: 7.82\n",
            "episode: 2833   score: 11.0   memory length: 707681   epsilon: 0.39839482001306026    steps: 409     evaluation reward: 7.83\n",
            "episode: 2834   score: 5.0   memory length: 708007   epsilon: 0.39807208001306726    steps: 326     evaluation reward: 7.79\n",
            "episode: 2835   score: 7.0   memory length: 708378   epsilon: 0.39770479001307524    steps: 371     evaluation reward: 7.83\n",
            "episode: 2836   score: 6.0   memory length: 708787   epsilon: 0.39729988001308403    steps: 409     evaluation reward: 7.82\n",
            "episode: 2837   score: 19.0   memory length: 709290   epsilon: 0.39680191001309484    steps: 503     evaluation reward: 7.9\n",
            "episode: 2838   score: 17.0   memory length: 710021   epsilon: 0.39607822001311055    steps: 731     evaluation reward: 7.96\n",
            "episode: 2839   score: 8.0   memory length: 710442   epsilon: 0.3956614300131196    steps: 421     evaluation reward: 8.01\n",
            "episode: 2840   score: 10.0   memory length: 710935   epsilon: 0.3951733600131302    steps: 493     evaluation reward: 7.96\n",
            "episode: 2841   score: 9.0   memory length: 711414   epsilon: 0.3946991500131405    steps: 479     evaluation reward: 7.94\n",
            "episode: 2842   score: 4.0   memory length: 711689   epsilon: 0.3944269000131464    steps: 275     evaluation reward: 7.88\n",
            "episode: 2843   score: 9.0   memory length: 712019   epsilon: 0.3941002000131535    steps: 330     evaluation reward: 7.85\n",
            "episode: 2844   score: 5.0   memory length: 712330   epsilon: 0.3937923100131602    steps: 311     evaluation reward: 7.84\n",
            "episode: 2845   score: 7.0   memory length: 712729   epsilon: 0.39339730001316875    steps: 399     evaluation reward: 7.84\n",
            "episode: 2846   score: 9.0   memory length: 713173   epsilon: 0.3929577400131783    steps: 444     evaluation reward: 7.88\n",
            "episode: 2847   score: 8.0   memory length: 713478   epsilon: 0.39265579001318485    steps: 305     evaluation reward: 7.9\n",
            "episode: 2848   score: 7.0   memory length: 713849   epsilon: 0.3922885000131928    steps: 371     evaluation reward: 7.93\n",
            "episode: 2849   score: 8.0   memory length: 714292   epsilon: 0.39184993001320234    steps: 443     evaluation reward: 7.95\n",
            "episode: 2850   score: 10.0   memory length: 714754   epsilon: 0.39139255001321227    steps: 462     evaluation reward: 7.88\n",
            "episode: 2851   score: 9.0   memory length: 715090   epsilon: 0.3910599100132195    steps: 336     evaluation reward: 7.93\n",
            "episode: 2852   score: 5.0   memory length: 715390   epsilon: 0.39076291001322594    steps: 300     evaluation reward: 7.85\n",
            "episode: 2853   score: 10.0   memory length: 715901   epsilon: 0.3902570200132369    steps: 511     evaluation reward: 7.89\n",
            "episode: 2854   score: 17.0   memory length: 716263   epsilon: 0.3898986400132447    steps: 362     evaluation reward: 8.0\n",
            "episode: 2855   score: 15.0   memory length: 716715   epsilon: 0.3894511600132544    steps: 452     evaluation reward: 8.03\n",
            "episode: 2856   score: 5.0   memory length: 717039   epsilon: 0.3891304000132614    steps: 324     evaluation reward: 8.03\n",
            "episode: 2857   score: 17.0   memory length: 717386   epsilon: 0.38878687001326884    steps: 347     evaluation reward: 8.18\n",
            "episode: 2858   score: 11.0   memory length: 717807   epsilon: 0.3883700800132779    steps: 421     evaluation reward: 8.25\n",
            "episode: 2859   score: 8.0   memory length: 718259   epsilon: 0.3879226000132876    steps: 452     evaluation reward: 8.23\n",
            "episode: 2860   score: 8.0   memory length: 718703   epsilon: 0.38748304001329714    steps: 444     evaluation reward: 8.25\n",
            "episode: 2861   score: 3.0   memory length: 718917   epsilon: 0.38727118001330174    steps: 214     evaluation reward: 8.24\n",
            "episode: 2862   score: 5.0   memory length: 719223   epsilon: 0.3869682400133083    steps: 306     evaluation reward: 8.13\n",
            "episode: 2863   score: 8.0   memory length: 719637   epsilon: 0.3865583800133172    steps: 414     evaluation reward: 8.08\n",
            "episode: 2864   score: 9.0   memory length: 720104   epsilon: 0.38609605001332725    steps: 467     evaluation reward: 8.11\n",
            "episode: 2865   score: 6.0   memory length: 720441   epsilon: 0.3857624200133345    steps: 337     evaluation reward: 8.1\n",
            "episode: 2866   score: 10.0   memory length: 720789   epsilon: 0.385417900013342    steps: 348     evaluation reward: 8.12\n",
            "episode: 2867   score: 4.0   memory length: 721091   epsilon: 0.38511892001334846    steps: 302     evaluation reward: 8.1\n",
            "episode: 2868   score: 12.0   memory length: 721556   epsilon: 0.38465857001335846    steps: 465     evaluation reward: 8.16\n",
            "episode: 2869   score: 5.0   memory length: 721851   epsilon: 0.3843665200133648    steps: 295     evaluation reward: 8.13\n",
            "episode: 2870   score: 13.0   memory length: 722217   epsilon: 0.38400418001337266    steps: 366     evaluation reward: 8.18\n",
            "episode: 2871   score: 8.0   memory length: 722659   epsilon: 0.38356660001338216    steps: 442     evaluation reward: 8.17\n",
            "episode: 2872   score: 18.0   memory length: 723212   epsilon: 0.38301913001339405    steps: 553     evaluation reward: 8.3\n",
            "episode: 2873   score: 8.0   memory length: 723605   epsilon: 0.3826300600134025    steps: 393     evaluation reward: 8.31\n",
            "episode: 2874   score: 7.0   memory length: 723986   epsilon: 0.3822528700134107    steps: 381     evaluation reward: 8.37\n",
            "episode: 2875   score: 4.0   memory length: 724253   epsilon: 0.3819885400134164    steps: 267     evaluation reward: 8.32\n",
            "episode: 2876   score: 11.0   memory length: 724808   epsilon: 0.38143909001342835    steps: 555     evaluation reward: 8.4\n",
            "episode: 2877   score: 10.0   memory length: 725173   epsilon: 0.3810777400134362    steps: 365     evaluation reward: 8.42\n",
            "episode: 2878   score: 4.0   memory length: 725457   epsilon: 0.3807965800134423    steps: 284     evaluation reward: 8.41\n",
            "episode: 2879   score: 10.0   memory length: 725969   epsilon: 0.3802897000134533    steps: 512     evaluation reward: 8.46\n",
            "episode: 2880   score: 5.0   memory length: 726257   epsilon: 0.3800045800134595    steps: 288     evaluation reward: 8.43\n",
            "episode: 2881   score: 11.0   memory length: 726644   epsilon: 0.3796214500134678    steps: 387     evaluation reward: 8.42\n",
            "episode: 2882   score: 7.0   memory length: 727025   epsilon: 0.379244260013476    steps: 381     evaluation reward: 8.43\n",
            "episode: 2883   score: 6.0   memory length: 727428   epsilon: 0.37884529001348466    steps: 403     evaluation reward: 8.39\n",
            "episode: 2884   score: 5.0   memory length: 727721   epsilon: 0.37855522001349096    steps: 293     evaluation reward: 8.37\n",
            "episode: 2885   score: 8.0   memory length: 728185   epsilon: 0.37809586001350093    steps: 464     evaluation reward: 8.41\n",
            "episode: 2886   score: 5.0   memory length: 728464   epsilon: 0.3778196500135069    steps: 279     evaluation reward: 8.4\n",
            "episode: 2887   score: 7.0   memory length: 728808   epsilon: 0.3774790900135143    steps: 344     evaluation reward: 8.4\n",
            "episode: 2888   score: 13.0   memory length: 729159   epsilon: 0.37713160001352186    steps: 351     evaluation reward: 8.43\n",
            "episode: 2889   score: 18.0   memory length: 729570   epsilon: 0.3767247100135307    steps: 411     evaluation reward: 8.51\n",
            "episode: 2890   score: 11.0   memory length: 729981   epsilon: 0.37631782001353953    steps: 411     evaluation reward: 8.6\n",
            "episode: 2891   score: 6.0   memory length: 730351   epsilon: 0.3759515200135475    steps: 370     evaluation reward: 8.61\n",
            "episode: 2892   score: 7.0   memory length: 730740   epsilon: 0.37556641001355584    steps: 389     evaluation reward: 8.58\n",
            "episode: 2893   score: 9.0   memory length: 731071   epsilon: 0.37523872001356295    steps: 331     evaluation reward: 8.63\n",
            "episode: 2894   score: 14.0   memory length: 731502   epsilon: 0.3748120300135722    steps: 431     evaluation reward: 8.75\n",
            "episode: 2895   score: 3.0   memory length: 731715   epsilon: 0.3746011600135768    steps: 213     evaluation reward: 8.72\n",
            "episode: 2896   score: 11.0   memory length: 732143   epsilon: 0.374177440013586    steps: 428     evaluation reward: 8.72\n",
            "episode: 2897   score: 10.0   memory length: 732497   epsilon: 0.3738269800135936    steps: 354     evaluation reward: 8.72\n",
            "episode: 2898   score: 13.0   memory length: 732983   epsilon: 0.37334584001360405    steps: 486     evaluation reward: 8.77\n",
            "episode: 2899   score: 4.0   memory length: 733236   epsilon: 0.3730953700136095    steps: 253     evaluation reward: 8.74\n",
            "episode: 2900   score: 14.0   memory length: 733869   epsilon: 0.3724687000136231    steps: 633     evaluation reward: 8.84\n",
            "episode: 2901   score: 8.0   memory length: 734147   epsilon: 0.37219348001362906    steps: 278     evaluation reward: 8.79\n",
            "episode: 2902   score: 3.0   memory length: 734390   epsilon: 0.3719529100136343    steps: 243     evaluation reward: 8.7\n",
            "episode: 2903   score: 5.0   memory length: 734669   epsilon: 0.3716767000136403    steps: 279     evaluation reward: 8.67\n",
            "episode: 2904   score: 7.0   memory length: 735076   epsilon: 0.37127377001364903    steps: 407     evaluation reward: 8.67\n",
            "episode: 2905   score: 10.0   memory length: 735464   epsilon: 0.37088965001365737    steps: 388     evaluation reward: 8.67\n",
            "episode: 2906   score: 13.0   memory length: 735942   epsilon: 0.37041643001366764    steps: 478     evaluation reward: 8.68\n",
            "episode: 2907   score: 10.0   memory length: 736282   epsilon: 0.37007983001367495    steps: 340     evaluation reward: 8.7\n",
            "episode: 2908   score: 10.0   memory length: 736730   epsilon: 0.3696363100136846    steps: 448     evaluation reward: 8.69\n",
            "episode: 2909   score: 5.0   memory length: 737045   epsilon: 0.36932446001369135    steps: 315     evaluation reward: 8.68\n",
            "episode: 2910   score: 12.0   memory length: 737508   epsilon: 0.3688660900137013    steps: 463     evaluation reward: 8.7\n",
            "episode: 2911   score: 11.0   memory length: 738072   epsilon: 0.3683077300137134    steps: 564     evaluation reward: 8.76\n",
            "episode: 2912   score: 9.0   memory length: 738392   epsilon: 0.3679909300137203    steps: 320     evaluation reward: 8.8\n",
            "episode: 2913   score: 15.0   memory length: 738805   epsilon: 0.3675820600137292    steps: 413     evaluation reward: 8.85\n",
            "episode: 2914   score: 5.0   memory length: 739116   epsilon: 0.36727417001373586    steps: 311     evaluation reward: 8.83\n",
            "episode: 2915   score: 10.0   memory length: 739622   epsilon: 0.36677323001374673    steps: 506     evaluation reward: 8.8\n",
            "episode: 2916   score: 5.0   memory length: 739935   epsilon: 0.36646336001375346    steps: 313     evaluation reward: 8.82\n",
            "episode: 2917   score: 12.0   memory length: 740361   epsilon: 0.3660416200137626    steps: 426     evaluation reward: 8.87\n",
            "episode: 2918   score: 11.0   memory length: 740780   epsilon: 0.3656268100137716    steps: 419     evaluation reward: 8.91\n",
            "episode: 2919   score: 2.0   memory length: 740962   epsilon: 0.36544663001377553    steps: 182     evaluation reward: 8.83\n",
            "episode: 2920   score: 11.0   memory length: 741275   epsilon: 0.36513676001378226    steps: 313     evaluation reward: 8.9\n",
            "episode: 2921   score: 12.0   memory length: 741585   epsilon: 0.3648298600137889    steps: 310     evaluation reward: 8.95\n",
            "episode: 2922   score: 12.0   memory length: 741909   epsilon: 0.3645091000137959    steps: 324     evaluation reward: 8.93\n",
            "episode: 2923   score: 10.0   memory length: 742370   epsilon: 0.3640527100138058    steps: 461     evaluation reward: 8.89\n",
            "episode: 2924   score: 4.0   memory length: 742656   epsilon: 0.36376957001381194    steps: 286     evaluation reward: 8.82\n",
            "episode: 2925   score: 9.0   memory length: 743014   epsilon: 0.36341515001381963    steps: 358     evaluation reward: 8.78\n",
            "episode: 2926   score: 6.0   memory length: 743391   epsilon: 0.36304192001382773    steps: 377     evaluation reward: 8.75\n",
            "episode: 2927   score: 8.0   memory length: 743834   epsilon: 0.36260335001383726    steps: 443     evaluation reward: 8.77\n",
            "episode: 2928   score: 8.0   memory length: 744298   epsilon: 0.36214399001384723    steps: 464     evaluation reward: 8.78\n",
            "episode: 2929   score: 6.0   memory length: 744690   epsilon: 0.36175591001385565    steps: 392     evaluation reward: 8.71\n",
            "episode: 2930   score: 8.0   memory length: 745116   epsilon: 0.3613341700138648    steps: 426     evaluation reward: 8.73\n",
            "episode: 2931   score: 6.0   memory length: 745488   epsilon: 0.3609658900138728    steps: 372     evaluation reward: 8.76\n",
            "episode: 2932   score: 4.0   memory length: 745785   epsilon: 0.3606718600138792    steps: 297     evaluation reward: 8.73\n",
            "episode: 2933   score: 5.0   memory length: 746097   epsilon: 0.3603629800138859    steps: 312     evaluation reward: 8.67\n",
            "episode: 2934   score: 17.0   memory length: 746471   epsilon: 0.35999272001389393    steps: 374     evaluation reward: 8.79\n",
            "episode: 2935   score: 8.0   memory length: 746866   epsilon: 0.3596016700139024    steps: 395     evaluation reward: 8.8\n",
            "episode: 2936   score: 5.0   memory length: 747174   epsilon: 0.35929675001390904    steps: 308     evaluation reward: 8.79\n",
            "episode: 2937   score: 14.0   memory length: 747525   epsilon: 0.3589492600139166    steps: 351     evaluation reward: 8.74\n",
            "episode: 2938   score: 7.0   memory length: 747920   epsilon: 0.35855821001392507    steps: 395     evaluation reward: 8.64\n",
            "episode: 2939   score: 6.0   memory length: 748230   epsilon: 0.35825131001393173    steps: 310     evaluation reward: 8.62\n",
            "episode: 2940   score: 3.0   memory length: 748451   epsilon: 0.3580325200139365    steps: 221     evaluation reward: 8.55\n",
            "episode: 2941   score: 5.0   memory length: 748764   epsilon: 0.3577226500139432    steps: 313     evaluation reward: 8.51\n",
            "episode: 2942   score: 6.0   memory length: 749121   epsilon: 0.3573692200139509    steps: 357     evaluation reward: 8.53\n",
            "episode: 2943   score: 8.0   memory length: 749556   epsilon: 0.35693857001396023    steps: 435     evaluation reward: 8.52\n",
            "episode: 2944   score: 3.0   memory length: 749810   epsilon: 0.3566871100139657    steps: 254     evaluation reward: 8.5\n",
            "now time :  2019-12-12 22:31:26.161927\n",
            "episode: 2945   score: 9.0   memory length: 750168   epsilon: 0.3563326900139734    steps: 358     evaluation reward: 8.52\n",
            "episode: 2946   score: 4.0   memory length: 750446   epsilon: 0.35605747001397936    steps: 278     evaluation reward: 8.47\n",
            "episode: 2947   score: 5.0   memory length: 750762   epsilon: 0.35574463001398615    steps: 316     evaluation reward: 8.44\n",
            "episode: 2948   score: 10.0   memory length: 751331   epsilon: 0.3551813200139984    steps: 569     evaluation reward: 8.47\n",
            "episode: 2949   score: 9.0   memory length: 751637   epsilon: 0.35487838001400496    steps: 306     evaluation reward: 8.48\n",
            "episode: 2950   score: 8.0   memory length: 752106   epsilon: 0.35441407001401504    steps: 469     evaluation reward: 8.46\n",
            "episode: 2951   score: 9.0   memory length: 752553   epsilon: 0.35397154001402464    steps: 447     evaluation reward: 8.46\n",
            "episode: 2952   score: 8.0   memory length: 753018   epsilon: 0.35351119001403464    steps: 465     evaluation reward: 8.49\n",
            "episode: 2953   score: 4.0   memory length: 753280   epsilon: 0.35325181001404027    steps: 262     evaluation reward: 8.43\n",
            "episode: 2954   score: 13.0   memory length: 753760   epsilon: 0.3527766100140506    steps: 480     evaluation reward: 8.39\n",
            "episode: 2955   score: 6.0   memory length: 754147   epsilon: 0.3523934800140589    steps: 387     evaluation reward: 8.3\n",
            "episode: 2956   score: 10.0   memory length: 754661   epsilon: 0.35188462001406995    steps: 514     evaluation reward: 8.35\n",
            "episode: 2957   score: 10.0   memory length: 755173   epsilon: 0.35137774001408095    steps: 512     evaluation reward: 8.28\n",
            "episode: 2958   score: 4.0   memory length: 755437   epsilon: 0.3511163800140866    steps: 264     evaluation reward: 8.21\n",
            "episode: 2959   score: 3.0   memory length: 755666   epsilon: 0.35088967001409155    steps: 229     evaluation reward: 8.16\n",
            "episode: 2960   score: 9.0   memory length: 756127   epsilon: 0.35043328001410146    steps: 461     evaluation reward: 8.17\n",
            "episode: 2961   score: 13.0   memory length: 756573   epsilon: 0.34999174001411104    steps: 446     evaluation reward: 8.27\n",
            "episode: 2962   score: 5.0   memory length: 756883   epsilon: 0.3496848400141177    steps: 310     evaluation reward: 8.27\n",
            "episode: 2963   score: 8.0   memory length: 757211   epsilon: 0.34936012001412475    steps: 328     evaluation reward: 8.27\n",
            "episode: 2964   score: 11.0   memory length: 757492   epsilon: 0.3490819300141308    steps: 281     evaluation reward: 8.29\n",
            "episode: 2965   score: 14.0   memory length: 757870   epsilon: 0.3487077100141389    steps: 378     evaluation reward: 8.37\n",
            "episode: 2966   score: 11.0   memory length: 758280   epsilon: 0.34830181001414773    steps: 410     evaluation reward: 8.38\n",
            "episode: 2967   score: 8.0   memory length: 758572   epsilon: 0.348012730014154    steps: 292     evaluation reward: 8.42\n",
            "episode: 2968   score: 6.0   memory length: 758945   epsilon: 0.347643460014162    steps: 373     evaluation reward: 8.36\n",
            "episode: 2969   score: 4.0   memory length: 759194   epsilon: 0.34739695001416737    steps: 249     evaluation reward: 8.35\n",
            "episode: 2970   score: 8.0   memory length: 759634   epsilon: 0.34696135001417683    steps: 440     evaluation reward: 8.3\n",
            "episode: 2971   score: 5.0   memory length: 759929   epsilon: 0.34666930001418317    steps: 295     evaluation reward: 8.27\n",
            "episode: 2972   score: 11.0   memory length: 760345   epsilon: 0.3462574600141921    steps: 416     evaluation reward: 8.2\n",
            "episode: 2973   score: 4.0   memory length: 760638   epsilon: 0.3459673900141984    steps: 293     evaluation reward: 8.16\n",
            "episode: 2974   score: 7.0   memory length: 761044   epsilon: 0.34556545001420713    steps: 406     evaluation reward: 8.16\n",
            "episode: 2975   score: 8.0   memory length: 761456   epsilon: 0.345157570014216    steps: 412     evaluation reward: 8.2\n",
            "episode: 2976   score: 9.0   memory length: 761940   epsilon: 0.3446784100142264    steps: 484     evaluation reward: 8.18\n",
            "episode: 2977   score: 13.0   memory length: 762438   epsilon: 0.3441853900142371    steps: 498     evaluation reward: 8.21\n",
            "episode: 2978   score: 8.0   memory length: 762827   epsilon: 0.34380028001424545    steps: 389     evaluation reward: 8.25\n",
            "episode: 2979   score: 7.0   memory length: 763213   epsilon: 0.34341814001425375    steps: 386     evaluation reward: 8.22\n",
            "episode: 2980   score: 5.0   memory length: 763503   epsilon: 0.34313104001426    steps: 290     evaluation reward: 8.22\n",
            "episode: 2981   score: 8.0   memory length: 763943   epsilon: 0.34269544001426944    steps: 440     evaluation reward: 8.19\n",
            "episode: 2982   score: 5.0   memory length: 764274   epsilon: 0.34236775001427655    steps: 331     evaluation reward: 8.17\n",
            "episode: 2983   score: 5.0   memory length: 764560   epsilon: 0.3420846100142827    steps: 286     evaluation reward: 8.16\n",
            "episode: 2984   score: 5.0   memory length: 764871   epsilon: 0.3417767200142894    steps: 311     evaluation reward: 8.16\n",
            "episode: 2985   score: 5.0   memory length: 765201   epsilon: 0.3414500200142965    steps: 330     evaluation reward: 8.13\n",
            "episode: 2986   score: 10.0   memory length: 765584   epsilon: 0.3410708500143047    steps: 383     evaluation reward: 8.18\n",
            "episode: 2987   score: 10.0   memory length: 765962   epsilon: 0.34069663001431283    steps: 378     evaluation reward: 8.21\n",
            "episode: 2988   score: 12.0   memory length: 766409   epsilon: 0.34025410001432244    steps: 447     evaluation reward: 8.2\n",
            "episode: 2989   score: 9.0   memory length: 766767   epsilon: 0.33989968001433013    steps: 358     evaluation reward: 8.11\n",
            "episode: 2990   score: 5.0   memory length: 767053   epsilon: 0.3396165400143363    steps: 286     evaluation reward: 8.05\n",
            "episode: 2991   score: 3.0   memory length: 767265   epsilon: 0.33940666001434083    steps: 212     evaluation reward: 8.02\n",
            "episode: 2992   score: 9.0   memory length: 767740   epsilon: 0.33893641001435104    steps: 475     evaluation reward: 8.04\n",
            "episode: 2993   score: 7.0   memory length: 768134   epsilon: 0.3385463500143595    steps: 394     evaluation reward: 8.02\n",
            "episode: 2994   score: 10.0   memory length: 768623   epsilon: 0.33806224001437    steps: 489     evaluation reward: 7.98\n",
            "episode: 2995   score: 6.0   memory length: 768965   epsilon: 0.33772366001437737    steps: 342     evaluation reward: 8.01\n",
            "episode: 2996   score: 8.0   memory length: 769379   epsilon: 0.33731380001438627    steps: 414     evaluation reward: 7.98\n",
            "episode: 2997   score: 9.0   memory length: 769736   epsilon: 0.33696037001439394    steps: 357     evaluation reward: 7.97\n",
            "episode: 2998   score: 7.0   memory length: 770134   epsilon: 0.3365663500144025    steps: 398     evaluation reward: 7.91\n",
            "episode: 2999   score: 5.0   memory length: 770438   epsilon: 0.336265390014409    steps: 304     evaluation reward: 7.92\n",
            "episode: 3000   score: 6.0   memory length: 770762   epsilon: 0.335944630014416    steps: 324     evaluation reward: 7.84\n",
            "episode: 3001   score: 7.0   memory length: 771185   epsilon: 0.3355258600144251    steps: 423     evaluation reward: 7.83\n",
            "episode: 3002   score: 8.0   memory length: 771671   epsilon: 0.3350447200144355    steps: 486     evaluation reward: 7.88\n",
            "episode: 3003   score: 9.0   memory length: 772007   epsilon: 0.33471208001444275    steps: 336     evaluation reward: 7.92\n",
            "episode: 3004   score: 11.0   memory length: 772412   epsilon: 0.33431113001445145    steps: 405     evaluation reward: 7.96\n",
            "episode: 3005   score: 12.0   memory length: 772732   epsilon: 0.33399433001445833    steps: 320     evaluation reward: 7.98\n",
            "episode: 3006   score: 20.0   memory length: 773362   epsilon: 0.33337063001447187    steps: 630     evaluation reward: 8.05\n",
            "episode: 3007   score: 5.0   memory length: 773687   epsilon: 0.33304888001447885    steps: 325     evaluation reward: 8.0\n",
            "episode: 3008   score: 9.0   memory length: 774011   epsilon: 0.3327281200144858    steps: 324     evaluation reward: 7.99\n",
            "episode: 3009   score: 12.0   memory length: 774472   epsilon: 0.3322717300144957    steps: 461     evaluation reward: 8.06\n",
            "episode: 3010   score: 4.0   memory length: 774755   epsilon: 0.3319915600145018    steps: 283     evaluation reward: 7.98\n",
            "episode: 3011   score: 5.0   memory length: 775103   epsilon: 0.3316470400145093    steps: 348     evaluation reward: 7.92\n",
            "episode: 3012   score: 8.0   memory length: 775553   epsilon: 0.33120154001451896    steps: 450     evaluation reward: 7.91\n",
            "episode: 3013   score: 11.0   memory length: 775955   epsilon: 0.3308035600145276    steps: 402     evaluation reward: 7.87\n",
            "episode: 3014   score: 12.0   memory length: 776395   epsilon: 0.33036796001453705    steps: 440     evaluation reward: 7.94\n",
            "episode: 3015   score: 5.0   memory length: 776703   epsilon: 0.3300630400145437    steps: 308     evaluation reward: 7.89\n",
            "episode: 3016   score: 16.0   memory length: 777256   epsilon: 0.32951557001455556    steps: 553     evaluation reward: 8.0\n",
            "episode: 3017   score: 11.0   memory length: 777821   epsilon: 0.3289562200145677    steps: 565     evaluation reward: 7.99\n",
            "episode: 3018   score: 4.0   memory length: 778098   epsilon: 0.32868199001457366    steps: 277     evaluation reward: 7.92\n",
            "episode: 3019   score: 5.0   memory length: 778426   epsilon: 0.3283572700145807    steps: 328     evaluation reward: 7.95\n",
            "episode: 3020   score: 6.0   memory length: 778794   epsilon: 0.3279929500145886    steps: 368     evaluation reward: 7.9\n",
            "episode: 3021   score: 7.0   memory length: 779158   epsilon: 0.32763259001459644    steps: 364     evaluation reward: 7.85\n",
            "episode: 3022   score: 6.0   memory length: 779502   epsilon: 0.32729203001460383    steps: 344     evaluation reward: 7.79\n",
            "episode: 3023   score: 10.0   memory length: 779990   epsilon: 0.3268089100146143    steps: 488     evaluation reward: 7.79\n",
            "episode: 3024   score: 8.0   memory length: 780369   epsilon: 0.32643370001462246    steps: 379     evaluation reward: 7.83\n",
            "episode: 3025   score: 12.0   memory length: 780820   epsilon: 0.32598721001463216    steps: 451     evaluation reward: 7.86\n",
            "episode: 3026   score: 9.0   memory length: 781289   epsilon: 0.32552290001464224    steps: 469     evaluation reward: 7.89\n",
            "episode: 3027   score: 3.0   memory length: 781518   epsilon: 0.32529619001464716    steps: 229     evaluation reward: 7.84\n",
            "episode: 3028   score: 5.0   memory length: 781857   epsilon: 0.32496058001465444    steps: 339     evaluation reward: 7.81\n",
            "episode: 3029   score: 5.0   memory length: 782174   epsilon: 0.32464675001466126    steps: 317     evaluation reward: 7.8\n",
            "episode: 3030   score: 8.0   memory length: 782568   epsilon: 0.3242566900146697    steps: 394     evaluation reward: 7.8\n",
            "episode: 3031   score: 9.0   memory length: 782995   epsilon: 0.3238339600146789    steps: 427     evaluation reward: 7.83\n",
            "episode: 3032   score: 5.0   memory length: 783288   epsilon: 0.3235438900146852    steps: 293     evaluation reward: 7.84\n",
            "episode: 3033   score: 7.0   memory length: 783678   epsilon: 0.3231577900146936    steps: 390     evaluation reward: 7.86\n",
            "episode: 3034   score: 10.0   memory length: 784163   epsilon: 0.322677640014704    steps: 485     evaluation reward: 7.79\n",
            "episode: 3035   score: 6.0   memory length: 784506   epsilon: 0.3223380700147114    steps: 343     evaluation reward: 7.77\n",
            "episode: 3036   score: 9.0   memory length: 784966   epsilon: 0.32188267001472126    steps: 460     evaluation reward: 7.81\n",
            "episode: 3037   score: 7.0   memory length: 785347   epsilon: 0.32150548001472945    steps: 381     evaluation reward: 7.74\n",
            "episode: 3038   score: 4.0   memory length: 785629   epsilon: 0.3212263000147355    steps: 282     evaluation reward: 7.71\n",
            "episode: 3039   score: 8.0   memory length: 786070   epsilon: 0.320789710014745    steps: 441     evaluation reward: 7.73\n",
            "episode: 3040   score: 7.0   memory length: 786457   epsilon: 0.3204065800147533    steps: 387     evaluation reward: 7.77\n",
            "episode: 3041   score: 9.0   memory length: 786890   epsilon: 0.3199779100147626    steps: 433     evaluation reward: 7.81\n",
            "episode: 3042   score: 6.0   memory length: 787250   epsilon: 0.31962151001477035    steps: 360     evaluation reward: 7.81\n",
            "episode: 3043   score: 12.0   memory length: 787725   epsilon: 0.31915126001478056    steps: 475     evaluation reward: 7.85\n",
            "episode: 3044   score: 7.0   memory length: 788071   epsilon: 0.318808720014788    steps: 346     evaluation reward: 7.89\n",
            "episode: 3045   score: 12.0   memory length: 788553   epsilon: 0.31833154001479835    steps: 482     evaluation reward: 7.92\n",
            "episode: 3046   score: 8.0   memory length: 789010   epsilon: 0.3178791100148082    steps: 457     evaluation reward: 7.96\n",
            "episode: 3047   score: 8.0   memory length: 789444   epsilon: 0.3174494500148175    steps: 434     evaluation reward: 7.99\n",
            "episode: 3048   score: 12.0   memory length: 789895   epsilon: 0.3170029600148272    steps: 451     evaluation reward: 8.01\n",
            "episode: 3049   score: 3.0   memory length: 790124   epsilon: 0.3167762500148321    steps: 229     evaluation reward: 7.95\n",
            "episode: 3050   score: 9.0   memory length: 790624   epsilon: 0.31628125001484286    steps: 500     evaluation reward: 7.96\n",
            "episode: 3051   score: 13.0   memory length: 791245   epsilon: 0.3156664600148562    steps: 621     evaluation reward: 8.0\n",
            "episode: 3052   score: 10.0   memory length: 791697   epsilon: 0.3152189800148659    steps: 452     evaluation reward: 8.02\n",
            "episode: 3053   score: 8.0   memory length: 792120   epsilon: 0.314800210014875    steps: 423     evaluation reward: 8.06\n",
            "episode: 3054   score: 10.0   memory length: 792641   epsilon: 0.3142844200148862    steps: 521     evaluation reward: 8.03\n",
            "episode: 3055   score: 8.0   memory length: 793099   epsilon: 0.31383100001489606    steps: 458     evaluation reward: 8.05\n",
            "episode: 3056   score: 12.0   memory length: 793644   epsilon: 0.31329145001490777    steps: 545     evaluation reward: 8.07\n",
            "episode: 3057   score: 9.0   memory length: 793978   epsilon: 0.31296079001491495    steps: 334     evaluation reward: 8.06\n",
            "episode: 3058   score: 7.0   memory length: 794365   epsilon: 0.31257766001492326    steps: 387     evaluation reward: 8.09\n",
            "episode: 3059   score: 11.0   memory length: 794768   epsilon: 0.3121786900149319    steps: 403     evaluation reward: 8.17\n",
            "episode: 3060   score: 8.0   memory length: 795202   epsilon: 0.31174903001494125    steps: 434     evaluation reward: 8.16\n",
            "episode: 3061   score: 12.0   memory length: 795746   epsilon: 0.31121047001495294    steps: 544     evaluation reward: 8.15\n",
            "episode: 3062   score: 4.0   memory length: 796014   epsilon: 0.3109451500149587    steps: 268     evaluation reward: 8.14\n",
            "episode: 3063   score: 14.0   memory length: 796581   epsilon: 0.3103838200149709    steps: 567     evaluation reward: 8.2\n",
            "episode: 3064   score: 9.0   memory length: 796958   epsilon: 0.310010590014979    steps: 377     evaluation reward: 8.18\n",
            "episode: 3065   score: 5.0   memory length: 797303   epsilon: 0.3096690400149864    steps: 345     evaluation reward: 8.09\n",
            "episode: 3066   score: 11.0   memory length: 797847   epsilon: 0.3091304800149981    steps: 544     evaluation reward: 8.09\n",
            "episode: 3067   score: 6.0   memory length: 798225   epsilon: 0.3087562600150062    steps: 378     evaluation reward: 8.07\n",
            "episode: 3068   score: 10.0   memory length: 798605   epsilon: 0.3083800600150144    steps: 380     evaluation reward: 8.11\n",
            "episode: 3069   score: 10.0   memory length: 799095   epsilon: 0.3078949600150249    steps: 490     evaluation reward: 8.17\n",
            "episode: 3070   score: 9.0   memory length: 799548   epsilon: 0.30744649001503466    steps: 453     evaluation reward: 8.18\n",
            "episode: 3071   score: 14.0   memory length: 799919   epsilon: 0.30707920001504263    steps: 371     evaluation reward: 8.27\n",
            "now time :  2019-12-12 22:58:03.324148\n",
            "episode: 3072   score: 7.0   memory length: 800314   epsilon: 0.3066881500150511    steps: 395     evaluation reward: 8.23\n",
            "episode: 3073   score: 14.0   memory length: 800848   epsilon: 0.3061594900150626    steps: 534     evaluation reward: 8.33\n",
            "episode: 3074   score: 10.0   memory length: 801207   epsilon: 0.3058040800150703    steps: 359     evaluation reward: 8.36\n",
            "episode: 3075   score: 4.0   memory length: 801470   epsilon: 0.30554371001507596    steps: 263     evaluation reward: 8.32\n",
            "episode: 3076   score: 7.0   memory length: 801828   epsilon: 0.30518929001508366    steps: 358     evaluation reward: 8.3\n",
            "episode: 3077   score: 9.0   memory length: 802279   epsilon: 0.30474280001509335    steps: 451     evaluation reward: 8.26\n",
            "episode: 3078   score: 4.0   memory length: 802527   epsilon: 0.3044972800150987    steps: 248     evaluation reward: 8.22\n",
            "episode: 3079   score: 14.0   memory length: 803057   epsilon: 0.30397258001511007    steps: 530     evaluation reward: 8.29\n",
            "episode: 3080   score: 9.0   memory length: 803471   epsilon: 0.30356272001511897    steps: 414     evaluation reward: 8.33\n",
            "episode: 3081   score: 15.0   memory length: 804012   epsilon: 0.3030271300151306    steps: 541     evaluation reward: 8.4\n",
            "episode: 3082   score: 9.0   memory length: 804513   epsilon: 0.30253114001514136    steps: 501     evaluation reward: 8.44\n",
            "episode: 3083   score: 8.0   memory length: 804827   epsilon: 0.3022202800151481    steps: 314     evaluation reward: 8.47\n",
            "episode: 3084   score: 12.0   memory length: 805316   epsilon: 0.3017361700151586    steps: 489     evaluation reward: 8.54\n",
            "episode: 3085   score: 13.0   memory length: 805782   epsilon: 0.30127483001516864    steps: 466     evaluation reward: 8.62\n",
            "episode: 3086   score: 10.0   memory length: 806304   epsilon: 0.30075805001517986    steps: 522     evaluation reward: 8.62\n",
            "episode: 3087   score: 7.0   memory length: 806696   epsilon: 0.3003699700151883    steps: 392     evaluation reward: 8.59\n",
            "episode: 3088   score: 7.0   memory length: 807107   epsilon: 0.2999630800151971    steps: 411     evaluation reward: 8.54\n",
            "episode: 3089   score: 12.0   memory length: 807519   epsilon: 0.29955520001520597    steps: 412     evaluation reward: 8.57\n",
            "episode: 3090   score: 8.0   memory length: 807845   epsilon: 0.299232460015213    steps: 326     evaluation reward: 8.6\n",
            "episode: 3091   score: 8.0   memory length: 808314   epsilon: 0.29876815001522306    steps: 469     evaluation reward: 8.65\n",
            "episode: 3092   score: 8.0   memory length: 808795   epsilon: 0.2982919600152334    steps: 481     evaluation reward: 8.64\n",
            "episode: 3093   score: 5.0   memory length: 809073   epsilon: 0.29801674001523937    steps: 278     evaluation reward: 8.62\n",
            "episode: 3094   score: 7.0   memory length: 809448   epsilon: 0.2976454900152474    steps: 375     evaluation reward: 8.59\n",
            "episode: 3095   score: 14.0   memory length: 809833   epsilon: 0.2972643400152557    steps: 385     evaluation reward: 8.67\n",
            "episode: 3096   score: 10.0   memory length: 810218   epsilon: 0.296883190015264    steps: 385     evaluation reward: 8.69\n",
            "episode: 3097   score: 4.0   memory length: 810497   epsilon: 0.29660698001526997    steps: 279     evaluation reward: 8.64\n",
            "episode: 3098   score: 11.0   memory length: 811106   epsilon: 0.29600407001528306    steps: 609     evaluation reward: 8.68\n",
            "episode: 3099   score: 8.0   memory length: 811395   epsilon: 0.29571796001528927    steps: 289     evaluation reward: 8.71\n",
            "episode: 3100   score: 7.0   memory length: 811790   epsilon: 0.29532691001529776    steps: 395     evaluation reward: 8.72\n",
            "episode: 3101   score: 10.0   memory length: 812253   epsilon: 0.2948685400153077    steps: 463     evaluation reward: 8.75\n",
            "episode: 3102   score: 6.0   memory length: 812620   epsilon: 0.2945052100153156    steps: 367     evaluation reward: 8.73\n",
            "episode: 3103   score: 6.0   memory length: 813003   epsilon: 0.29412604001532383    steps: 383     evaluation reward: 8.7\n",
            "episode: 3104   score: 13.0   memory length: 813340   epsilon: 0.2937924100153311    steps: 337     evaluation reward: 8.72\n",
            "episode: 3105   score: 15.0   memory length: 813760   epsilon: 0.2933766100153401    steps: 420     evaluation reward: 8.75\n",
            "episode: 3106   score: 5.0   memory length: 814060   epsilon: 0.29307961001534655    steps: 300     evaluation reward: 8.6\n",
            "episode: 3107   score: 11.0   memory length: 814511   epsilon: 0.29263312001535624    steps: 451     evaluation reward: 8.66\n",
            "episode: 3108   score: 8.0   memory length: 814971   epsilon: 0.2921777200153661    steps: 460     evaluation reward: 8.65\n",
            "episode: 3109   score: 4.0   memory length: 815241   epsilon: 0.29191042001537193    steps: 270     evaluation reward: 8.57\n",
            "episode: 3110   score: 7.0   memory length: 815641   epsilon: 0.2915144200153805    steps: 400     evaluation reward: 8.6\n",
            "episode: 3111   score: 5.0   memory length: 815915   epsilon: 0.2912431600153864    steps: 274     evaluation reward: 8.6\n",
            "episode: 3112   score: 5.0   memory length: 816238   epsilon: 0.29092339001539336    steps: 323     evaluation reward: 8.57\n",
            "episode: 3113   score: 6.0   memory length: 816582   epsilon: 0.29058283001540075    steps: 344     evaluation reward: 8.52\n",
            "episode: 3114   score: 6.0   memory length: 816914   epsilon: 0.2902541500154079    steps: 332     evaluation reward: 8.46\n",
            "episode: 3115   score: 11.0   memory length: 817345   epsilon: 0.28982746001541715    steps: 431     evaluation reward: 8.52\n",
            "episode: 3116   score: 5.0   memory length: 817650   epsilon: 0.2895255100154237    steps: 305     evaluation reward: 8.41\n",
            "episode: 3117   score: 5.0   memory length: 817963   epsilon: 0.28921564001543043    steps: 313     evaluation reward: 8.35\n",
            "episode: 3118   score: 6.0   memory length: 818321   epsilon: 0.2888612200154381    steps: 358     evaluation reward: 8.37\n",
            "episode: 3119   score: 3.0   memory length: 818536   epsilon: 0.28864837001544275    steps: 215     evaluation reward: 8.35\n",
            "episode: 3120   score: 13.0   memory length: 819028   epsilon: 0.2881612900154533    steps: 492     evaluation reward: 8.42\n",
            "episode: 3121   score: 12.0   memory length: 819647   epsilon: 0.2875484800154666    steps: 619     evaluation reward: 8.47\n",
            "episode: 3122   score: 22.0   memory length: 820057   epsilon: 0.28714258001547543    steps: 410     evaluation reward: 8.63\n",
            "episode: 3123   score: 4.0   memory length: 820317   epsilon: 0.286885180015481    steps: 260     evaluation reward: 8.57\n",
            "episode: 3124   score: 13.0   memory length: 820693   epsilon: 0.2865129400154891    steps: 376     evaluation reward: 8.62\n",
            "episode: 3125   score: 13.0   memory length: 821209   epsilon: 0.2860021000155002    steps: 516     evaluation reward: 8.63\n",
            "episode: 3126   score: 4.0   memory length: 821471   epsilon: 0.2857427200155058    steps: 262     evaluation reward: 8.58\n",
            "episode: 3127   score: 10.0   memory length: 821863   epsilon: 0.28535464001551425    steps: 392     evaluation reward: 8.65\n",
            "episode: 3128   score: 6.0   memory length: 822174   epsilon: 0.28504675001552093    steps: 311     evaluation reward: 8.66\n",
            "episode: 3129   score: 11.0   memory length: 822585   epsilon: 0.28463986001552977    steps: 411     evaluation reward: 8.72\n",
            "episode: 3130   score: 3.0   memory length: 822824   epsilon: 0.2844032500155349    steps: 239     evaluation reward: 8.67\n",
            "episode: 3131   score: 6.0   memory length: 823174   epsilon: 0.2840567500155424    steps: 350     evaluation reward: 8.64\n",
            "episode: 3132   score: 7.0   memory length: 823568   epsilon: 0.2836666900155509    steps: 394     evaluation reward: 8.66\n",
            "episode: 3133   score: 6.0   memory length: 823890   epsilon: 0.2833479100155578    steps: 322     evaluation reward: 8.65\n",
            "episode: 3134   score: 7.0   memory length: 824255   epsilon: 0.28298656001556566    steps: 365     evaluation reward: 8.62\n",
            "episode: 3135   score: 7.0   memory length: 824651   epsilon: 0.28259452001557417    steps: 396     evaluation reward: 8.63\n",
            "episode: 3136   score: 13.0   memory length: 824993   epsilon: 0.2822559400155815    steps: 342     evaluation reward: 8.67\n",
            "episode: 3137   score: 5.0   memory length: 825301   epsilon: 0.28195102001558814    steps: 308     evaluation reward: 8.65\n",
            "episode: 3138   score: 20.0   memory length: 825671   epsilon: 0.2815847200155961    steps: 370     evaluation reward: 8.81\n",
            "episode: 3139   score: 8.0   memory length: 826056   epsilon: 0.28120357001560436    steps: 385     evaluation reward: 8.81\n",
            "episode: 3140   score: 5.0   memory length: 826370   epsilon: 0.2808927100156111    steps: 314     evaluation reward: 8.79\n",
            "episode: 3141   score: 4.0   memory length: 826632   epsilon: 0.28063333001561674    steps: 262     evaluation reward: 8.74\n",
            "episode: 3142   score: 10.0   memory length: 827117   epsilon: 0.28015318001562717    steps: 485     evaluation reward: 8.78\n",
            "episode: 3143   score: 5.0   memory length: 827442   epsilon: 0.27983143001563415    steps: 325     evaluation reward: 8.71\n",
            "episode: 3144   score: 8.0   memory length: 827867   epsilon: 0.2794106800156433    steps: 425     evaluation reward: 8.72\n",
            "episode: 3145   score: 5.0   memory length: 828188   epsilon: 0.2790928900156502    steps: 321     evaluation reward: 8.65\n",
            "episode: 3146   score: 8.0   memory length: 828659   epsilon: 0.2786266000156603    steps: 471     evaluation reward: 8.65\n",
            "episode: 3147   score: 7.0   memory length: 829039   epsilon: 0.2782504000156685    steps: 380     evaluation reward: 8.64\n",
            "episode: 3148   score: 9.0   memory length: 829499   epsilon: 0.27779500001567836    steps: 460     evaluation reward: 8.61\n",
            "episode: 3149   score: 7.0   memory length: 829885   epsilon: 0.27741286001568666    steps: 386     evaluation reward: 8.65\n",
            "episode: 3150   score: 5.0   memory length: 830175   epsilon: 0.2771257600156929    steps: 290     evaluation reward: 8.61\n",
            "episode: 3151   score: 5.0   memory length: 830470   epsilon: 0.27683371001569923    steps: 295     evaluation reward: 8.53\n",
            "episode: 3152   score: 11.0   memory length: 830895   epsilon: 0.27641296001570836    steps: 425     evaluation reward: 8.54\n",
            "episode: 3153   score: 15.0   memory length: 831469   epsilon: 0.2758447000157207    steps: 574     evaluation reward: 8.61\n",
            "episode: 3154   score: 4.0   memory length: 831717   epsilon: 0.27559918001572603    steps: 248     evaluation reward: 8.55\n",
            "episode: 3155   score: 6.0   memory length: 832034   epsilon: 0.27528535001573284    steps: 317     evaluation reward: 8.53\n",
            "episode: 3156   score: 12.0   memory length: 832599   epsilon: 0.274726000015745    steps: 565     evaluation reward: 8.53\n",
            "episode: 3157   score: 7.0   memory length: 833023   epsilon: 0.2743062400157541    steps: 424     evaluation reward: 8.51\n",
            "episode: 3158   score: 5.0   memory length: 833335   epsilon: 0.2739973600157608    steps: 312     evaluation reward: 8.49\n",
            "episode: 3159   score: 6.0   memory length: 833637   epsilon: 0.2736983800157673    steps: 302     evaluation reward: 8.44\n",
            "episode: 3160   score: 5.0   memory length: 833931   epsilon: 0.2734073200157736    steps: 294     evaluation reward: 8.41\n",
            "episode: 3161   score: 2.0   memory length: 834113   epsilon: 0.2732271400157775    steps: 182     evaluation reward: 8.31\n",
            "episode: 3162   score: 5.0   memory length: 834423   epsilon: 0.2729202400157842    steps: 310     evaluation reward: 8.32\n",
            "episode: 3163   score: 5.0   memory length: 834690   epsilon: 0.2726559100157899    steps: 267     evaluation reward: 8.23\n",
            "episode: 3164   score: 9.0   memory length: 835157   epsilon: 0.27219358001579996    steps: 467     evaluation reward: 8.23\n",
            "episode: 3165   score: 5.0   memory length: 835446   epsilon: 0.2719074700158062    steps: 289     evaluation reward: 8.23\n",
            "episode: 3166   score: 6.0   memory length: 835809   epsilon: 0.271548100015814    steps: 363     evaluation reward: 8.18\n",
            "episode: 3167   score: 8.0   memory length: 836251   epsilon: 0.2711105200158235    steps: 442     evaluation reward: 8.2\n",
            "episode: 3168   score: 8.0   memory length: 836673   epsilon: 0.27069274001583254    steps: 422     evaluation reward: 8.18\n",
            "episode: 3169   score: 4.0   memory length: 836933   epsilon: 0.27043534001583813    steps: 260     evaluation reward: 8.12\n",
            "episode: 3170   score: 5.0   memory length: 837249   epsilon: 0.2701225000158449    steps: 316     evaluation reward: 8.08\n",
            "episode: 3171   score: 6.0   memory length: 837610   epsilon: 0.2697651100158527    steps: 361     evaluation reward: 8.0\n",
            "episode: 3172   score: 6.0   memory length: 837985   epsilon: 0.26939386001586074    steps: 375     evaluation reward: 7.99\n",
            "episode: 3173   score: 10.0   memory length: 838359   epsilon: 0.2690236000158688    steps: 374     evaluation reward: 7.95\n",
            "episode: 3174   score: 4.0   memory length: 838627   epsilon: 0.26875828001587454    steps: 268     evaluation reward: 7.89\n",
            "episode: 3175   score: 6.0   memory length: 839013   epsilon: 0.26837614001588284    steps: 386     evaluation reward: 7.91\n",
            "episode: 3176   score: 7.0   memory length: 839417   epsilon: 0.2679761800158915    steps: 404     evaluation reward: 7.91\n",
            "episode: 3177   score: 5.0   memory length: 839714   epsilon: 0.2676821500158979    steps: 297     evaluation reward: 7.87\n",
            "episode: 3178   score: 4.0   memory length: 839979   epsilon: 0.2674198000159036    steps: 265     evaluation reward: 7.87\n",
            "episode: 3179   score: 6.0   memory length: 840358   epsilon: 0.26704459001591174    steps: 379     evaluation reward: 7.79\n",
            "episode: 3180   score: 10.0   memory length: 840831   epsilon: 0.2665763200159219    steps: 473     evaluation reward: 7.8\n",
            "episode: 3181   score: 7.0   memory length: 841229   epsilon: 0.26618230001593046    steps: 398     evaluation reward: 7.72\n",
            "episode: 3182   score: 7.0   memory length: 841623   epsilon: 0.26579224001593893    steps: 394     evaluation reward: 7.7\n",
            "episode: 3183   score: 14.0   memory length: 842027   epsilon: 0.2653922800159476    steps: 404     evaluation reward: 7.76\n",
            "episode: 3184   score: 5.0   memory length: 842320   epsilon: 0.2651022100159539    steps: 293     evaluation reward: 7.69\n",
            "episode: 3185   score: 9.0   memory length: 842823   epsilon: 0.2646042400159647    steps: 503     evaluation reward: 7.65\n",
            "episode: 3186   score: 10.0   memory length: 843318   epsilon: 0.26411419001597536    steps: 495     evaluation reward: 7.65\n",
            "episode: 3187   score: 12.0   memory length: 843775   epsilon: 0.2636617600159852    steps: 457     evaluation reward: 7.7\n",
            "episode: 3188   score: 10.0   memory length: 844184   epsilon: 0.26325685001599397    steps: 409     evaluation reward: 7.73\n",
            "episode: 3189   score: 11.0   memory length: 844607   epsilon: 0.26283808001600306    steps: 423     evaluation reward: 7.72\n",
            "episode: 3190   score: 4.0   memory length: 844882   epsilon: 0.26256583001600897    steps: 275     evaluation reward: 7.68\n",
            "episode: 3191   score: 9.0   memory length: 845327   epsilon: 0.26212528001601854    steps: 445     evaluation reward: 7.69\n",
            "episode: 3192   score: 10.0   memory length: 845843   epsilon: 0.2616144400160296    steps: 516     evaluation reward: 7.71\n",
            "episode: 3193   score: 7.0   memory length: 846215   epsilon: 0.2612461600160376    steps: 372     evaluation reward: 7.73\n",
            "episode: 3194   score: 7.0   memory length: 846461   epsilon: 0.2610026200160429    steps: 246     evaluation reward: 7.73\n",
            "episode: 3195   score: 4.0   memory length: 846740   epsilon: 0.2607264100160489    steps: 279     evaluation reward: 7.63\n",
            "episode: 3196   score: 10.0   memory length: 847237   epsilon: 0.2602343800160596    steps: 497     evaluation reward: 7.63\n",
            "episode: 3197   score: 14.0   memory length: 847740   epsilon: 0.2597364100160704    steps: 503     evaluation reward: 7.73\n",
            "episode: 3198   score: 8.0   memory length: 848163   epsilon: 0.2593176400160795    steps: 423     evaluation reward: 7.7\n",
            "episode: 3199   score: 15.0   memory length: 848570   epsilon: 0.25891471001608823    steps: 407     evaluation reward: 7.77\n",
            "episode: 3200   score: 9.0   memory length: 849040   epsilon: 0.25844941001609834    steps: 470     evaluation reward: 7.79\n",
            "episode: 3201   score: 13.0   memory length: 849438   epsilon: 0.2580553900161069    steps: 398     evaluation reward: 7.82\n",
            "episode: 3202   score: 8.0   memory length: 849896   epsilon: 0.25760197001611673    steps: 458     evaluation reward: 7.84\n",
            "now time :  2019-12-12 23:25:11.668967\n",
            "episode: 3203   score: 5.0   memory length: 850219   epsilon: 0.2572822000161237    steps: 323     evaluation reward: 7.83\n",
            "episode: 3204   score: 6.0   memory length: 850584   epsilon: 0.2569208500161315    steps: 365     evaluation reward: 7.76\n",
            "episode: 3205   score: 5.0   memory length: 850907   epsilon: 0.25660108001613846    steps: 323     evaluation reward: 7.66\n",
            "episode: 3206   score: 11.0   memory length: 851334   epsilon: 0.25617835001614764    steps: 427     evaluation reward: 7.72\n",
            "episode: 3207   score: 10.0   memory length: 851730   epsilon: 0.25578631001615615    steps: 396     evaluation reward: 7.71\n",
            "episode: 3208   score: 7.0   memory length: 852118   epsilon: 0.2554021900161645    steps: 388     evaluation reward: 7.7\n",
            "episode: 3209   score: 10.0   memory length: 852641   epsilon: 0.25488442001617573    steps: 523     evaluation reward: 7.76\n",
            "episode: 3210   score: 9.0   memory length: 852988   epsilon: 0.2545408900161832    steps: 347     evaluation reward: 7.78\n",
            "episode: 3211   score: 7.0   memory length: 853244   epsilon: 0.2542874500161887    steps: 256     evaluation reward: 7.8\n",
            "episode: 3212   score: 7.0   memory length: 853623   epsilon: 0.25391224001619683    steps: 379     evaluation reward: 7.82\n",
            "episode: 3213   score: 8.0   memory length: 853903   epsilon: 0.25363504001620285    steps: 280     evaluation reward: 7.84\n",
            "episode: 3214   score: 7.0   memory length: 854279   epsilon: 0.25326280001621093    steps: 376     evaluation reward: 7.85\n",
            "episode: 3215   score: 8.0   memory length: 854555   epsilon: 0.25298956001621686    steps: 276     evaluation reward: 7.82\n",
            "episode: 3216   score: 5.0   memory length: 854843   epsilon: 0.25270444001622305    steps: 288     evaluation reward: 7.82\n",
            "episode: 3217   score: 11.0   memory length: 855296   epsilon: 0.2522559700162328    steps: 453     evaluation reward: 7.88\n",
            "episode: 3218   score: 10.0   memory length: 855679   epsilon: 0.251876800016241    steps: 383     evaluation reward: 7.92\n",
            "episode: 3219   score: 6.0   memory length: 856029   epsilon: 0.25153030001624854    steps: 350     evaluation reward: 7.95\n",
            "episode: 3220   score: 7.0   memory length: 856412   epsilon: 0.2511511300162568    steps: 383     evaluation reward: 7.89\n",
            "episode: 3221   score: 14.0   memory length: 856805   epsilon: 0.2507620600162652    steps: 393     evaluation reward: 7.91\n",
            "episode: 3222   score: 4.0   memory length: 857068   epsilon: 0.2505016900162709    steps: 263     evaluation reward: 7.73\n",
            "episode: 3223   score: 23.0   memory length: 857540   epsilon: 0.250034410016281    steps: 472     evaluation reward: 7.92\n",
            "episode: 3224   score: 8.0   memory length: 857996   epsilon: 0.2495829700162791    steps: 456     evaluation reward: 7.87\n",
            "episode: 3225   score: 5.0   memory length: 858288   epsilon: 0.24929389001627728    steps: 292     evaluation reward: 7.79\n",
            "episode: 3226   score: 7.0   memory length: 858632   epsilon: 0.24895333001627512    steps: 344     evaluation reward: 7.82\n",
            "episode: 3227   score: 8.0   memory length: 859118   epsilon: 0.24847219001627208    steps: 486     evaluation reward: 7.8\n",
            "episode: 3228   score: 12.0   memory length: 859552   epsilon: 0.24804253001626936    steps: 434     evaluation reward: 7.86\n",
            "episode: 3229   score: 5.0   memory length: 859829   epsilon: 0.24776830001626762    steps: 277     evaluation reward: 7.8\n",
            "episode: 3230   score: 4.0   memory length: 860103   epsilon: 0.2474970400162659    steps: 274     evaluation reward: 7.81\n",
            "episode: 3231   score: 5.0   memory length: 860394   epsilon: 0.24720895001626408    steps: 291     evaluation reward: 7.8\n",
            "episode: 3232   score: 8.0   memory length: 860785   epsilon: 0.24682186001626163    steps: 391     evaluation reward: 7.81\n",
            "episode: 3233   score: 8.0   memory length: 861186   epsilon: 0.24642487001625912    steps: 401     evaluation reward: 7.83\n",
            "episode: 3234   score: 8.0   memory length: 861647   epsilon: 0.24596848001625624    steps: 461     evaluation reward: 7.84\n",
            "episode: 3235   score: 7.0   memory length: 862016   epsilon: 0.24560317001625392    steps: 369     evaluation reward: 7.84\n",
            "episode: 3236   score: 8.0   memory length: 862326   epsilon: 0.24529627001625198    steps: 310     evaluation reward: 7.79\n",
            "episode: 3237   score: 7.0   memory length: 862580   epsilon: 0.2450448100162504    steps: 254     evaluation reward: 7.81\n",
            "episode: 3238   score: 10.0   memory length: 863109   epsilon: 0.24452110001624708    steps: 529     evaluation reward: 7.71\n",
            "episode: 3239   score: 6.0   memory length: 863424   epsilon: 0.2442092500162451    steps: 315     evaluation reward: 7.69\n",
            "episode: 3240   score: 13.0   memory length: 863927   epsilon: 0.24371128001624195    steps: 503     evaluation reward: 7.77\n",
            "episode: 3241   score: 5.0   memory length: 864256   epsilon: 0.2433855700162399    steps: 329     evaluation reward: 7.78\n",
            "episode: 3242   score: 11.0   memory length: 864703   epsilon: 0.2429430400162371    steps: 447     evaluation reward: 7.79\n",
            "episode: 3243   score: 8.0   memory length: 865010   epsilon: 0.24263911001623517    steps: 307     evaluation reward: 7.82\n",
            "episode: 3244   score: 14.0   memory length: 865526   epsilon: 0.24212827001623194    steps: 516     evaluation reward: 7.88\n",
            "episode: 3245   score: 8.0   memory length: 865952   epsilon: 0.24170653001622927    steps: 426     evaluation reward: 7.91\n",
            "episode: 3246   score: 9.0   memory length: 866284   epsilon: 0.2413778500162272    steps: 332     evaluation reward: 7.92\n",
            "episode: 3247   score: 8.0   memory length: 866714   epsilon: 0.2409521500162245    steps: 430     evaluation reward: 7.93\n",
            "episode: 3248   score: 4.0   memory length: 867001   epsilon: 0.2406680200162227    steps: 287     evaluation reward: 7.88\n",
            "episode: 3249   score: 9.0   memory length: 867340   epsilon: 0.24033241001622058    steps: 339     evaluation reward: 7.9\n",
            "episode: 3250   score: 7.0   memory length: 867745   epsilon: 0.23993146001621804    steps: 405     evaluation reward: 7.92\n",
            "episode: 3251   score: 9.0   memory length: 868170   epsilon: 0.23951071001621538    steps: 425     evaluation reward: 7.96\n",
            "episode: 3252   score: 11.0   memory length: 868690   epsilon: 0.23899591001621212    steps: 520     evaluation reward: 7.96\n",
            "episode: 3253   score: 7.0   memory length: 868966   epsilon: 0.2387226700162104    steps: 276     evaluation reward: 7.88\n",
            "episode: 3254   score: 5.0   memory length: 869290   epsilon: 0.23840191001620836    steps: 324     evaluation reward: 7.89\n",
            "episode: 3255   score: 10.0   memory length: 869654   epsilon: 0.23804155001620608    steps: 364     evaluation reward: 7.93\n",
            "episode: 3256   score: 10.0   memory length: 870152   epsilon: 0.23754853001620296    steps: 498     evaluation reward: 7.91\n",
            "episode: 3257   score: 7.0   memory length: 870579   epsilon: 0.2371258000162003    steps: 427     evaluation reward: 7.91\n",
            "episode: 3258   score: 3.0   memory length: 870850   epsilon: 0.2368575100161986    steps: 271     evaluation reward: 7.89\n",
            "episode: 3259   score: 6.0   memory length: 871204   epsilon: 0.23650705001619637    steps: 354     evaluation reward: 7.89\n",
            "episode: 3260   score: 7.0   memory length: 871605   epsilon: 0.23611006001619386    steps: 401     evaluation reward: 7.91\n",
            "episode: 3261   score: 6.0   memory length: 871952   epsilon: 0.2357665300161917    steps: 347     evaluation reward: 7.95\n",
            "episode: 3262   score: 10.0   memory length: 872293   epsilon: 0.23542894001618955    steps: 341     evaluation reward: 8.0\n",
            "episode: 3263   score: 10.0   memory length: 872669   epsilon: 0.2350567000161872    steps: 376     evaluation reward: 8.05\n",
            "episode: 3264   score: 8.0   memory length: 873114   epsilon: 0.2346161500161844    steps: 445     evaluation reward: 8.04\n",
            "episode: 3265   score: 9.0   memory length: 873462   epsilon: 0.23427163001618223    steps: 348     evaluation reward: 8.08\n",
            "episode: 3266   score: 12.0   memory length: 873940   epsilon: 0.23379841001617924    steps: 478     evaluation reward: 8.14\n",
            "episode: 3267   score: 11.0   memory length: 874359   epsilon: 0.2333836000161766    steps: 419     evaluation reward: 8.17\n",
            "episode: 3268   score: 5.0   memory length: 874671   epsilon: 0.23307472001617466    steps: 312     evaluation reward: 8.14\n",
            "episode: 3269   score: 6.0   memory length: 875006   epsilon: 0.23274307001617256    steps: 335     evaluation reward: 8.16\n",
            "episode: 3270   score: 12.0   memory length: 875463   epsilon: 0.2322906400161697    steps: 457     evaluation reward: 8.23\n",
            "episode: 3271   score: 10.0   memory length: 875969   epsilon: 0.23178970001616653    steps: 506     evaluation reward: 8.27\n",
            "episode: 3272   score: 4.0   memory length: 876240   epsilon: 0.23152141001616483    steps: 271     evaluation reward: 8.25\n",
            "episode: 3273   score: 9.0   memory length: 876654   epsilon: 0.23111155001616224    steps: 414     evaluation reward: 8.24\n",
            "episode: 3274   score: 5.0   memory length: 877002   epsilon: 0.23076703001616006    steps: 348     evaluation reward: 8.25\n",
            "episode: 3275   score: 11.0   memory length: 877413   epsilon: 0.23036014001615748    steps: 411     evaluation reward: 8.3\n",
            "episode: 3276   score: 8.0   memory length: 877841   epsilon: 0.2299364200161548    steps: 428     evaluation reward: 8.31\n",
            "episode: 3277   score: 10.0   memory length: 878340   epsilon: 0.22944241001615168    steps: 499     evaluation reward: 8.36\n",
            "episode: 3278   score: 9.0   memory length: 878780   epsilon: 0.22900681001614892    steps: 440     evaluation reward: 8.41\n",
            "episode: 3279   score: 10.0   memory length: 879161   epsilon: 0.22862962001614653    steps: 381     evaluation reward: 8.45\n",
            "episode: 3280   score: 8.0   memory length: 879470   epsilon: 0.2283237100161446    steps: 309     evaluation reward: 8.43\n",
            "episode: 3281   score: 15.0   memory length: 879900   epsilon: 0.2278980100161419    steps: 430     evaluation reward: 8.51\n",
            "episode: 3282   score: 8.0   memory length: 880211   epsilon: 0.22759012001613996    steps: 311     evaluation reward: 8.52\n",
            "episode: 3283   score: 11.0   memory length: 880624   epsilon: 0.22718125001613737    steps: 413     evaluation reward: 8.49\n",
            "episode: 3284   score: 7.0   memory length: 881030   epsilon: 0.22677931001613483    steps: 406     evaluation reward: 8.51\n",
            "episode: 3285   score: 7.0   memory length: 881402   epsilon: 0.2264110300161325    steps: 372     evaluation reward: 8.49\n",
            "episode: 3286   score: 6.0   memory length: 881749   epsilon: 0.22606750001613032    steps: 347     evaluation reward: 8.45\n",
            "episode: 3287   score: 16.0   memory length: 882197   epsilon: 0.22562398001612752    steps: 448     evaluation reward: 8.49\n",
            "episode: 3288   score: 5.0   memory length: 882500   epsilon: 0.22532401001612562    steps: 303     evaluation reward: 8.44\n",
            "episode: 3289   score: 8.0   memory length: 882959   epsilon: 0.22486960001612274    steps: 459     evaluation reward: 8.41\n",
            "episode: 3290   score: 11.0   memory length: 883390   epsilon: 0.22444291001612005    steps: 431     evaluation reward: 8.48\n",
            "episode: 3291   score: 10.0   memory length: 883815   epsilon: 0.22402216001611738    steps: 425     evaluation reward: 8.49\n",
            "episode: 3292   score: 8.0   memory length: 884308   epsilon: 0.2235340900161143    steps: 493     evaluation reward: 8.47\n",
            "episode: 3293   score: 5.0   memory length: 884605   epsilon: 0.22324006001611243    steps: 297     evaluation reward: 8.45\n",
            "episode: 3294   score: 9.0   memory length: 885041   epsilon: 0.2228084200161097    steps: 436     evaluation reward: 8.47\n",
            "episode: 3295   score: 4.0   memory length: 885286   epsilon: 0.22256587001610817    steps: 245     evaluation reward: 8.47\n",
            "episode: 3296   score: 7.0   memory length: 885627   epsilon: 0.22222828001610603    steps: 341     evaluation reward: 8.44\n",
            "episode: 3297   score: 6.0   memory length: 885978   epsilon: 0.22188079001610383    steps: 351     evaluation reward: 8.36\n",
            "episode: 3298   score: 10.0   memory length: 886445   epsilon: 0.2214184600161009    steps: 467     evaluation reward: 8.38\n",
            "episode: 3299   score: 5.0   memory length: 886720   epsilon: 0.2211462100160992    steps: 275     evaluation reward: 8.28\n",
            "episode: 3300   score: 3.0   memory length: 886941   epsilon: 0.2209274200160978    steps: 221     evaluation reward: 8.22\n",
            "episode: 3301   score: 15.0   memory length: 887559   epsilon: 0.22031560001609393    steps: 618     evaluation reward: 8.24\n",
            "episode: 3302   score: 14.0   memory length: 888132   epsilon: 0.21974833001609034    steps: 573     evaluation reward: 8.3\n",
            "episode: 3303   score: 11.0   memory length: 888513   epsilon: 0.21937114001608796    steps: 381     evaluation reward: 8.36\n",
            "episode: 3304   score: 9.0   memory length: 888994   epsilon: 0.21889495001608494    steps: 481     evaluation reward: 8.39\n",
            "episode: 3305   score: 12.0   memory length: 889478   epsilon: 0.2184157900160819    steps: 484     evaluation reward: 8.46\n",
            "episode: 3306   score: 6.0   memory length: 889849   epsilon: 0.2180485000160796    steps: 371     evaluation reward: 8.41\n",
            "episode: 3307   score: 11.0   memory length: 890418   epsilon: 0.21748519001607602    steps: 569     evaluation reward: 8.42\n",
            "episode: 3308   score: 8.0   memory length: 890712   epsilon: 0.21719413001607418    steps: 294     evaluation reward: 8.43\n",
            "episode: 3309   score: 9.0   memory length: 891156   epsilon: 0.2167545700160714    steps: 444     evaluation reward: 8.42\n",
            "episode: 3310   score: 4.0   memory length: 891398   epsilon: 0.21651499001606989    steps: 242     evaluation reward: 8.37\n",
            "episode: 3311   score: 12.0   memory length: 891937   epsilon: 0.2159813800160665    steps: 539     evaluation reward: 8.42\n",
            "episode: 3312   score: 10.0   memory length: 892321   epsilon: 0.2156012200160641    steps: 384     evaluation reward: 8.45\n",
            "episode: 3313   score: 6.0   memory length: 892626   epsilon: 0.2152992700160622    steps: 305     evaluation reward: 8.43\n",
            "episode: 3314   score: 9.0   memory length: 893079   epsilon: 0.21485080001605936    steps: 453     evaluation reward: 8.45\n",
            "episode: 3315   score: 10.0   memory length: 893455   epsilon: 0.214478560016057    steps: 376     evaluation reward: 8.47\n",
            "episode: 3316   score: 5.0   memory length: 893762   epsilon: 0.21417463001605508    steps: 307     evaluation reward: 8.47\n",
            "episode: 3317   score: 9.0   memory length: 894094   epsilon: 0.213845950016053    steps: 332     evaluation reward: 8.45\n",
            "episode: 3318   score: 5.0   memory length: 894385   epsilon: 0.21355786001605118    steps: 291     evaluation reward: 8.4\n",
            "episode: 3319   score: 8.0   memory length: 894789   epsilon: 0.21315790001604865    steps: 404     evaluation reward: 8.42\n",
            "episode: 3320   score: 7.0   memory length: 895158   epsilon: 0.21279259001604633    steps: 369     evaluation reward: 8.42\n",
            "episode: 3321   score: 9.0   memory length: 895654   epsilon: 0.21230155001604323    steps: 496     evaluation reward: 8.37\n",
            "episode: 3322   score: 10.0   memory length: 896054   epsilon: 0.21190555001604072    steps: 400     evaluation reward: 8.43\n",
            "episode: 3323   score: 4.0   memory length: 896352   epsilon: 0.21161053001603886    steps: 298     evaluation reward: 8.24\n",
            "episode: 3324   score: 6.0   memory length: 896700   epsilon: 0.21126601001603668    steps: 348     evaluation reward: 8.22\n",
            "episode: 3325   score: 5.0   memory length: 896988   epsilon: 0.21098089001603487    steps: 288     evaluation reward: 8.22\n",
            "episode: 3326   score: 10.0   memory length: 897452   epsilon: 0.21052153001603197    steps: 464     evaluation reward: 8.25\n",
            "episode: 3327   score: 13.0   memory length: 897940   epsilon: 0.2100384100160289    steps: 488     evaluation reward: 8.3\n",
            "episode: 3328   score: 8.0   memory length: 898361   epsilon: 0.20962162001602627    steps: 421     evaluation reward: 8.26\n",
            "episode: 3329   score: 11.0   memory length: 898881   epsilon: 0.20910682001602302    steps: 520     evaluation reward: 8.32\n",
            "episode: 3330   score: 8.0   memory length: 899179   epsilon: 0.20881180001602115    steps: 298     evaluation reward: 8.36\n",
            "episode: 3331   score: 7.0   memory length: 899600   epsilon: 0.2083950100160185    steps: 421     evaluation reward: 8.38\n",
            "now time :  2019-12-12 23:52:51.670593\n",
            "episode: 3332   score: 13.0   memory length: 900244   epsilon: 0.20775745001601448    steps: 644     evaluation reward: 8.43\n",
            "episode: 3333   score: 5.0   memory length: 900553   epsilon: 0.20745154001601254    steps: 309     evaluation reward: 8.4\n",
            "episode: 3334   score: 8.0   memory length: 900942   epsilon: 0.2070664300160101    steps: 389     evaluation reward: 8.4\n",
            "episode: 3335   score: 13.0   memory length: 901397   epsilon: 0.20661598001600726    steps: 455     evaluation reward: 8.46\n",
            "episode: 3336   score: 6.0   memory length: 901745   epsilon: 0.20627146001600508    steps: 348     evaluation reward: 8.44\n",
            "episode: 3337   score: 10.0   memory length: 902109   epsilon: 0.2059111000160028    steps: 364     evaluation reward: 8.47\n",
            "episode: 3338   score: 3.0   memory length: 902384   epsilon: 0.20563885001600107    steps: 275     evaluation reward: 8.4\n",
            "episode: 3339   score: 9.0   memory length: 902840   epsilon: 0.20518741001599822    steps: 456     evaluation reward: 8.43\n",
            "episode: 3340   score: 8.0   memory length: 903148   epsilon: 0.2048824900159963    steps: 308     evaluation reward: 8.38\n",
            "episode: 3341   score: 17.0   memory length: 903537   epsilon: 0.20449738001599385    steps: 389     evaluation reward: 8.5\n",
            "episode: 3342   score: 9.0   memory length: 904009   epsilon: 0.2040301000159909    steps: 472     evaluation reward: 8.48\n",
            "episode: 3343   score: 10.0   memory length: 904516   epsilon: 0.20352817001598772    steps: 507     evaluation reward: 8.5\n",
            "episode: 3344   score: 9.0   memory length: 904878   epsilon: 0.20316979001598545    steps: 362     evaluation reward: 8.45\n",
            "episode: 3345   score: 8.0   memory length: 905331   epsilon: 0.20272132001598261    steps: 453     evaluation reward: 8.45\n",
            "episode: 3346   score: 7.0   memory length: 905724   epsilon: 0.20233225001598015    steps: 393     evaluation reward: 8.43\n",
            "episode: 3347   score: 8.0   memory length: 906125   epsilon: 0.20193526001597764    steps: 401     evaluation reward: 8.43\n",
            "episode: 3348   score: 10.0   memory length: 906477   epsilon: 0.20158678001597544    steps: 352     evaluation reward: 8.49\n",
            "episode: 3349   score: 8.0   memory length: 906888   epsilon: 0.20117989001597286    steps: 411     evaluation reward: 8.48\n",
            "episode: 3350   score: 10.0   memory length: 907406   epsilon: 0.20066707001596962    steps: 518     evaluation reward: 8.51\n",
            "episode: 3351   score: 11.0   memory length: 907800   epsilon: 0.20027701001596715    steps: 394     evaluation reward: 8.53\n",
            "episode: 3352   score: 7.0   memory length: 908216   epsilon: 0.19986517001596454    steps: 416     evaluation reward: 8.49\n",
            "episode: 3353   score: 23.0   memory length: 908718   epsilon: 0.1993681900159614    steps: 502     evaluation reward: 8.65\n",
            "episode: 3354   score: 8.0   memory length: 909140   epsilon: 0.19895041001595876    steps: 422     evaluation reward: 8.68\n",
            "episode: 3355   score: 9.0   memory length: 909484   epsilon: 0.1986098500159566    steps: 344     evaluation reward: 8.67\n",
            "episode: 3356   score: 6.0   memory length: 909838   epsilon: 0.19825939001595438    steps: 354     evaluation reward: 8.63\n",
            "episode: 3357   score: 4.0   memory length: 910092   epsilon: 0.1980079300159528    steps: 254     evaluation reward: 8.6\n",
            "episode: 3358   score: 7.0   memory length: 910445   epsilon: 0.19765846001595058    steps: 353     evaluation reward: 8.64\n",
            "episode: 3359   score: 10.0   memory length: 910917   epsilon: 0.19719118001594763    steps: 472     evaluation reward: 8.68\n",
            "episode: 3360   score: 17.0   memory length: 911469   epsilon: 0.19664470001594417    steps: 552     evaluation reward: 8.78\n",
            "episode: 3361   score: 10.0   memory length: 911986   epsilon: 0.19613287001594093    steps: 517     evaluation reward: 8.82\n",
            "episode: 3362   score: 14.0   memory length: 912402   epsilon: 0.19572103001593832    steps: 416     evaluation reward: 8.86\n",
            "episode: 3363   score: 17.0   memory length: 912829   epsilon: 0.19529830001593565    steps: 427     evaluation reward: 8.93\n",
            "episode: 3364   score: 6.0   memory length: 913143   epsilon: 0.19498744001593368    steps: 314     evaluation reward: 8.91\n",
            "episode: 3365   score: 11.0   memory length: 913613   epsilon: 0.19452214001593074    steps: 470     evaluation reward: 8.93\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}